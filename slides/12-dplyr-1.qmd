---
title: "Data Wrangling - one data frame `r emo::ji('hammer_and_wrench')`"
subtitle: "MATH/COSC 3570 Introduction to Data Science"
author: "Dr. Cheng-Han Yu <br> Department of Mathematical and Statistical Sciences <br> Marquette University"
# date: "`r format(Sys.time(), '%B %d %Y')`"
# macros: _macros.tex # import a list of TeX/LaTeX definitions
format: 
  revealjs:
    #     - "macros.tex"
    html-math-method:
      method: mathjax
      url: "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
    # include-in-header:
    highlight-style: arrow
    code-block-bg: true
    self-contained: false
    slide-number: c/t
    incremental: false
    width: 1800
    height: 1000
    margin: 0.05
    logo: "https://upload.wikimedia.org/wikipedia/commons/e/e8/Marquette_Golden_Eagles_logo.svg"
    footer: "[math3570-s24.github.io/website](https://math3570-s24.github.io/website/)"
    theme: ["simple", "slides.scss"]
    multiplex: true
    code-link: true
    fig-cap-location: bottom
    fig-align: center
    transition: none ## fade slide convex concave zoom
    title-slide-attributes:
      data-background-color: "#447099"
      # data-background-image: images/paper-texture.jpg
      # data-background-size: cover
      # data-background-color: "#698ED5"
editor: source
execute:
  freeze: true
  echo: true
---

#  {visibility="hidden"}

\def\bx{\mathbf{x}}
\def\bg{\mathbf{g}}
\def\bw{\mathbf{w}}
\def\bbeta{\boldsymbol \beta}
\def\bX{\mathbf{X}}
\def\by{\mathbf{y}}
\def\bH{\mathbf{H}}
\def\bI{\mathbf{I}}
\def\bS{\mathbf{S}}
\def\bW{\mathbf{W}}
\def\T{\text{T}}
\def\cov{\mathrm{Cov}}
\def\cor{\mathrm{Corr}}
\def\var{\mathrm{Var}}
\def\E{\mathrm{E}}
\def\bmu{\boldsymbol \mu}
\DeclareMathOperator*{\argmin}{arg\,min}
\def\Trace{\text{Trace}}



```{r}
#| label: setup
#| include: false
#| eval: true
library(countdown)
library(emo)
library(knitr)
library(gt)
library(gtExtras)
library(ggplot2)
library(tidyverse)
library(tidymodels)
library(fontawesome)
library(rmarkdown)
library(reticulate)
library(lattice)
library(openintro)
library(plotly)
# library(ISLR2)
# library(genridge)
# library(glmnet)
# library(gam)
# library(splines)
# library(MASS)

# library(ElemStatLearn)
knitr::opts_chunk$set(
    fig.asp = 0.618,
    fig.align = "center",
    out.width = "100%",
    fig.retina = 10,
    fig.path = "images/12-dplyr-1/",
    message = FALSE,
    global.par = TRUE
)
options(
  htmltools.dir.version = FALSE,
  dplyr.print_min = 6, 
  dplyr.print_max = 9,
  tibble.width = 80,
  width = 80,
  digits = 3
  )
hook_output <- knitr::knit_hooks$get("output")
knitr::knit_hooks$set(output = function(x, options) {
  lines <- options$output.lines
  if (is.null(lines)) {
    return(hook_output(x, options))  # pass to default hook
  }
  x <- unlist(strsplit(x, "\n"))
  more <- "..."
  if (length(lines)==1) {        # first n lines
    if (length(x) > lines) {
      # truncate the output, but add ....
      x <- c(head(x, lines), more)
    }
  } else {
    x <- c(more, x[lines], more)
  }
  # paste these lines together
  x <- paste(c(x, ""), collapse = "\n")
  hook_output(x, options)
})
```


## 

```{r}
#| out-width: "100%"
#| fig-align: "center"
#| echo: false
knitr::include_graphics("https://raw.githubusercontent.com/hadley/r4ds/main/diagrams/data-science/wrangle.png")
```


::: notes
- Welcome back
- This week: introduce tools of tidyverse for data wrangling
- learn how to easily clean or transform our data so that we can extract some important properties of the data, and the data are ready for visualization, modeling and analysis.
:::
<!-- # {background-color="#A7D5E8"} -->

# {background-color="#A7D5E8" background-image="https://raw.githubusercontent.com/rstudio/hex-stickers/master/PNG/dplyr.png" background-size="30%" background-position="90% 50%"}

::: {.left}
<h1> Grammar of Data Manipulation </h1>
<!-- <h3>[htmlwidgets](http://www.htmlwidgets.org/): leaflet, dygraphs, networkD3</h3> -->
:::

::: notes
- Starting this week, we are going to talk about Grammar of Data Manipulation or Grammar of Data Wrangling. 
- In particular, we are going to use the tidyverse package dplyr to manipulate or transform our data.
- If you become a data scientist after college, you will find that you spend most of the time cleaning or wrangling your data because the raw data usually look ugly, big and unorganized, and you have to grab what you really need for your analysis. Once the data set is ready, fitting a machine learning model or run an algorithm is just couple lines of code. Very easy because nowadays, many models and algorithms have been wrapped in a function. You just need to call the function.
- You may feel a little bored the coming two weeks because I think data wrangling is not as fun as data visualization. But we have no choice. It is a must-have skill to be a data scientist, and I believe you will not learn this in other courses, but in this course only, or maybe in my course only.
- All right. Let's begin.
:::


## Grammar of Data Wrangling: [dplyr](https://dplyr.tidyverse.org/index.html) `r emo::ji('package')`

- based on the concepts of functions as **verbs** that manipulate data frames

:::: {.columns}

::: {.column width="50%"}
```{r}
#| purl: false
#| echo: false
#| out-width: "70%"
knitr::include_graphics("images/12-dplyr-1/dplyr-part-of-tidyverse.png")
```
:::

::: {.column width="50%"}

- `mutate`: *create* new columns from the existing^[We can use `tibble::add_column()` to add one or more columns to an existing data frame.]
- `filter`: pick *rows matching criteria*
- `slice`: pick *rows using index(es)*
- `distinct`: filter for *unique* rows
- `select`: pick *columns by name*
- `summarise`: reduce variables to values
- `group_by`: for grouped operations
- `arrange`: reorder rows
- ... (many more)
:::
::::


::: notes
- So Grammar of Data Wrangling is based on the concepts of functions as **verbs** that manipulate data frames. Using these verbs in coding is simple, intuitive and straightforward. They let you know what you are doing on your data.
- And the package that does this is called dplyr.
- This package offers a variety of functions each of which is a verb, as listed here, mutate, filter, slice, distinct. Is distinct a verb?? 
- there is no rule without an exception
- Anyway, we will be going through these functions that help us manipulate or transform our data. OK
:::



## Rules of **dplyr** Functions
:::: {.red}

::: {.large}

- First argument is *always* a **data frame**

- Subsequent arguments say what to do with that data frame

- *Always* return a **data frame**

- Don't modify in place

:::

::::


::: notes
- So there are four rules of dplyr functions.
- First argument is *always* a **data frame**
- Subsequent arguments say what to do with that data frame
- *Always* return a **data frame**, so data frame in, data frame out.
- Don't modify in place, meaning that when we apply a function of dplyr to the data, we are not changing that data frame. We have option to re-save our result, either overwrite the existing data frame that we have or as a separate object, but we are not modifying the data frame in place.
:::


## Data: US gun murders by state for 2010
```{r}
#| label: murders_data
(murders <- read_csv("./data/murders.csv"))
```

::: notes
- The data set we are going to use as an illustrative example is again the murders data set in the dslabs package with the book Intro to Data Science
- It is of R base data frame type with 51 observations and 5 variables.
- Notice that region variable here is a factor, which may not make sense and we can convert it into a character vector if needed.
- And we can change its data type to modern tibble data frame, again use as_tibble() function.
:::


## Adding a New Variable (Column) with `mutate()`
- `dplyr::mutate()` takes
  + a data frame as the 1st argument
  + the name and values of the variable as the 2nd argument using format `name = values`.

```{r mutate}
#| label: mutate
(murders <- murders |>  
     mutate(rate = total / population * 100000)) #<<
```

. . .

- `total` and `population` inside the function are **not** defined in our R environment. 

- `dplyr` functions know to look for variables in the data frame provided in the 1st argument. 




::: notes
- OK now let's begin playing the the data set.
- First, we can add a New Variable into the existing data set with the function mutate().
- Remember, variables are stored by columns, and so adding new variables means add more columns to the data set.
- The function `mutate()` takes the data frame as a first argument and the name and values of the variable as a second argument using the convention `name = values`.
- Here, I compute the murder rate as the total number of murders divided by population and times 100,000. So the rate means the incidence rate per 100,000 people
- `total` and `population` inside the function are **not** defined in our R environment, but we didn't get an error.
- Functions in **dplyr** know to look for variables in the data frame provided in the first argument. `total` will have the values in `murders_tbl$total`.
- Now you can see the new data set has a new column variable `rate` shown in the last column. 
- Use relocate() to change column positions, using the same syntax as select() to make it easy to move blocks of columns at once.
<!-- - `total` will have the values in `murders$total` -->

mutate() creates new columns that are functions of existing variables. It can also modify (if the name is the same as an existing column) and delete columns (by setting their value to NULL).
mutate(
  .data,
  ...,
  .by = NULL,
  .keep = c("all", "used", "unused", "none"),
  .before = NULL,
  .after = NULL
)

:::

## Filtering Observations (Rows) with `filter()`

- `dplyr::filter()` takes a
  + data frame as the 1st argument
  + *conditional* statement as the 2nd. (pick rows matching criteria)

```{r filter}
#| label: filter
# filter the data table to only show the entries for which 
# the murder rate is lower than 0.7
murders |> 
    filter(rate < 0.7) #<<
```


::: notes
- All right. We add columns by mutate() function, and we pick observations (rows) with filter() function.
- `filter()` function again takes the data frame as the first argument and then the conditional statement as the second. 
- So we pick rows by matching the criteria of the conditional statement in the second argument of the filter() function.
- For example, here I filter the data table to only show the obs for which the murder rate is lower than 0.71
:::


## `filter()` for Many Conditions at Once

```{r}
#| label: filter2
murders |>  
    filter(rate > 0.1 & rate < 0.7,  #<<
           region == "Northeast")  #<<
```

::: notes
- We can actually use several conditions at once to filter the observations
- For example, here we want the observations whose murder rate is between 0.1 and 0.71, and their region is Northeast.
- You can see that only two observations satisfy the conditions, New Hampshire and Vermont.
- Use one single & to have a logical vector
- You can also write rate >= 0.1, rate <= 0.71. This way we separate the condition rate >= 0.1 & rate <= 0.71 into 2 conditions. 
- Theoretically You can provide as many conditions as you want. The conditions are combined with &
:::


## Logical Operators

|operator    | definition                   | operator                    | definition          |
|------------|------------------------------|-----------------------------|---------------------|
|`<`         | less than                    |`x`&nbsp;&#124;&nbsp;`y`     | `x` OR `y`          |
|`<=`        |	less than or equal to       |`is.na(x)`                   | if `x` is `NA`      |
|`>`         | greater than                 |`!is.na(x)`                  | if `x` is not `NA`  |
|`>=`        |	greater than or equal to    |`x %in% y`                   | if `x` is in `y`    |
|`==`        |	exactly equal to            |`!(x %in% y)`                | if `x` is not in `y`|
|`!=`        |	not equal to                |`!x`                         | not `x`             |
|`x & y`     | `x` AND `y`                  |                             |                     |


::: notes
- We have talked about this. These are logical operators you can use in the conditions of the filter() function.
:::


## `slice()` for Certain Rows using Indexes

```{r}
#| label: slice
#| 
# 3rd to 6th row
murders |> 
    slice(3:6)
```


. . .

:::{.question}
How do we subset rows using matrix indexing?
:::

. . .

```{r}
murders[3:6, ]
```

::: notes
- OK. Slice. We use slice() function to subset observations or rows using indexes.
- Same as other functions, the first argument is a data frame, so I use the pipe operator sending murders_tbl data set to the slice function.
- It is the same as treating a data drame as a matrix and subsetting the rows, which is the usual way we do before learning this function. 
- So here we extract row 3 to row 6 of the data set.
- microbenchmark::microbenchmark(slice(murders_tbl, 3:6), murders_tbl[3:6, ])
- You cannot(can?) write murders_tbl[3:6, ] as a function call. How?
slice_head() and slice_tail() select the first or last rows.
slice_sample() randomly selects rows.
slice_min() and slice_max() select rows with highest or lowest values of a variable.
:::


## `distinct()` to Filter for Unique Rows

```{r}
#| label: distinct
# Select only unique/distinct rows from a data frame
murders |> distinct(region)  ## default
murders |> distinct(region, .keep_all = TRUE) ## keep all other variables
```

::: notes
- We can use distinct() function to select only unique/distinct rows from a data frame.
- For example here, we use variable region to decide the unique rows. By default, the function only gives us the unique values of the variable region. 
- Do you wonder why we have the order South, West, Northeast, and North Central?
- Actually, these values are the values of some rows.
- If we keep all variables, we see that the south is the south for Alabama, west for alaska, northeast for connecticut, and North central for illinois.
- distinct() functions grabs rows that first has each of the unique values of region variable.
- So Alabama is the first observation that has value South, Alaska is the first observation that has value West, Connecticut is the first observation that has value Northeast, and Illinois is the first observation that has value North Central. 
- microbenchmark::microbenchmark(distinct(murders_tbl, region), as_tibble(unique(murders_tbl$region)))
:::



## `distinct()` Grabs First Row of The Unique Value

```{r}
murders |> distinct(region, .keep_all = TRUE)
```

```{r}
murders |> slice(1:5)
```


## Selecting Columns with `select()`
- In `dplyr::select()`, the 1st argument is a data frame, followed by variable names being selected in the data.
- **The order of variable names matters!**
```{r}
names(murders)
```

```{r}
#| label: select
# select three columns, assign this to a new object
murders |> select(region, rate, state)
```


::: notes
- filter(), slice() and distinct()are functions for picking rows. 
- select() is a function for picking columns or variables.
- Here, I select three columns region, rate, and state.
- Notice that the order of variable names matters! The original data set has variable order "state"      "abb"        "region"     "population" "total"      "rate".
- But the resulting data frame will have the variables or columns ordered as  region, rate, state because this is the order you specify in the select().
- If you don't know the column names, you can select by position. murders_tbl %>% select(3, 6, 1)
:::

## `select()` to Exclude Variables

```{r}
#| label: select-exclude
## exclude variable population
murders |> select(-population)
```

::: notes
- If you want to exclude some variables, just provide a vector of variables you want to remove, and put a minus sign in front of it.
- Here we remove the population variable.
:::

## `select()` a Range of Variables

```{r}
#| label: select-range
names(murders)
## from region to rate
murders |> select(region:rate)
```

::: notes
- We can also select a range of variables.
- For example, we select all variables for region to rate by using region:rate, just as we create a sequence of numbers from 1 to 5 using 1:5.
- murders_tbl %>% select(3:6)
:::

## `select()` Variables with Certain Characteristics

- `starts_with()` is a [**tidy-select**](https://tidyselect.r-lib.org/index.html) helper function.

```{r}
#| label: select-start
murders |> select(starts_with("r"))
```


::: notes
- We can also some helper functions to select variables with some condition.
- For example, we can use a helper function starts_with() to select variables whose name starts with letter "r".
- And so region and rate variables are selected.
:::

## `select()` Variables with Certain Characteristics
- `ends_with()` is a [**tidy-select**](https://tidyselect.r-lib.org/index.html) helper function.

```{r}
#| label: select-end
murders |> select(ends_with("ion"))
```

::: notes
- We can also select variables whose name ends with "ion"
- And so region and population variables are selected.
:::


## [**tidy-select**](https://tidyselect.r-lib.org/index.html) Helpers^[See help for any of these functions for more info, e.g. `?num_range`.]

- `starts_with()`: Starts with a prefix
- `ends_with()`: Ends with a suffix
- `contains()`: Contains a literal string
- `num_range()`: Matches a numerical range like x01, x02, x03
- `one_of()`: Matches variable names in a character vector
- `everything()`: Matches all variables
- `last_col()`: Select last variable, possibly with an offset
- `matches()`: Matches a regular expression (a sequence of symbols/characters expressing a string/pattern to be searched for within text)

::: notes
- Here is a list of select helpers.
- I am not able to go through every helper in detail. But they can be very useful depending on your goal.
- Absolutely check their help page to learn how to use them and review the examples in the help page. OK.
:::

## Rationale for Pipe Operator

:::{.question}
How do we show three variables (state, region, rate) for states that have murder rates below 0.7?
:::

- Method 1: Define the intermediate object `new_table`

```{r}
new_table <- select(murders, state, region, rate) 
filter(new_table, rate < 0.7)
```

::: notes
- Remember we talked about the pipe operator, right? But we haven't really used it often.
- But it kinda make much sense to use the pipe operator for data manipulation using dplyr functions.
- Because the first argument of dplyr function is always a data frame and its function output is also a data frame, which can be the input of another dplyr function.
- So if we wanna manipulate our data set via several different actions using the dplyr functions step by step, pipe operator can be very useful. Let's see why.
- How do we show three variables (state, region, rate) for states that have murder rate below 0.71?
- We can first select three variables state, region, rate, and save the resulting output to an object new_table, and then apply filter() function on the new_table to get the observations having murder rate less than 0.71
- In fact, the object new_table is unnecessary. The table is not what we want, and any object created in the R environment occupies some memory space. 
:::


## Rationale for Pipe Operator
:::{.question}
How do we show three variables (state, region, rate) for states that have murder rates below 0.7?
:::

- Method 2: Apply one function onto the other with no intermediate object


```{r}
#| purl=FALSE
## not so easy to read and understand
filter(select(murders, state, region, rate), rate < 0.7) 
```

::: notes
- If we don't use new_table object, we can put the code select(murders_tbl, state, region, rate) directly on the first argument of filter() function as the data input.
- This gives us the same resulting data frame. 
- However, the code is not very easy to read and understand because when we read the code from left to right, it starts with filter, and then select, but we actually do the selection first. Also, the second argument or the condition used in the filter() function is at the end of the code, which is far away from the function name at the beginning.
:::


## Rationale for Pipe Operator
- The code that looks like a verbal description of what we want to do without intermediate objects:

> **data > *select()* > data after selecting > *filter()* > data after selecting and filtering**

```{r}
murders |> 
    select(state, region, rate) |>  
    filter(rate < 0.7)
```

::: notes
- Pipe Operator let us write code that looks more like a description of what we want to do without intermediate objects.
- We start with the original data set, then we select variables, and then we filter observations.
- So our code can be like 
It's more clear and intuitive, right?
:::


## Summarizing Data -- `summarize()`
- `summarize()` provides a data frame that summarizes the statistics we compute.
<!-- - The output is always a data frame. -->

```{r}
heights <- read_csv("./data/heights.csv")
head(heights)
```

::: notes
- The `summarize()` function in **dplyr** provides a way to compute summary statistics.
- Again, its first argument and output are always data frames.
- We are gonna use another data set heights in the dslabs package to demonstrate the usage of function.
- The data set only has two variables, sex and height.
- height is a variable, but heights is the data set
:::


## Summarizing Data -- `summarize()`
```{r summarize}
(s <- heights |> 
    filter(sex == "Female") |> 
    summarize(avg = mean(height),  
              stdev = sd(height),
              median = median(height), 
              minimum = min(height)))
s$avg; s$minimum
```

:::{.alert}
`summarise()` produces a *new data frame* that is not any variant of the original data frame.
:::


::: notes
- Suppose we want to find the mean and standard deviation of female height and store the two values as a data frame, we can start with the data set heights, then filter or grab the observations that have sex Female, and then with the filtered data, use the summarize function to create a data frame of two variables "average" and "standard_deviation" computed from the variable height. 
- You see that the resulting object s is a data frame with two variables. 
- Notice that `summarise()` changes the data frame entirely, it collapses rows down to a single summary statistic, and removes all columns that are irrelevant to the calculation. Basically, the resulting df is not any variant of the original df anymore.

`summarise()` changes the data frame entirely, it collapses rows down to a single summary statistic, and removes all columns that are irrelevant to the calculation.
:::


## Summarizing Data -- `summarize()`
- One variable `quans` that has 3 values. The output is a 3 by 1 data frame.

```{r summarize-quan}
(s2 <- heights |>  
    filter(sex == "Female") |> 
    summarize(quans = quantile(height, c(0.1, 0.5, 0.9))))
```


::: notes
- we will get a data frame with more than one row if the function we use in summarize() return a vector.
- For example here, we compute the 01, 0.5, and 0.9 quantile of variable height, and call it quantiles. Then the resulting data frame will have 3 rows, basically a column vector with 3 elements.
str(s2)
:::


## Summarizing Data -- `summarize()` {visibility="hidden"}
- `summarize()` always returns a data frame, which might be problematic when we want to use it as a numeric value with other operations or functions.

```{r}
(rate_df <- murders |> 
    summarize(rate = sum(total) / sum(population) * 100000))
class(rate_df)
rep(rate_df, 3) ## want a (atomic) vector of length 3, but get a list of length 3!
```

::: notes
- We use summarize() function and compute the variable rate. The result is a 1 by 1 data frame. 
:::


## Summarizing Data -- `pull()`  {visibility="hidden"}
- `pull()` accesses values or extract a single column in a data frame.

```{r pull}
rate_num <- rate_df |>  
    pull()
class(rate_num)
rep(rate_num, 3)
```

. . .

:::: {.columns}

::: {.column width="50%"}
```{r}
murders |> select(total)
```
:::


::: {.column width="50%"}
```{r}
murders |> pull(total)
```
:::
::::


::: notes
- If we want a number or a vector in general, we can use pull() function with the variable name rate inside the function.
- Basically, pull() extract a single column as a vector, not a data frame. It's like `$` for selecting a column. `murder_rate_df$rate`
- If we wanna keep the pipe operation style, using pull() function looks nicer.
murder_rate_df %>% `$`(rate)
- murders_tbl["total"]: tibble
- murders_tbl %>% select(total): tibble
- murders_tbl[["total"]]: vector
- murders_tbl %>% pull(total): vector

:::


## Grouping -- `group_by()`

```{r}
#| label: groupby

(heights_group <- heights |> 
     group_by(sex))  #<<
```

```{r}
class(heights_group)
```

- `heights_group` is a **grouped data frame**.

- Tibbles are similar, but see `Groups: sex [2]` after grouping data by `sex`.

- `summarize()` behaves differently when acting on `grouped_df`.



::: notes
- A common operation in data exploration is to first split data into groups and then compute summaries for each group.
- To group a data set by some variable, we can use group_by() function. 
- Here, we group the heights data set by the variable sex. 
- Outputs are similar, but we see `Groups: sex [2]` after grouping data by sex. [2] means there are two groups.
- And now the heights_group data set has a new class called grouped_df.
:::


## Group and Summarize: `group_by()` + `summarize()`

- `summarize()` applies the summarization to **each group separately**.

```{r}
#| label: groupby-summarize
heights |> 
    group_by(sex) |> 
    summarize(avg = mean(height), stdev = sd(height), 
              median = median(height), minimum = min(height))
```

. . .

```{r}
#| label: groupby-summarize2
murders |>  
    group_by(region) |> 
    summarize(median_rate = median(rate))
```

::: notes
- The `summarize()` function applies the summarization to **each group separately**.
- Here we use the same summarize() function and compute the average and sd of the variable height as we previous did. 
- But if the the data set is a grouped data frame grouped by sex, the summarized output will show the avg and sd for each group, make and female separately.
- Another example is that we first group the murders data by region, then when we compute the median murder rate, it will get the median murder rate for each region.
- This is quite helpful when we want to explore the relationship between numerical and categorical variables. Like here, we discover that the murder rate in the south is the highest.
- You can absolutely include some statistics summary in your project proposal when you describe your data.
:::


## Sorting Rows in Data Frames -- `arrange()`
- `arrange()` orders entire data tables.

```{r}
#| label: arrange
## order the states by population size
murders |>  
    arrange(population)
```


::: notes
- For ordering entire data tables, the dplyr function `arrange()` is useful.
- We get to decide which column to sort by.
- If we want to sort the observations of murders data set by population size, we just need to pipe the data set into arrange function and specify population variable.
- How do we do the same thing with base R grammar, not tidyverse grammar?
- murders[order(murders$population), ]
:::

## Sorting Rows in Data Frames -- `arrange()`  {visibility="hidden"}
- The function `desc()` transforms a vector so that it is in descending order.

```{r}
#| label: desc
## see the states by murder rate, from highest to lowest
murders |> 
    arrange(desc(rate))
```

::: notes
- The function `desc()` transforms a vector so that it is in descending order.
- With this function, we arrange states by murder rate in descending order.
:::



##
::: {.lab}
<span style="color:blue"> **15-dplyr** </span>
<!-- - Create the R script **lab13-dplyr.R** -->

In **lab.qmd** `## Lab 15` section, import the `murders.csv` data and 

1. Add **(mutate)** the variable `rate = total / population * 100000` to `murders` data (as I did).

2. **Filter** states that are in *region Northeast or West* and their *murder rate is less than 1*.

3. **Select** variables `state`, `region`, `rate`. 

- Print the output table after you do 1. to 3., and save it as object `my_states`.

- **Group** `my_states` **by** `region`. Then **summarize** data by creating variables `avg` and `stdev` that compute the mean and standard deviation of `rate`. 

- **Arrange** the summarized table by `avg`.
:::

##

:::: {.columns}

::: {.column width="50%"}
```{r, eval=FALSE}

_______ <- _______ |> 
    mutate(_______) |> 
    filter(_______) |> 
    select(_______)

_______ |>  
    group_by(______) |> 
    summarize(______) |> 
    arrange(_______)
```
:::

::: {.column width="50%"}

```{r}
#| echo: false
library(dplyr)
library(dslabs)
data(murders)
(my_states <- murders |>  
    mutate(rate = total / population * 100000) |>  
    filter(region %in% c("West", "Northeast"), rate < 1) |>  
    select(state, region, rate))
my_states |>  
    group_by(region) |>  
    summarize(avg = mean(rate), std_dev = sd(rate)) |>  
    arrange(avg)
```
:::
::::


# {background-color="#ffde57" background-image="https://upload.wikimedia.org/wikipedia/commons/e/ed/Pandas_logo.svg" background-size="40%" background-position="90% 50%"}


::: {.left}
<h1> Data Manipulation </h1>
:::


::: notes
https://towardsdatascience.com/python-pandas-vs-r-dplyr-5b5081945ccb
:::

## 

```{python}
import numpy as np
import pandas as pd
```

```{python}
murders = pd.read_csv('./data/murders.csv')
murders.head(5)
```

## New Variables `.assign`

- `dplyr::mutate()`

- [Have to use `murders.total` and `murders.population` instead of `total` and `popution`.]{.green}

```{python}
#| eval: true
murders = murders.assign(
    rate = round(murders.total / murders.population * 100000, 2))
```

```{python}
#| echo: true
murders.head(5)
```

## Filter Rows `.query`

-  `dplyr::filter()`

- [Conditions must be a **string** to be evaluated!]{.green}

- [Cannot write `murders.rate`, and should use `rate`. ]{.green}


```{python}
murders.query("rate < 0.7")
```


## Select Columns `.filter`

-  `dplyr::select()`

- [Have to be strings]{.green}


```{python}
murders.filter(items = ['region', 'rate', 'state'])
```


## Grouping `.groupby + .agg`

- `dplyr::group_by() + dplyr::summarize()`

```{python}
heights = pd.read_csv('./data/heights.csv')
```

```{python}
heights.groupby('sex')
```


. . .


```{python}
## a data frame
heights.groupby('sex').agg(['mean', 'std', 'median', 'min'])
```



## Sorting `.sort_values`


- `dplyr::arrange()`


```{python}
murders.sort_values('population').head(5)
```

. . .

- `dplyr::arrange(desc())`


```{python}
murders.sort_values('rate', ascending = False).head(5)
```











