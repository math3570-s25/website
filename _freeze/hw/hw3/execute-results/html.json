{
  "hash": "39e3acb697b54e349ca004e05bc90041",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Homework 3: Probability, Statistics and Machine Learning\"\nsubtitle: \"Spring 2025 MATH/COSC 3570 Introduction to Data Science by Dr. Cheng-Han Yu\"\nformat: \n  html:\n    code-fold: false\n    code-tools: true\ndate: today\nauthor: \"**Insert Your Name!!**\"\nnumber-sections: true\nfrom: markdown+emoji\neditor: \n  source\n---\n\n\n\n-   **Note: For any simulation or random sampling, set the random seed at your student ID number, for example `set.seed(6145678)` in R or `train_test_split(X, y, test_size=0.2, random_state=6145678)` in Python **\n\n- Please code in R for the problems starting with **[R]**, and code in python for those starting with **[Python]**.\n\n# Probability and Statistics\n\n## Monte Carlo Simulation\n\n<!-- 1. Milwaukee Bucks and Golden State Warriors are playing NBA Finals 🏆. The first to win four games wins the series. The Bucks are a better team and have a 60% chance of winning each game. If the Bucks lose the **first two games**, calculate the probability that the Bucks win the NBA championship?  -->\n\n<!-- **[Hint]**: You can use binomial distribution, and given the first two games loss, the probability $P(\\text{Bucks wins the series})$ is -->\n\n<!-- $$P(\\text{Bucks wins 4 in a row}) + P(\\text{Bucks wins 4 in 5 games})$$ -->\n\n<!-- ```{r} -->\n\n<!-- ## code -->\n\n<!-- ``` -->\n\n<!-- 2. Confirm the results of the previous question using a Monte Carlo simulation. -->\n\n<!-- ```{r} -->\n\n<!-- ## code -->\n\n<!-- # set.seed(your ID number) -->\n\n<!-- ``` -->\n\n1. **[R]** We are in a classroom with 50 people. If we assume this is a randomly selected group of 50 people, what is the chance that [at least two people have the same birthday](https://betterexplained.com/articles/understanding-the-birthday-paradox/)? Here we use a Monte Carlo simulation. For simplicity, we assume nobody was born on February 29.\n\n\ni.  Note that birthdays can be represented as numbers between 1 and 365, so a sample of 50 birthdays can be obtained like this:\n\n::: {.cell}\n\n```{.r .cell-code}\nn <- 50\nbdays <- sample(x = 1:365, size = n, replace = TRUE)\n```\n:::\n\nii. To check if in this particular set of 50 people we have at least two with the same birthday, we can use the function `duplicated()`, which returns `TRUE` whenever an element of a vector is a duplicate. Here is an example:\n\n::: {.cell}\n\n```{.r .cell-code}\nduplicated(c(1, 2, 3, 1, 4, 3, 5))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] FALSE FALSE FALSE  TRUE FALSE  TRUE FALSE\n```\n\n\n:::\n:::\n\nThe second time 1 and 3 appear, we get a `TRUE`.\n\niii. To check if two birthdays were the same, we simply use the `any()` and `duplicated()` functions like this:\n\n::: {.cell}\n\n```{.r .cell-code}\nany(duplicated(bdays))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] TRUE\n```\n\n\n:::\n:::\n\nIn this case, we see that it did happen. At least two people had the same birthday.\n\nTo estimate the probability of a shared birthday in the group, repeat this experiment by sampling sets of 50 birthdays 10000 times, and find the relative frequency of the event that at least two people had the same birthday.\n\n::: {.cell}\n\n```{.r .cell-code}\n## code\n# set.seed(your ID number)\n```\n:::\n\n## [Central Limit Theorem](https://chenghanyu-introstatsbook.netlify.app/prob-llnclt#central-limit-theorem)\n\nSuppose random variables $X_1, X_2, \\dots, X_n$ are independent and follow [Chi-squared distribution](https://en.wikipedia.org/wiki/Chi-squared_distribution) with its parameter degrees of freedom (df) 1, $\\chi^2_{df=1}$.\n\n\n2. **[R]**  Use `dchisq()` to plot $\\chi^2_{df=1}$ distribution. $\\chi^2_{df=1}$ takes any positive value. But let's just consider values between 0 and 5, $x\\in (0, 5)$ for plotting.\n\n::: {.cell}\n\n```{.r .cell-code}\n## code\n```\n:::\n\n3. **[R]**  Consider three sample sizes $n = 2, 8, 100$, and set the sample size of the sample mean $\\overline{X}_n$ be $1000$. Show the sampling distribution of $\\overline{X}_n$, i.e., the collection $\\{\\overline{X}_n^{(m)}, m=1, 2, \\dots, 1000\\}$, looks more and more like Gaussian as $n$ increases by making histograms of $\\overline{X}_n$ samples with $n = 2, 8, 100$. \n\n\nThe procedure is the following: For each $n = 2, 8, 100$,\n\ni.  Draw $n$ values $x_1, x_2, \\dots, x_n$ using `rchisq(n, df = 1)`.\nii. Compute the mean of the $n$ values, which is $\\overline{x}_n$.\niii. Repeat i. and ii. 1000 times to obtain 1000 $\\overline{x}_n$s.\niv. Plot the histogram of these 1000 $\\overline{x}_n$s.\n\n::: {.cell}\n\n```{.r .cell-code}\n## code\n# set.seed(your ID number)\n```\n:::\n\n\n\n\n# Machine Learning\n\n## Linear Regression\n\nA pharmaceutical firm would like to obtain information on the relationship between the dose level and potency of a drug product. To do this, each of 15 test tubes is inoculated with a virus culture and incubated for 5 days at 30°C. Three test tubes are randomly assigned to each of the five different dose levels to be investigated (2, 4, 8, 16, and 32 mg). Each tube is injected with only one dose level, and the response of interest is obtained.\n\n4. **[R]**  Import [`dose.csv`](./dose.csv) into your working session. The data set is not tidy for us. Use `pivot_longer()` to make it tidy as the shown tibble below. Call the tidy data set `dose_tidy` for later regression analysis.\n\n::: {.cell}\n\n```{.r .cell-code}\n## code\n\n## # A tibble: 15 × 3\n##    dose_level tube  response\n##         <dbl> <chr>    <dbl>\n##  1          2 tube1        5\n##  2          2 tube2        7\n##  3          2 tube3        3\n##  4          4 tube1       10\n##  5          4 tube2       12\n##  6          4 tube3       14\n##  7          8 tube1       15\n##  8          8 tube2       17\n##  9          8 tube3       18\n## 10         16 tube1       20\n## 11         16 tube2       21\n## 12         16 tube3       19\n## 13         32 tube1       23\n## 14         32 tube2       24\n## 15         32 tube3       29\n```\n:::\n\n5. **[R]**  Fit a simple linear regression with the predictor $\\texttt{dose level}$ for `response`. Print the fitted result.\n\n::: {.cell}\n\n```{.r .cell-code}\n## code\n```\n:::\n\n6. **[R]** With (5), plot the data with a $95\\%$ confidence interval for the mean response.\n\n::: {.cell}\n\n```{.r .cell-code}\n## code\n```\n:::\n\n7. **[R]**  Fit a simple linear regression model with the predictor $\\texttt{ln(dose level)}$ for `response`, where $\\ln = \\log_e$. Print the fitted result.\n\n::: {.cell}\n\n```{.r .cell-code}\n## code\n```\n:::\n\n8. **[R]**  With (7), plot the data $(\\ln(\\text{dose level})_i, \\text{response}_i), i = 1, \\dots, 15$ with a $95\\%$ confidence interval for the mean response.\n\n::: {.cell}\n\n```{.r .cell-code}\n## code\n```\n:::\n\n9. **[R]**  Draw residual plots of Model in (5) and (7). According to the plots, which model you think is better?\n\n::: {.cell}\n\n```{.r .cell-code}\n## code\n```\n:::\n\n10. **[Python]**  Import [`dose_tidy.csv`](./dose_tidy.csv) and redo (5). Show the slope and intercept.\n\n::: {.cell}\n\n```{.python .cell-code}\n\n# code\n```\n:::\n\n11. **[Python]** to predict the response value when the dose level is 10 and 30.\n\n::: {.cell}\n\n```{.python .cell-code}\n\n# code\n```\n:::\n\n## Binary Logistic Regression\n\n12. **[R]** Import [`body.csv`](./body.csv). Split the data into a training set and a test set. Set the random seed at your student ID number. Use 80:20 rule.\n\n::: {.cell}\n\n```{.r .cell-code}\n# code\n# set.seed(your ID number)\n```\n:::\n\n13. **[R]** Fit a logistic regression with the predictor `HEIGHT` using the training sample data. Find the probability that the subject is male given `HEIGHT = 165`.\n\n::: {.cell}\n\n```{.r .cell-code}\n# code\n```\n:::\n\n14. **[R]** Fit a logistic regression with the predictor `BMI` using the training sample data. Find the probability that the subject is male given `BMI = 25`.\n\n::: {.cell}\n\n```{.r .cell-code}\n# code\n```\n:::\n\n15. **[R]** Do the classification on the test set for the model (13) and (14), and compute the test accuracy rate. Which model gives us higher accuracy rate?\n\n::: {.cell}\n\n```{.r .cell-code}\n# code\n```\n:::\n\n16. **[Python]** Split the `body` data into a training set and a test set.\n\n::: {.cell}\n\n```{.python .cell-code}\n\n## code\n# set random_state\n```\n:::\n\n17. **[Python]** Fit a logistic regression with the predictor `BMI` using the training sample data. Find the probability that the subject is male given `BMI = 25`.\n\n::: {.cell}\n\n```{.python .cell-code}\n\n# code\n```\n:::\n\n18. **[Python]** Do the classification on the test set. Compute the test accuracy rate.\n\n::: {.cell}\n\n```{.python .cell-code}\n\n# code\n\n```\n:::\n\n## Multinomial Logistic Regression\n\n\n19. **[Python]** We can actually use logistic regression for the responses with more than 2 categories. \n    + Import `penguins.csv`.\n    + Use method `.dropna()` to remove observations having missing values `NaN`.\n\n::: {.cell}\n\n```{.python .cell-code}\n\n# code\n```\n:::\n\n20. **[Python]** Use [`.value_counts()`](https://pandas.pydata.org/docs/reference/api/pandas.Series.value_counts.html) and [`.plot.bar()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.bar.html) to get the frequency distribution and bar chart of `species`.\n\n::: {.cell}\n\n```{.python .cell-code}\n\n# code\n```\n:::\n\n21. **[Python]** Use the camplete-case penguins data and variable `flipper_length_mm` to classify the `species`. Save the fitted result as `clf_pen`. Compute the training accuracy rate.\n\n::: {.cell}\n\n```{.python .cell-code}\n\n# code\n```\n:::\n\n\n\n22. **[Python]** Construct the confusion matrix, and save it as the object `cm`. Then use the code below to show the confusion matrix as a plot.\n\n::: {.cell}\n\n```{.python .cell-code}\n\n# code\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom sklearn.metrics import ConfusionMatrixDisplay\nimport matplotlib.pyplot as plt\ndisp = ConfusionMatrixDisplay(cm, display_labels=clf_pen.classes_)\ndisp.plot()\nplt.show()\n```\n:::\n\n\n\n## K-Nearest Neighbors (KNN)\n\n23. **[R] or [Python] (Choose one)** Fit the KNN with $K=10$ using `BMI` on the training data and do the classification on the same test set used in logistic regression. Obtain the confusion matrix of the test data, and test accuracy rate.\n\n::: {.cell}\n\n```{.r .cell-code}\n# R code\n```\n:::\n\n\n::: {.cell}\n\n```{.python .cell-code}\n\n# Python code\n```\n:::",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}