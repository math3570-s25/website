[
  {
    "objectID": "course-syllabus.html",
    "href": "course-syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Click here to download the syllabus.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#time-and-location",
    "href": "course-syllabus.html#time-and-location",
    "title": "Syllabus",
    "section": "Time and location",
    "text": "Time and location\n\n\n\n\n\n\n\n\n\nDay and Time\nLocation\n\n\n\n\nLectures\nTu & Th 2:00 - 3:15 PM\nLalumiere Language Hall 232\n\n\nOffice hours\nTu & Th 4:50 - 5:50 PM; Wed 12 - 1 PM\nCudahy Hall 353\n\n\nTA Help Desk\nTo be determined (TBD)\nTBD\n\n\nLab Section\nNone\nNone",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#ta-information",
    "href": "course-syllabus.html#ta-information",
    "title": "Syllabus",
    "section": "TA Information",
    "text": "TA Information\n\nName: Qishi Zhan\nEmail: qishi.zhan@marquette.edu",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#office-hours",
    "href": "course-syllabus.html#office-hours",
    "title": "Syllabus",
    "section": "Office Hours",
    "text": "Office Hours\n\nMy in-person office hours are TuTh 4:50 - 5:50 PM, and Wed 12 - 1 PM in Cudahy Hall room 353.\nYou are welcome to schedule an online meeting via Microsoft Teams if you need/prefer.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#learning-objectives",
    "href": "course-syllabus.html#learning-objectives",
    "title": "Syllabus",
    "section": "Learning objectives",
    "text": "Learning objectives\nBy the end of the semester, you will be able to…\n\nRepresent and manipulate data in effective ways\nManipulate data using packages/tools and by ad hoc data handling\nUse mathematical, computational and statistical tools to detect patterns and model performance\nUse computational principles and tools to tackle issues addressable by data science\nUse a solid foundation in data science to independently learn new methodologies and technologies in the field of data science",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#prerequisites",
    "href": "course-syllabus.html#prerequisites",
    "title": "Syllabus",
    "section": "Prerequisites",
    "text": "Prerequisites\n\nCOSC 1010 (Intro to Programming) and MATH 4720 (Intro to Statistics), or MATH 2780 (Intro to Regression and Classification).\nProgramming experience is helpful because the course involves doing regression analysis using  programming language.\nThe course will also assume facility with using the internet and a personal computer/laptop. The course involves coding in R and Python using Posit Cloud, a cloud integrated development environment (IDE).\nTalk to me if you are not sure whether or not this is the right course for you.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#e-mail-policy",
    "href": "course-syllabus.html#e-mail-policy",
    "title": "Syllabus",
    "section": "E-mail Policy",
    "text": "E-mail Policy\n\nI will attempt to reply your email quickly, at least within 24 hours.\nExpect a reply on Monday if you send a question during weekends. If you do not receive a response from me within two days, re-send your question/comment in case there was a “mix-up” with email communication (Hope this won’t happen!).\nPlease start your subject line with [math3570] or [cosc3570] followed by a clear description of your question. See an example below.\n\n\n\n\nEmail Subject Line Example\n\n\n\nEmail etiquette is important. Please read this article to learn more about email etiquette.\nI am more than happy to answer your questions about this course or data science/statistics in general. However, with tons of email messages everyday, I may choose NOT to respond to students’ e-mail if\n\nThe student could answer his/her own inquiry by reading the syllabus or information on the course website or D2L.\nThe student is asking for an extra credit opportunity. The answer is “no”.\nThe student is requesting an extension on homework. The answer is “no”.\nThe student is asking for a grade to be raised for no legitimate reason. The answer is “no”.\nThe student is sending an email with no etiquette.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#textbooks",
    "href": "course-syllabus.html#textbooks",
    "title": "Syllabus",
    "section": "Textbooks",
    "text": "Textbooks\n\nNo textbook is required for this course. Course materials are mainly Dr. Yu’s slides. Below are some good references.\n\n(r4ds) R for Data Science (2e) by Hadley Wickham, Mine Çetinkaya-Rundel, and Garrett Grolemund.\n(tmwr) Tidy Modeling with R by Max Kuhn and Julia Silge.\n(py4da) Python for Data Analysis by Wes McKinney.\n(IS) Introduction to Statistics by Cheng-Han Yu. (Good resource for brushing up your basic probability, statistics and simple linear regression knowledge.)",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#grading-policy",
    "href": "course-syllabus.html#grading-policy",
    "title": "Syllabus",
    "section": "Grading Policy",
    "text": "Grading Policy\n\nYour grade is from the following categories and distribution\n\n30% In-class lab exercises and participation.\n30% Homework\n15% Midterm mini project\n25% Final project competition\nExtra credit opportunities\n\nEvery student has to participate (in-person) in the final presentation to pass the course.\nYou will NOT be allowed any extra credit projects/homework/exam to compensate for a poor grade. Everyone is given the same opportunity to do well in this class. I may use class participation to make grade adjustments at the end of the semester.\nThe final grade is based on the grade-percentage conversion Table 1 on the next page. \\([x, y)\\) means greater than or equal to \\(x\\) and less than \\(y\\). For example, 94.1 is in \\([94, 100]\\) and the grade is A and 93.8 is in \\([90, 94)\\) and the grade is A-.\n\n\n\n\nGrade-Percentage Conversion\n\n\nGrade\nPercentage\n\n\n\n\nA\n[94, 100]\n\n\nA-\n[90, 94)\n\n\nB+\n[87, 90)\n\n\nB\n[83, 87)\n\n\nB-\n[80, 83)\n\n\nC+\n[77, 80)\n\n\nC\n[73, 77)\n\n\nC-\n[70, 73)\n\n\nD+\n[65, 70)\n\n\nD\n[60, 65)\n\n\nF\n[0, 60)\n\n\n\n\n\n\nLab exercises\n\nThere are several in-class lab exercises, which are graded as complete/incomplete and used as evidence of attendance and class participation.\nYou are allowed to have one incomplete lab exercise without penalty. Beyond that, 2% grade percentage will be taken off for each missing/incomplete exercise.\n\n\n\n\nHomework\n\nThe homework assignments are individual. You should submit your own work.\nYou may not directly share or discuss answers/code with anyone other than the instructor. But you are welcome to discuss the problems in general and ask for advice.\nHomework will be assigned through GitHub. You need to clone/pull the homework repo into Posit Cloud and work on the Quarto file in the repo. A step-by-step guide will be discussed in class before homework is assigned.\nYou will have at least one week to complete your assignment.\nNo make-up homework for any reason unless you have excused absences.\nIf you miss a homework assignment due to excused absence, the homework percentage will be added to your final project. If you miss more than one assignment, only one assignment percentage can be added to the final project percentage. You get 0% for the other assignment.\n\n\n\nMidterm mini project\n\nYou will be team up to do the midterm mini project.\nMore details about the mini project presentation will be released later.\n\n\n\nFinal project competition\n\nYou will be team up to do the final project. Your project can be in either of the following categories:\n\nData analysis using statistical models or machine learning algorithms\nIntroduce a R or Python package not learned in class, including live demo\nIntroduce a data science tool (visualization, computing, etc) not learned in class, including live demo\nIntroduce a programming language not learned in class for doing data science, including live demo, Julia, SQL, MATLAB, SAS for example.\nWeb development: Shiny website or dashboard, including live demo\n\nDetails about the project will be provided as the course progresses. You must complete the final project and be in class to present it in order to pass this course.\n\n\n\n\n\nThe final project presentation is on Thursday, May 1, 2 PM and Monday, May 5, 10:30 AM - 12:30 PM.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#generative-ai-and-sharingreusing-code-policy",
    "href": "course-syllabus.html#generative-ai-and-sharingreusing-code-policy",
    "title": "Syllabus",
    "section": "Generative AI and Sharing/Reusing Code Policy",
    "text": "Generative AI and Sharing/Reusing Code Policy\n\nGenerative AI \n\nYou are responsible for the content of all work submitted for this course. You may use generative AI tools such as ChatGPT or DALL-E to generate a first draft of text for your assignments, provided that this use is documented and cited.\n\n\n\nSharing/Reusing Code\n\nUnless explicitly stated otherwise, you may make use of any online resources, but you must explicitly cite where you obtained any code you directly use or use as inspiration in your solutions.\nAny recycled code that is discovered and is not explicitly cited will be treated as plagiarism, regardless of source.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#university-and-college-policies",
    "href": "course-syllabus.html#university-and-college-policies",
    "title": "Syllabus",
    "section": "University and college policies",
    "text": "University and college policies\nAs a student in this course, you have agreed to comply with Marquette undergraduate policies and regulations.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#accommodation",
    "href": "course-syllabus.html#accommodation",
    "title": "Syllabus",
    "section": "Accommodation",
    "text": "Accommodation\nIf you need to request accommodations, or modify existing accommodations that address disability-related needs, please contact Disability Service.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#important-dates",
    "href": "course-syllabus.html#important-dates",
    "title": "Syllabus",
    "section": "Important dates",
    "text": "Important dates\n\nJan 21: Last day to add/swap/drop\nMar 10-16: Spring break\nMar 11: Midterm grade submission\nApr 11: Withdrawal deadline\nApr 17 - Apr 20: Easter break\nMay 3: Last day of class\nMay 1: Final project presentation I\nMay 5: Final project presentation II\nMay 13: Final grade submission\n\nClick here for the full Marquette academic calendar.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "exercise/lab15-dplyr.html",
    "href": "exercise/lab15-dplyr.html",
    "title": "Lab 15: dplyr",
    "section": "",
    "text": "Note\n\n\n\n\n\n\nIn lab.qmd ## Lab 15 section, import the murders.csv data and\n\nAdd (mutate) the variable rate = total / population * 100000 to murders data (as I did).\nFilter states that are in region Northeast or West and their murder rate is less than 1.\nSelect variables state, region, rate.\n\n\nPrint the output table after you do 1. to 3., and save it as object my_states.\nGroup my_states by region. Then summarize data by creating variables avg and stdev that compute the mean and standard deviation of rate.\nArrange the summarized table by avg.\n\n\n_______ &lt;- _______ |&gt; \n    mutate(_______) |&gt; \n    filter(_______) |&gt; \n    select(_______)\n\n_______ |&gt;  \n    group_by(______) |&gt; \n    summarize(______) |&gt; \n    arrange(_______)\n\n\n\n          state    region      rate\n1        Hawaii      West 0.5145920\n2         Idaho      West 0.7655102\n3         Maine Northeast 0.8280881\n4 New Hampshire Northeast 0.3798036\n5        Oregon      West 0.9396843\n6          Utah      West 0.7959810\n7       Vermont Northeast 0.3196211\n8       Wyoming      West 0.8871131\n\n\n# A tibble: 2 × 3\n  region      avg std_dev\n  &lt;fct&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 West      0.781   0.164\n2 Northeast 0.509   0.278"
  },
  {
    "objectID": "exercise/lab00-git.html",
    "href": "exercise/lab00-git.html",
    "title": "Lab Exercise: Git/GitHub",
    "section": "",
    "text": "Note"
  },
  {
    "objectID": "exercise/lab00-git.html#connect-posit-cloud-and-github-step-1",
    "href": "exercise/lab00-git.html#connect-posit-cloud-and-github-step-1",
    "title": "Lab Exercise: Git/GitHub",
    "section": "Connect Posit Cloud and GitHub: Step 1",
    "text": "Connect Posit Cloud and GitHub: Step 1\n\nPosit Cloud cannot recognize your GitHub account unless you connect them each other.\nIn Posit Cloud, click on your name on the top-right corner to open the right menu.\nClick on Authentication."
  },
  {
    "objectID": "exercise/lab00-git.html#connect-posit-cloud-and-github-step-2",
    "href": "exercise/lab00-git.html#connect-posit-cloud-and-github-step-2",
    "title": "Lab Exercise: Git/GitHub",
    "section": "Connect Posit Cloud and GitHub: Step 2",
    "text": "Connect Posit Cloud and GitHub: Step 2\n\nIn the Authentication window, check the box for Enabled.\n\n\n\n\n\n\n\n\n\n\nWhen check Enabled, will jump to GitHub page shown in the next."
  },
  {
    "objectID": "exercise/lab00-git.html#connect-posit-cloud-and-github-step-3",
    "href": "exercise/lab00-git.html#connect-posit-cloud-and-github-step-3",
    "title": "Lab Exercise: Git/GitHub",
    "section": "Connect Posit Cloud and GitHub: Step 3",
    "text": "Connect Posit Cloud and GitHub: Step 3\n\nFor your GitHub page, click on the green box that says “Authorize posit-hosted”."
  },
  {
    "objectID": "exercise/lab00-git.html#connect-posit-cloud-and-github-step-4",
    "href": "exercise/lab00-git.html#connect-posit-cloud-and-github-step-4",
    "title": "Lab Exercise: Git/GitHub",
    "section": "Connect Posit Cloud and GitHub: Step 4",
    "text": "Connect Posit Cloud and GitHub: Step 4\n\nBack to the Authentication of Posit Cloud, check Private repo access also enabled.\nMake sure math3570-s25 shows up under Organization access.\nClick on Grant.\nClick on the green box “Authorize posit-hosted”.\n\n\n\n\n\n\n\n\n\n\nWhen check Private repo access also enabled, will jump to GitHub page as shown."
  },
  {
    "objectID": "exercise/lab00-git.html#connect-posit-cloud-and-github-step-5",
    "href": "exercise/lab00-git.html#connect-posit-cloud-and-github-step-5",
    "title": "Lab Exercise: Git/GitHub",
    "section": "Connect Posit Cloud and GitHub: Step 5",
    "text": "Connect Posit Cloud and GitHub: Step 5\n\nOnce you’re done, both of these boxes should be checked."
  },
  {
    "objectID": "exercise/lab00-git.html#connect-posit-cloud-and-github-step-6",
    "href": "exercise/lab00-git.html#connect-posit-cloud-and-github-step-6",
    "title": "Lab Exercise: Git/GitHub",
    "section": "Connect Posit Cloud and GitHub: Step 6",
    "text": "Connect Posit Cloud and GitHub: Step 6\n\nConfirm that you’ve linked up your GitHub and Posit Cloud accounts GitHub settings &gt; Applications. Should see Posit Cloud listed as an authorized app under Authorized OAuth Apps.\n\n\n\n\n\n\n\n\n\n\nIf you see RStudio is under the Authorized Apps, congratulations! Your RStudio and GitHub are now linked together!"
  },
  {
    "objectID": "exercise/lab00-git.html#github-to-posit-cloud-step-1",
    "href": "exercise/lab00-git.html#github-to-posit-cloud-step-1",
    "title": "Lab Exercise: Git/GitHub",
    "section": "GitHub to Posit Cloud: Step 1",
    "text": "GitHub to Posit Cloud: Step 1\n\nEach of your assignments will begin with the following steps.\nGo to the repo named hw00-yourusername I created for you."
  },
  {
    "objectID": "exercise/lab00-git.html#github-to-posit-cloud-step-2",
    "href": "exercise/lab00-git.html#github-to-posit-cloud-step-2",
    "title": "Lab Exercise: Git/GitHub",
    "section": "GitHub to Posit Cloud: Step 2",
    "text": "GitHub to Posit Cloud: Step 2\n\nOn GitHub,\n\nclick on the green Code button, select HTTPS.\nclick on the clipboard icon on the right to copy the repo URL, such as https://github.com/math3570-s25/hw00-chenghanyu.git"
  },
  {
    "objectID": "exercise/lab00-git.html#github-to-posit-cloud-step-3",
    "href": "exercise/lab00-git.html#github-to-posit-cloud-step-3",
    "title": "Lab Exercise: Git/GitHub",
    "section": "GitHub to Posit Cloud: Step 3",
    "text": "GitHub to Posit Cloud: Step 3\n\nGo to Posit Cloud and into the course workspace 2025-spring-math-3570.\nCreate a New Project from Git Repo.\n\n\n\n\n\n\n\n\n\n\nYou will need to click on the down arrow next to the New Project button to see this option."
  },
  {
    "objectID": "exercise/lab00-git.html#github-to-posit-cloud-step-4",
    "href": "exercise/lab00-git.html#github-to-posit-cloud-step-4",
    "title": "Lab Exercise: Git/GitHub",
    "section": "GitHub to Posit Cloud: Step 4",
    "text": "GitHub to Posit Cloud: Step 4\n\nCopy and paste the URL of your assignment repo into the dialog box.\nHit OK, and you’re good to go!"
  },
  {
    "objectID": "exercise/lab00-git.html#github-to-posit-cloud-step-5",
    "href": "exercise/lab00-git.html#github-to-posit-cloud-step-5",
    "title": "Lab Exercise: Git/GitHub",
    "section": "GitHub to Posit Cloud: Step 5",
    "text": "GitHub to Posit Cloud: Step 5\n\nClick hw00-yourusername to do your assignment in Posit Cloud!\n\n\n\n\n\n\n\n\n\n\n\nDone! We learned the entire process of cloning a repo on GitHub to Posit Cloud as a project.\nNext, we’ll see how to keep your revision record (commit) and send (push) the latest revised version of your work from Posit Cloud to GitHub!"
  },
  {
    "objectID": "exercise/lab00-git.html#personal-access-token-pat-step-1",
    "href": "exercise/lab00-git.html#personal-access-token-pat-step-1",
    "title": "Lab Exercise: Git/GitHub",
    "section": "Personal Access Token (PAT): Step 1",
    "text": "Personal Access Token (PAT): Step 1\n\nGitHub has removed the support for Password Authentication for Git operations.\nBefore we can send our work in Posit Cloud to GitHub, we need Personal Access Token (PAT)\nSettings &gt; Developer settings\n\n\n\n\n\n\n\n\n\n\nGitHub has removed the support for Password Authentication for Git operations for more safety from 08/13/2021."
  },
  {
    "objectID": "exercise/lab00-git.html#personal-access-token-pat-step-2",
    "href": "exercise/lab00-git.html#personal-access-token-pat-step-2",
    "title": "Lab Exercise: Git/GitHub",
    "section": "Personal Access Token (PAT): Step 2",
    "text": "Personal Access Token (PAT): Step 2"
  },
  {
    "objectID": "exercise/lab00-git.html#personal-access-token-pat-step-3",
    "href": "exercise/lab00-git.html#personal-access-token-pat-step-3",
    "title": "Lab Exercise: Git/GitHub",
    "section": "Personal Access Token (PAT): Step 3",
    "text": "Personal Access Token (PAT): Step 3"
  },
  {
    "objectID": "exercise/lab00-git.html#personal-access-token-pat-step-4",
    "href": "exercise/lab00-git.html#personal-access-token-pat-step-4",
    "title": "Lab Exercise: Git/GitHub",
    "section": "Personal Access Token (PAT): Step 4",
    "text": "Personal Access Token (PAT): Step 4"
  },
  {
    "objectID": "exercise/lab00-git.html#personal-access-token-pat-step-5",
    "href": "exercise/lab00-git.html#personal-access-token-pat-step-5",
    "title": "Lab Exercise: Git/GitHub",
    "section": "Personal Access Token (PAT): Step 5",
    "text": "Personal Access Token (PAT): Step 5\n\nCopy and paste your PAT to a secrete and safe space!!"
  },
  {
    "objectID": "exercise/lab00-git.html#posit-cloud-to-github-step-1---edit-your-file",
    "href": "exercise/lab00-git.html#posit-cloud-to-github-step-1---edit-your-file",
    "title": "Lab Exercise: Git/GitHub",
    "section": "Posit Cloud to GitHub: Step 1 - Edit your file",
    "text": "Posit Cloud to GitHub: Step 1 - Edit your file\n\nOpen the quarto file hw-00-test.qmd, in YAML change the author to your name.\nClick Render to generate your beautiful document. (If asked to install any packages, please do!)"
  },
  {
    "objectID": "exercise/lab00-git.html#posit-cloud-to-github-step-2---commit-changes",
    "href": "exercise/lab00-git.html#posit-cloud-to-github-step-2---commit-changes",
    "title": "Lab Exercise: Git/GitHub",
    "section": "Posit Cloud to GitHub: Step 2 - Commit changes",
    "text": "Posit Cloud to GitHub: Step 2 - Commit changes\n\nGo to the Git tab in your RStudio.\nClick on Commit. This shows you the difference between the last committed state of the document and its current state that includes your changes.\nCheck Staged box to add files to be committed.\nWrite “Update author’s name” in the Commit message box and hit Commit."
  },
  {
    "objectID": "exercise/lab00-git.html#posit-cloud-to-github-step-3---push-changes",
    "href": "exercise/lab00-git.html#posit-cloud-to-github-step-3---push-changes",
    "title": "Lab Exercise: Git/GitHub",
    "section": "Posit Cloud to GitHub: Step 3 - Push changes",
    "text": "Posit Cloud to GitHub: Step 3 - Push changes\n\nWe’ve made an update and committed this change locally.\nIt’s time to push the changes to your repo on GitHub, so that others (Dr. Yu) can see your changes.\nClick on Push.\nIn the prompted dialogue box, enter your GitHub user name, and your password (PAT)."
  },
  {
    "objectID": "exercise/lab00-git.html#posit-cloud-to-github-step-3---updated-repo",
    "href": "exercise/lab00-git.html#posit-cloud-to-github-step-3---updated-repo",
    "title": "Lab Exercise: Git/GitHub",
    "section": "Posit Cloud to GitHub: Step 3 - Updated Repo",
    "text": "Posit Cloud to GitHub: Step 3 - Updated Repo\n\nBack to your GitHub repo and refresh it.\nThe online repo is now synced with your local project in Posit Cloud."
  },
  {
    "objectID": "exercise/lab00-git.html#resources",
    "href": "exercise/lab00-git.html#resources",
    "title": "Lab Exercise: Git/GitHub",
    "section": "Resources",
    "text": "Resources\n\n\n\nCreate a personal access token (PAT)\nTwo-factor authentication\nGit hands-on session within RStudio\nHappy Git and GitHub for the useR\nHappier version control with Git and GitHub"
  },
  {
    "objectID": "exercise/lab02-quarto.html",
    "href": "exercise/lab02-quarto.html",
    "title": "Lab 02: Quarto File",
    "section": "",
    "text": "Note\n\n\n\n\n\n\n\nGo to your GitHub repo lab-yourusername. Clone it to your Posit Cloud as a project in 2025-Spring-Math-3570 workspace.\nOpen the file lab.qmd.\nChange author in YAML.\nClick on  or Ctrl/Cmd + Shift + K to produce a HTML document.\nHow can we show the current date every time we compile the file? [Hint:] Check your hw00. Compile your document and make sure the date shows up.\nHow do we hide the code so that the document is shorter? Describe it in ## Lab 2: Quarto\nOnce done, commit with message “02-quarto” and push your version to GitHub."
  },
  {
    "objectID": "exercise/lab19-ci.html",
    "href": "exercise/lab19-ci.html",
    "title": "Lab 19: Confidence Interval",
    "section": "",
    "text": "Note\n\n\n\n\n\n\nIn lab.qmd ## Lab 19 section,\n\nRun the code I give you for simulating 100 \\(95\\%\\) CIs. Change the random generator seed to another number you like.\n\n\nset.seed(a number you like) Birthday? Lucky number?\n\n\nHow many CIs do not cover the true mean \\(\\mu\\)?\n\n\n\n\n\n\n\n\n\n\n```"
  },
  {
    "objectID": "exercise/lab03-markdown.html",
    "href": "exercise/lab03-markdown.html",
    "title": "Lab 03: Markdown",
    "section": "",
    "text": "Note\n\n\n\n\n\n\n\nBack to your lab.qmd. In ## Lab 3: Markdown section, add a self-introduction paragraph containing a header, bold and italic text.\nAdd another paragraph that contains\n\nlisted items\na hyperlink\na blockquote\nmath expression\n\nOnce done, commit with message “03-markdown” and push it to GitHub."
  },
  {
    "objectID": "exercise/lab08-tibble.html",
    "href": "exercise/lab08-tibble.html",
    "title": "Lab 08: Tibbles and Pipes",
    "section": "",
    "text": "Note\n\n\n\n\n\n\nIn lab.qmd ## Lab 8 section,\n\nCompare and contrast the following operations on a data.frame and equivalent tibble. What are the differences?\n\n\ndf &lt;- data.frame(abc = 1:2, \n                 xyz = c(\"a\", \"b\"))\n# list method\ndf$x\ndf[[2]]\ndf[\"xyz\"]\ndf[c(\"abc\", \"xyz\")]\n# matrix method\ndf[, 2]\ndf[, \"xyz\"]\ndf[, c(\"abc\", \"xyz\")]\n\n\ntib &lt;- tibble(abc = 1:2, \n              xyz = c(\"a\", \"b\"))\n# list method\ntib$x\ntib[[2]]\ntib[\"xyz\"]\ntib[c(\"abc\", \"xyz\")]\n# matrix method\ntib[, 2]\ntib[, \"xyz\"]\ntib[, c(\"abc\", \"xyz\")]\n\n\nUse |&gt; to first select last 12 rows of iris data set using tail(), then provides summary statistics on its columns using summary()."
  },
  {
    "objectID": "exercise/lab09-numpy.html",
    "href": "exercise/lab09-numpy.html",
    "title": "Lab 09: NumPy and pandas",
    "section": "",
    "text": "Note\n\n\n\n\n\n\nIn lab.qmd ## Lab 9 section, create a Python pandas.DataFrame equivalent to the R tibble\n\ntibble(x = 1:5, y = 5:1, z = LETTERS[1:5])\n\n# A tibble: 5 × 3\n      x     y z    \n  &lt;int&gt; &lt;int&gt; &lt;chr&gt;\n1     1     5 A    \n2     2     4 B    \n3     3     3 C    \n4     4     2 D    \n5     5     1 E    \n\n\n\nimport numpy as np\nimport pandas as pd\nimport string\nlist(string.ascii_uppercase)\ndic = {'__': ____________, \n       '__': reversed(____________),\n       '__': list(string.ascii_uppercase)[______]}\npd._____________(dic)"
  },
  {
    "objectID": "exercise/lab14-interactive.html",
    "href": "exercise/lab14-interactive.html",
    "title": "Lab 14: plotly",
    "section": "",
    "text": "Note\n\n\n\n\n\n\nIn lab.qmd ## Lab 14 section,\n\nLoad tidyverse and plotly and the loans.csv data.\nGenerate a plot using plotly. An example is shown below. Welcome to create a more fancy one!"
  },
  {
    "objectID": "exercise/lab01-rscript.html",
    "href": "exercise/lab01-rscript.html",
    "title": "Lab-01: Running R Script",
    "section": "",
    "text": "Note\n\n\n\n\n\n\n\nLoad R package ggplot2 into your Posit Cloud.\n\n\n## install the package if you haven't!\n________(ggplot2)\n\n\nCreate a R script named lab01-run-script.R in your 3570-project.\nCopy and paste the code below into the script, and save it.\n\n\nbar &lt;- ggplot(data = diamonds) + \n  geom_bar(mapping = aes(x = cut, fill = cut), \n           show.legend = FALSE, width = 1) + \n  theme(aspect.ratio = 1) +\n  labs(x = NULL, y = NULL)\nbar + coord_flip()\nbar + coord_polar()\n\n\nSource the script. A pretty plot showing up?!"
  },
  {
    "objectID": "exercise/lab-sol-s25-midterm.html",
    "href": "exercise/lab-sol-s25-midterm.html",
    "title": "In-Class Lab Exercises",
    "section": "",
    "text": "x &lt;- 4; y &lt;- 3\nbar &lt;- ggplot(data = diamonds) + \n  geom_bar(mapping = aes(x = cut, fill = cut), \n           show.legend = FALSE, width = 1) + \n  theme(aspect.ratio = 1) +\n  labs(x = NULL, y = NULL)\nbar + coord_flip()\n\n\n\n\n\n\n\nbar + coord_polar()"
  },
  {
    "objectID": "exercise/lab-sol-s25-midterm.html#lab-1-running-r-script",
    "href": "exercise/lab-sol-s25-midterm.html#lab-1-running-r-script",
    "title": "In-Class Lab Exercises",
    "section": "",
    "text": "x &lt;- 4; y &lt;- 3\nbar &lt;- ggplot(data = diamonds) + \n  geom_bar(mapping = aes(x = cut, fill = cut), \n           show.legend = FALSE, width = 1) + \n  theme(aspect.ratio = 1) +\n  labs(x = NULL, y = NULL)\nbar + coord_flip()\n\n\n\n\n\n\n\nbar + coord_polar()"
  },
  {
    "objectID": "exercise/lab-sol-s25-midterm.html#lab-2-quarto",
    "href": "exercise/lab-sol-s25-midterm.html#lab-2-quarto",
    "title": "In-Class Lab Exercises",
    "section": "Lab 2: Quarto",
    "text": "Lab 2: Quarto\nBriefly describe how we produce a pdf."
  },
  {
    "objectID": "exercise/lab-sol-s25-midterm.html#lab-3-markdown",
    "href": "exercise/lab-sol-s25-midterm.html#lab-3-markdown",
    "title": "In-Class Lab Exercises",
    "section": "Lab 3: Markdown",
    "text": "Lab 3: Markdown\nHello everyone, I am Cheng-Han Yu, an assistant professor at Marquette University. I love data science!\nMy main research interests include\n\nBayesian spatiotemporal modeling\n\nMCMC\nVariational Inference\n\nNeuroimaging\n\nfMRI\nEEG/ERP\n\nR programming\n\nMy favorite quote is\n\nAll models are wrong, but some are useful. George Box\n\nHere I write a simple math equation \\(\\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a}\\)."
  },
  {
    "objectID": "exercise/lab-sol-s25-midterm.html#lab-4-code-chunk",
    "href": "exercise/lab-sol-s25-midterm.html#lab-4-code-chunk",
    "title": "In-Class Lab Exercises",
    "section": "Lab 4: Code Chunk",
    "text": "Lab 4: Code Chunk\n\n# include image\nknitr::include_graphics(\"https://raw.githubusercontent.com/rstudio/hex-stickers/master/PNG/ggplot2.png\")\n\n\n\n\n\n\n\n\n\n# include plot\nplot(x = mtcars$disp, y = mtcars$mpg)\n\n\n\n\nMPG vs. Displacement\n\n\n\n\n\n# show dataset `mtcars`\nknitr::kable(mtcars, caption = \"A knitr kable table of mtcars data set\")\n\n\nA knitr kable table of mtcars data set\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmpg\ncyl\ndisp\nhp\ndrat\nwt\nqsec\nvs\nam\ngear\ncarb\n\n\n\n\nMazda RX4\n21.0\n6\n160.0\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\nMazda RX4 Wag\n21.0\n6\n160.0\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\nDatsun 710\n22.8\n4\n108.0\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\nHornet 4 Drive\n21.4\n6\n258.0\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\nHornet Sportabout\n18.7\n8\n360.0\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\nValiant\n18.1\n6\n225.0\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n\n\nDuster 360\n14.3\n8\n360.0\n245\n3.21\n3.570\n15.84\n0\n0\n3\n4\n\n\nMerc 240D\n24.4\n4\n146.7\n62\n3.69\n3.190\n20.00\n1\n0\n4\n2\n\n\nMerc 230\n22.8\n4\n140.8\n95\n3.92\n3.150\n22.90\n1\n0\n4\n2\n\n\nMerc 280\n19.2\n6\n167.6\n123\n3.92\n3.440\n18.30\n1\n0\n4\n4\n\n\nMerc 280C\n17.8\n6\n167.6\n123\n3.92\n3.440\n18.90\n1\n0\n4\n4\n\n\nMerc 450SE\n16.4\n8\n275.8\n180\n3.07\n4.070\n17.40\n0\n0\n3\n3\n\n\nMerc 450SL\n17.3\n8\n275.8\n180\n3.07\n3.730\n17.60\n0\n0\n3\n3\n\n\nMerc 450SLC\n15.2\n8\n275.8\n180\n3.07\n3.780\n18.00\n0\n0\n3\n3\n\n\nCadillac Fleetwood\n10.4\n8\n472.0\n205\n2.93\n5.250\n17.98\n0\n0\n3\n4\n\n\nLincoln Continental\n10.4\n8\n460.0\n215\n3.00\n5.424\n17.82\n0\n0\n3\n4\n\n\nChrysler Imperial\n14.7\n8\n440.0\n230\n3.23\n5.345\n17.42\n0\n0\n3\n4\n\n\nFiat 128\n32.4\n4\n78.7\n66\n4.08\n2.200\n19.47\n1\n1\n4\n1\n\n\nHonda Civic\n30.4\n4\n75.7\n52\n4.93\n1.615\n18.52\n1\n1\n4\n2\n\n\nToyota Corolla\n33.9\n4\n71.1\n65\n4.22\n1.835\n19.90\n1\n1\n4\n1\n\n\nToyota Corona\n21.5\n4\n120.1\n97\n3.70\n2.465\n20.01\n1\n0\n3\n1\n\n\nDodge Challenger\n15.5\n8\n318.0\n150\n2.76\n3.520\n16.87\n0\n0\n3\n2\n\n\nAMC Javelin\n15.2\n8\n304.0\n150\n3.15\n3.435\n17.30\n0\n0\n3\n2\n\n\nCamaro Z28\n13.3\n8\n350.0\n245\n3.73\n3.840\n15.41\n0\n0\n3\n4\n\n\nPontiac Firebird\n19.2\n8\n400.0\n175\n3.08\n3.845\n17.05\n0\n0\n3\n2\n\n\nFiat X1-9\n27.3\n4\n79.0\n66\n4.08\n1.935\n18.90\n1\n1\n4\n1\n\n\nPorsche 914-2\n26.0\n4\n120.3\n91\n4.43\n2.140\n16.70\n0\n1\n5\n2\n\n\nLotus Europa\n30.4\n4\n95.1\n113\n3.77\n1.513\n16.90\n1\n1\n5\n2\n\n\nFord Pantera L\n15.8\n8\n351.0\n264\n4.22\n3.170\n14.50\n0\n1\n5\n4\n\n\nFerrari Dino\n19.7\n6\n145.0\n175\n3.62\n2.770\n15.50\n0\n1\n5\n6\n\n\nMaserati Bora\n15.0\n8\n301.0\n335\n3.54\n3.570\n14.60\n0\n1\n5\n8\n\n\nVolvo 142E\n21.4\n4\n121.0\n109\n4.11\n2.780\n18.60\n1\n1\n4\n2\n\n\n\n\n\nThere are 11 variables in the mtcars data set.\nAnswer to the questions.\n\nradius = 5\n\nThe radius of the circle is {python} print(radius)"
  },
  {
    "objectID": "exercise/lab-sol-s25-midterm.html#lab-5-r-data-type-summary",
    "href": "exercise/lab-sol-s25-midterm.html#lab-5-r-data-type-summary",
    "title": "In-Class Lab Exercises",
    "section": "Lab 5: R Data Type Summary",
    "text": "Lab 5: R Data Type Summary\n\nv1 &lt;- c(3, 8, 4, 5)\nfac &lt;- factor(c(\"bad\", \"neutral\", \"good\"))\nx_lst &lt;- list(idx = 1:3, \n              \"a\", \n              c(TRUE, FALSE))\nmat &lt;- matrix(data = 1:6, \n              nrow = 3, \n              ncol = 2)\ndf &lt;- data.frame(age = c(19, 21, 40), \n                 gender = c(\"m\",\"f\", \"m\"))\nvec &lt;- c(type = typeof(v1), class = class(v1))\nfac &lt;- c(type = typeof(fac), class = class(fac))\nlst &lt;- c(type = typeof(x_lst), class = class(x_lst))\nmat &lt;- c(type = typeof(mat), class = class(mat))\ndf &lt;- c(type = typeof(df), class = class(df))\nlist(vector = vec,\n     factor = fac,\n     list = lst,\n     matrix = mat,\n     dataframe = df)\n\n$vector\n     type     class \n \"double\" \"numeric\" \n\n$factor\n     type     class \n\"integer\"  \"factor\" \n\n$list\n  type  class \n\"list\" \"list\" \n\n$matrix\n     type    class1    class2 \n\"integer\"  \"matrix\"   \"array\" \n\n$dataframe\n        type        class \n      \"list\" \"data.frame\""
  },
  {
    "objectID": "exercise/lab-sol-s25-midterm.html#lab-6-python-data-structure",
    "href": "exercise/lab-sol-s25-midterm.html#lab-6-python-data-structure",
    "title": "In-Class Lab Exercises",
    "section": "Lab 6: Python Data Structure",
    "text": "Lab 6: Python Data Structure\n\nx_lst &lt;- list(idx = 1:3, \n              word = \"a\", \n              bool = c(TRUE, FALSE))\n\n\npy_lst = [[1, 2, 3], \"a\", [True, False]]\npy_lst\n\n[[1, 2, 3], 'a', [True, False]]\n\npy_dic = {\"idx\": [1, 2, 3], \"word\": \"a\", \"bool\": [True, False]}\npy_dic\n\n{'idx': [1, 2, 3], 'word': 'a', 'bool': [True, False]}"
  },
  {
    "objectID": "exercise/lab-sol-s25-midterm.html#lab-7-plotting",
    "href": "exercise/lab-sol-s25-midterm.html#lab-7-plotting",
    "title": "In-Class Lab Exercises",
    "section": "Lab 7: Plotting",
    "text": "Lab 7: Plotting\n\nplot(mtcars$mpg, mtcars$wt, \n     col = 4, pch = 8, cex = 2,\n     xlab = \"MPG\", ylab = \"Wt. (1000 lbs)\", \n     main = \"MPG vs. Weight\")\n\n\n\n\n\n\n\nhist(mtcars$qsec, breaks = 20, border = \"#FFCC00\", \n     col = 2, main = \"Histogram of 1/4 mile time\")\n\n\n\n\n\n\n\nboxplot(mpg ~ gear, \n        data = mtcars, \n        col = 2:4, \n        las = 1, \n        horizontal = TRUE,\n        xlab = \"Miles per gallon\", \n        ylab = \"Number of forward gears\")\n\n\n\n\n\n\n\n\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nmtcars = pd.read_csv('./data/mtcars.csv')\nmtcars\n\n     mpg  cyl   disp   hp  drat     wt   qsec  vs  am  gear  carb\n0   21.0    6  160.0  110  3.90  2.620  16.46   0   1     4     4\n1   21.0    6  160.0  110  3.90  2.875  17.02   0   1     4     4\n2   22.8    4  108.0   93  3.85  2.320  18.61   1   1     4     1\n3   21.4    6  258.0  110  3.08  3.215  19.44   1   0     3     1\n4   18.7    8  360.0  175  3.15  3.440  17.02   0   0     3     2\n5   18.1    6  225.0  105  2.76  3.460  20.22   1   0     3     1\n6   14.3    8  360.0  245  3.21  3.570  15.84   0   0     3     4\n7   24.4    4  146.7   62  3.69  3.190  20.00   1   0     4     2\n8   22.8    4  140.8   95  3.92  3.150  22.90   1   0     4     2\n9   19.2    6  167.6  123  3.92  3.440  18.30   1   0     4     4\n10  17.8    6  167.6  123  3.92  3.440  18.90   1   0     4     4\n11  16.4    8  275.8  180  3.07  4.070  17.40   0   0     3     3\n12  17.3    8  275.8  180  3.07  3.730  17.60   0   0     3     3\n13  15.2    8  275.8  180  3.07  3.780  18.00   0   0     3     3\n14  10.4    8  472.0  205  2.93  5.250  17.98   0   0     3     4\n15  10.4    8  460.0  215  3.00  5.424  17.82   0   0     3     4\n16  14.7    8  440.0  230  3.23  5.345  17.42   0   0     3     4\n17  32.4    4   78.7   66  4.08  2.200  19.47   1   1     4     1\n18  30.4    4   75.7   52  4.93  1.615  18.52   1   1     4     2\n19  33.9    4   71.1   65  4.22  1.835  19.90   1   1     4     1\n20  21.5    4  120.1   97  3.70  2.465  20.01   1   0     3     1\n21  15.5    8  318.0  150  2.76  3.520  16.87   0   0     3     2\n22  15.2    8  304.0  150  3.15  3.435  17.30   0   0     3     2\n23  13.3    8  350.0  245  3.73  3.840  15.41   0   0     3     4\n24  19.2    8  400.0  175  3.08  3.845  17.05   0   0     3     2\n25  27.3    4   79.0   66  4.08  1.935  18.90   1   1     4     1\n26  26.0    4  120.3   91  4.43  2.140  16.70   0   1     5     2\n27  30.4    4   95.1  113  3.77  1.513  16.90   1   1     5     2\n28  15.8    8  351.0  264  4.22  3.170  14.50   0   1     5     4\n29  19.7    6  145.0  175  3.62  2.770  15.50   0   1     5     6\n30  15.0    8  301.0  335  3.54  3.570  14.60   0   1     5     8\n31  21.4    4  121.0  109  4.11  2.780  18.60   1   1     4     2\n\nplt.scatter(x = mtcars.mpg, \n            y = mtcars.wt, \n            color = \"r\")\nplt.xlabel(\"Miles per gallon\")\nplt.ylabel(\"Weight\")\nplt.title(\"Scatter plot\")\nplt.show()\n\n\n\n\n\n\n\nplt.clf()\n\n\n\n\n\n\n\n\n\nplt.hist(mtcars.qsec, \n         bins = 19, \n         color=\"#003366\",\n         edgecolor=\"#FFCC00\")\nplt.xlabel(\"1/4 mile time\")\nplt.title(\"Histogram of 1/4 mile time\")\nplt.show()"
  },
  {
    "objectID": "exercise/lab-sol-s25-midterm.html#lab-8-tibbles-and-pipes",
    "href": "exercise/lab-sol-s25-midterm.html#lab-8-tibbles-and-pipes",
    "title": "In-Class Lab Exercises",
    "section": "Lab 8: Tibbles and Pipes",
    "text": "Lab 8: Tibbles and Pipes\n\ndf &lt;- data.frame(abc = 1:2, \n                 xyz = c(\"a\", \"b\"))\n# list method\ndf$x\n\n[1] \"a\" \"b\"\n\ndf[[2]]\n\n[1] \"a\" \"b\"\n\ndf[\"xyz\"]\n\n  xyz\n1   a\n2   b\n\ndf[c(\"abc\", \"xyz\")]\n\n  abc xyz\n1   1   a\n2   2   b\n\n# matrix method\ndf[, 2]\n\n[1] \"a\" \"b\"\n\ndf[, \"xyz\"]\n\n[1] \"a\" \"b\"\n\ndf[, c(\"abc\", \"xyz\")]\n\n  abc xyz\n1   1   a\n2   2   b\n\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ lubridate 1.9.3     ✔ tibble    3.2.1\n✔ purrr     1.0.2     ✔ tidyr     1.3.1\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ntib &lt;- tibble(abc = 1:2, \n              xyz = c(\"a\", \"b\"))\n# list method\ntib$x\n\nWarning: Unknown or uninitialised column: `x`.\n\n\nNULL\n\ntib[[2]]\n\n[1] \"a\" \"b\"\n\ntib[\"xyz\"]\n\n# A tibble: 2 × 1\n  xyz  \n  &lt;chr&gt;\n1 a    \n2 b    \n\ntib[c(\"abc\", \"xyz\")]\n\n# A tibble: 2 × 2\n    abc xyz  \n  &lt;int&gt; &lt;chr&gt;\n1     1 a    \n2     2 b    \n\n# matrix method\ntib[, 2]\n\n# A tibble: 2 × 1\n  xyz  \n  &lt;chr&gt;\n1 a    \n2 b    \n\ntib[, \"xyz\"]\n\n# A tibble: 2 × 1\n  xyz  \n  &lt;chr&gt;\n1 a    \n2 b    \n\ntib[, c(\"abc\", \"xyz\")]\n\n# A tibble: 2 × 2\n    abc xyz  \n  &lt;int&gt; &lt;chr&gt;\n1     1 a    \n2     2 b    \n\n\nExplain their differences.\nWith data.frames,\n\nThe $ operator will match any column name that starts with the name following it. Since there is a column named xyz, the expression df$x will be expanded to df$xyz. This behavior of the $ operator saves a few keystrokes, but it can result in accidentally using a different column than you thought you were using.\n\nWith [ the type of object that is returned differs on the number of columns. If it is one column, it won’t return a data.frame, but instead will return a vector. With more than one column, then it will return a data.frame. This is fine if you know what you are passing in, but suppose you did df[ , vars] where vars was a variable. Then what that code does depends on length(vars) and you’d have to write code to account for those situations or risk bugs.\n\nFor tibbles,\n\nWhen using the matrix subsetting method, a tibble always return a tibble.\n\n\nWhen using $ to grab an element, tibbles never do partial matching.\n\n\n[] always returns another tibble, regardless of list or matrix subsetting method.\n\n\n$ and [[]] return a vector.\n\n\nTibbles never do partial matching and name “x” cannot be recognized.\n\n\nWhat does tibble::enframe() do? Try enframe(c(a = 1, b = 2, c = 3)). Check ?enframe for more details.\nThe function tibble::enframe() converts named vectors to a data frame with names and values\n\n\niris |&gt; tail(n = 12) |&gt; summary()\n\n  Sepal.Length    Sepal.Width     Petal.Length    Petal.Width   \n Min.   :5.800   Min.   :2.500   Min.   :4.800   Min.   :1.800  \n 1st Qu.:6.150   1st Qu.:3.000   1st Qu.:5.100   1st Qu.:1.900  \n Median :6.600   Median :3.050   Median :5.200   Median :2.200  \n Mean   :6.450   Mean   :3.033   Mean   :5.292   Mean   :2.133  \n 3rd Qu.:6.725   3rd Qu.:3.125   3rd Qu.:5.450   3rd Qu.:2.300  \n Max.   :6.900   Max.   :3.400   Max.   :5.900   Max.   :2.500  \n       Species  \n setosa    : 0  \n versicolor: 0  \n virginica :12"
  },
  {
    "objectID": "exercise/lab-sol-s25-midterm.html#lab-9-numpy-and-pandas",
    "href": "exercise/lab-sol-s25-midterm.html#lab-9-numpy-and-pandas",
    "title": "In-Class Lab Exercises",
    "section": "Lab 9: NumPy and pandas",
    "text": "Lab 9: NumPy and pandas\n\ntibble(x = 1:5, y = 5:1, z = LETTERS[1:5])\n\n# A tibble: 5 × 3\n      x     y z    \n  &lt;int&gt; &lt;int&gt; &lt;chr&gt;\n1     1     5 A    \n2     2     4 B    \n3     3     3 C    \n4     4     2 D    \n5     5     1 E    \n\n\n\nimport numpy as np\nimport pandas as pd\nimport string\nlist(string.ascii_uppercase)\n\n['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n\ndic = {'x':np.arange(1, 6), 'y': np.arange(5, 0, -1), 'z':list(string.ascii_uppercase)[0:5]}\npd.DataFrame(dic)\n\n   x  y  z\n0  1  5  A\n1  2  4  B\n2  3  3  C\n3  4  2  D\n4  5  1  E"
  },
  {
    "objectID": "exercise/lab-sol-s25-midterm.html#lab-10-import-data",
    "href": "exercise/lab-sol-s25-midterm.html#lab-10-import-data",
    "title": "In-Class Lab Exercises",
    "section": "Lab 10: Import Data",
    "text": "Lab 10: Import Data\n\nlibrary(tidyverse)\n# ssa &lt;- read_csv(file = \"./data/ssa-death-probability.csv\")\n\n# ssa_male &lt;- ssa[ssa$Sex == \"Male\",]\n# ssa_female &lt;- ssa[ssa$Sex == \"Female\",]\nssa_male &lt;- readr::read_csv(\"./data/ssa_male_prob.csv\")\n\nRows: 120 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): Sex\ndbl (4): Age, DeathProb, NumberOfLives, LifeExp\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nssa_female &lt;- readr::read_rds(\"./data/ssa_female_prob.Rds\")\nplot(x = ssa_female$Age, y = ssa_female$LifeExp, \n     type = \"l\", col = 2, lwd = 3,\n     xlab = \"Age\", ylab = \"Life Exp\",\n     main = \"Age vs. Life Exp by Gender\")\nlines(ssa_male$Age, ssa_male$LifeExp, col = 4, lwd = 3)"
  },
  {
    "objectID": "exercise/lab-sol-s25-midterm.html#lab-11-ggplot2",
    "href": "exercise/lab-sol-s25-midterm.html#lab-11-ggplot2",
    "title": "In-Class Lab Exercises",
    "section": "Lab 11: ggplot2",
    "text": "Lab 11: ggplot2\n\npenguins &lt;- read_csv(\"./data/penguins.csv\")\n\nRows: 344 Columns: 8\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): species, island, sex\ndbl (5): bill_length_mm, bill_depth_mm, flipper_length_mm, body_mass_g, year\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\npenguins |&gt; \n  ggplot(mapping = aes(x = bill_depth_mm,\n                       y = bill_length_mm,\n                       colour = species)) +\n  geom_point() +\n  labs(title = \"Bill depth and length\",\n       subtitle = \"Dimensions for Adelie, Chinstrap, and Gentoo Penguins\",\n       x = \"Bill depth (mm)\", y = \"Bill length (mm)\",\n       colour = \"Species\",\n       caption = \"Source: Palmer Station LTER / palmerpenguins package\") +\n  scale_colour_viridis_d()\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`)."
  },
  {
    "objectID": "exercise/lab-sol-s25-midterm.html#lab-12-faceting",
    "href": "exercise/lab-sol-s25-midterm.html#lab-12-faceting",
    "title": "In-Class Lab Exercises",
    "section": "Lab 12: Faceting",
    "text": "Lab 12: Faceting\n\nmpg |&gt; ggplot(mapping = aes(x = displ, y = cty, color = drv, shape = fl)) +\n    geom_point(size = 3, alpha = 0.8) + \n    facet_grid(drv ~ fl) +\n    guides(color = \"none\")"
  },
  {
    "objectID": "exercise/lab-sol-s25-midterm.html#lab-13-visualization",
    "href": "exercise/lab-sol-s25-midterm.html#lab-13-visualization",
    "title": "In-Class Lab Exercises",
    "section": "Lab 13: Visualization",
    "text": "Lab 13: Visualization\n\npenguins &lt;- read_csv(\"./data/penguins.csv\")\n\nRows: 344 Columns: 8\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): species, island, sex\ndbl (5): bill_length_mm, bill_depth_mm, flipper_length_mm, body_mass_g, year\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\npenguins |&gt; ggplot(aes(x = species, fill = species)) +\n    geom_bar() +\n    labs(x = \"Species of Penguins\", \n         title = \"Species Counts in Penguins Data\")\n\n\n\n\n\n\n\n\n\npenguins |&gt; ggplot(aes(x = bill_length_mm, \n                       fill = species)) +\n    geom_histogram() +\n    labs(x = \"Bill Length (mm)\",\n         y = \"Frequency\",\n         title = \"Penguins Bill Length by Species\") +\n    facet_wrap(~ species, nrow = 1) + \n    theme(legend.position = \"none\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_bin()`)."
  },
  {
    "objectID": "exercise/lab-sol-s25-midterm.html#lab-14-plotly",
    "href": "exercise/lab-sol-s25-midterm.html#lab-14-plotly",
    "title": "In-Class Lab Exercises",
    "section": "Lab 14: plotly",
    "text": "Lab 14: plotly\n\nlibrary(plotly)\n\n\nAttaching package: 'plotly'\n\n\nThe following object is masked from 'package:ggplot2':\n\n    last_plot\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\n\nThe following object is masked from 'package:graphics':\n\n    layout\n\nloans &lt;- readr::read_csv(\"./data/loans.csv\")\n\nRows: 10000 Columns: 5\n\n\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): grade, homeownership\ndbl (3): loan_amount, interest_rate, debt_to_income\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\np &lt;- plot_ly(loans, x = ~interest_rate, alpha = 0.5)\np |&gt; add_boxplot(y = ~grade, color = ~grade)\n\n\n\n\n\n\n# x = interest_rate, y = grade won't work\ngg &lt;- loans %&gt;% ggplot(aes(x = grade, y = interest_rate, color = grade)) + \n    geom_boxplot() + theme_minimal() + coord_flip()\nggplotly(gg)"
  },
  {
    "objectID": "exercise/lab-sol-s25-midterm.html#lab-15-dplyr",
    "href": "exercise/lab-sol-s25-midterm.html#lab-15-dplyr",
    "title": "In-Class Lab Exercises",
    "section": "Lab 15: dplyr",
    "text": "Lab 15: dplyr\n\nmurders &lt;- read.csv(\"./data/murders.csv\")\n(my_states &lt;- murders |&gt; \n    mutate(rate = total / population * 100000) |&gt; \n    filter(region %in% c(\"West\", \"Northeast\"), rate &lt; 1) |&gt; \n    select(state, region, rate))\n\n          state    region      rate\n1        Hawaii      West 0.5145920\n2         Idaho      West 0.7655102\n3         Maine Northeast 0.8280881\n4 New Hampshire Northeast 0.3798036\n5        Oregon      West 0.9396843\n6          Utah      West 0.7959810\n7       Vermont Northeast 0.3196211\n8       Wyoming      West 0.8871131\n\nmy_states |&gt; \n    group_by(region) |&gt; \n    summarize(avg = mean(rate), std_dev = sd(rate)) |&gt; \n    arrange(desc(avg))\n\n# A tibble: 2 × 3\n  region      avg std_dev\n  &lt;chr&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 West      0.781   0.164\n2 Northeast 0.509   0.278"
  },
  {
    "objectID": "exercise/lab-sol-s25-midterm.html#lab-16-joining-tables",
    "href": "exercise/lab-sol-s25-midterm.html#lab-16-joining-tables",
    "title": "In-Class Lab Exercises",
    "section": "Lab 16: Joining Tables",
    "text": "Lab 16: Joining Tables\n\ndiamond_color &lt;- read_csv(\"https://www.jaredlander.com/data/DiamondColors.csv\")\n\nRows: 10 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): Color, Description, Details\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\njoined_df &lt;- left_join(diamonds, diamond_color, by = c('color' = 'Color')) |&gt; \n    select(carat, color, price, Description, Details)\njoined_df\n\n# A tibble: 53,940 × 5\n   carat color price Description    Details                    \n   &lt;dbl&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt;          &lt;chr&gt;                      \n 1  0.23 E       326 Colorless      Minute traces of color     \n 2  0.21 E       326 Colorless      Minute traces of color     \n 3  0.23 E       327 Colorless      Minute traces of color     \n 4  0.29 I       334 Near Colorless Slightly detectable color  \n 5  0.31 J       335 Near Colorless Slightly detectable color  \n 6  0.24 J       336 Near Colorless Slightly detectable color  \n 7  0.24 I       336 Near Colorless Slightly detectable color  \n 8  0.26 H       337 Near Colorless Color is dificult to detect\n 9  0.22 E       337 Colorless      Minute traces of color     \n10  0.23 H       338 Near Colorless Color is dificult to detect\n# ℹ 53,930 more rows\n\njoined_df |&gt; ggplot(aes(x = color)) + \n  geom_bar()\n\n\n\n\n\n\n\njoined_df |&gt; count(color, sort = TRUE)\n\n# A tibble: 7 × 2\n  color     n\n  &lt;chr&gt; &lt;int&gt;\n1 G     11292\n2 E      9797\n3 F      9542\n4 H      8304\n5 D      6775\n6 I      5422\n7 J      2808"
  },
  {
    "objectID": "exercise/lab06-py.html",
    "href": "exercise/lab06-py.html",
    "title": "Lab 06: Python Data Structure",
    "section": "",
    "text": "Note\n\n\n\n\n\n\nIn lab.qmd Lab 6,\n\nCreate a Python list and dictionary similar to the R list below.\n\n\nx_lst &lt;- list(idx = 1:3, \n              \"a\", \n              c(TRUE, FALSE))\n\nRemember to create Python code chunk\n\n```{Python}\n#| echo: true\n#| eval: false\n#| code-line-numbers: false\n\n```\n\nAny issue of this Python chunk?\nCommit and Push your work once you are done."
  },
  {
    "objectID": "exercise/lab12-facet.html",
    "href": "exercise/lab12-facet.html",
    "title": "Lab 12: Faceting",
    "section": "",
    "text": "Note\n\n\n\n\n\n\nIn lab.qmd ## Lab 12 section,\n\nggplot(data = _______, \n       mapping = aes(x = ______, y = ______, ______ = drv, shape = _____)) +\n    geom______(______ = 3, ______ = 0.8) + \n    facet_grid(______ ~ _______) +\n    guides(______ = \"none\")"
  },
  {
    "objectID": "exercise/lab13-visualization.html",
    "href": "exercise/lab13-visualization.html",
    "title": "Lab 13: Visualization",
    "section": "",
    "text": "Note\n\n\n\n\n\n\nIn lab.qmd ## Lab 13 section,\n\nImport the data penguins.csv.\nGenerate the following\n\n\n\n\n\n\n\n\n\n\n\n\nWarning: Removed 2 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n\n\n\n\n\n\n\n\n# library(tidyverse)\npenguins &lt;- read_csv(__________________)\n________ |&gt; ggplot(_______________________) +  ## mapping layer  \n    ___________________ +  ## geometry layer\n    _____________________________  ## label layer\n\n  \n\n________ |&gt; ggplot(______________________________) +  ## mapping layer  \n    _______________ +  ## geometry layer\n    _______________ +  ## label layer\n    ______________________________  +   ## facet layer\n    ______________________________      ## theme layer (set legend.position = \"none\")"
  },
  {
    "objectID": "slides/14-tidyr.html#grammar-of-data-tidying",
    "href": "slides/14-tidyr.html#grammar-of-data-tidying",
    "title": "Tidying Data 🧹",
    "section": "Grammar of Data Tidying",
    "text": "Grammar of Data Tidying\n\nHave data organised in an unideal way for our analysis\nWant to re-organise the data to carry on with our analysis\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe goal of tidyr is to help you tidy your data via\n\npivoting for going between wide and long data\nseparating and uniting character columns\nclarifying how NAs should be treated\nnesting and unnesting columns\n\n\n\n\nSuppose we have a data set that is untidy, and organised in an unideal way for our analysis.\nWhat tidyr is doing is not like dplyr, just filter rows or select columns, because it is kinda meaningless, because the data after filtering or selecting from the untidy data are still untidy.\nSo our goal is to re-organise the data so that it is clean enough for being filtered or selected and for later data analysis.\ntidyr helps you tidy your data via\n\n\npivoting for going between wide and long data\n\nseparating and uniting character columns\nclarifying how NAs should be treated. for example, do we wanna keep them or drop them, or fill in with some values.\nnesting and unnesting columns\n\n\nWe will go through the first three. You can check the tidyr page to learn more about its functionality."
  },
  {
    "objectID": "slides/14-tidyr.html#wide-data",
    "href": "slides/14-tidyr.html#wide-data",
    "title": "Tidying Data 🧹",
    "section": "Wide Data",
    "text": "Wide Data\nTo tidy your data, (1) figure out what the (column) variables and (row) observations are; (2) resolve one of two common problems:\n\n\n\nOne (column) variable spreads across multiple columns\n\n\n\n\n\n\n\n\n\n\n\ncustomers &lt;- read_csv(\"./data/sales/customers.csv\")\n\nwider (\\(2 \\times 4\\))\nmore columns than we want!\n\ncustomers\n\n# A tibble: 2 × 4\n  customer_id item_1 item_2       item_3\n        &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;        &lt;chr&gt; \n1           1 bread  milk         banana\n2           2 milk   toilet paper &lt;NA&gt;  \n\n\n\n\n\nWe may want one single column variable item showing all purchased times."
  },
  {
    "objectID": "slides/14-tidyr.html#long-data",
    "href": "slides/14-tidyr.html#long-data",
    "title": "Tidying Data 🧹",
    "section": "Long Data",
    "text": "Long Data\n\n\nOne (row) subject is scattered across multiple rows\n\n\n\n\n\n\n\n\n\n\n\nlonger (\\(6 \\times 3\\))\nmore rows than we want!\n\n\n# A tibble: 6 × 3\n  customer_id item_no item        \n        &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;       \n1           1 item_1  bread       \n2           1 item_2  milk        \n3           1 item_3  banana      \n4           2 item_1  milk        \n5           2 item_2  toilet paper\n6           2 item_3  &lt;NA&gt;        \n\n\n\n\n\nWe may want each row corresponds to one single customer, not one single purchased item.\nWhich data format we adopt depends on our own research question.\n\n\n\n\n\nIf our data is untidy, to tidy our data, first, we get to figure out what the variables (column) and observations (row) are. Remember the definition of tidy data. each row is for one and only one observation, and each column is for one and only one variable.\nOnce we know observations and variables, we need to resolve one of two common problems:\n\nOne variable might be spread across multiple columns.\nOne observation might be scattered across multiple rows.\n\n\neither problem is a reason why our data is not tidy."
  },
  {
    "objectID": "slides/14-tidyr.html#pivot_longer-and-pivot_wider",
    "href": "slides/14-tidyr.html#pivot_longer-and-pivot_wider",
    "title": "Tidying Data 🧹",
    "section": "\npivot_longer() and pivot_wider()\n",
    "text": "pivot_longer() and pivot_wider()\n\n\nTo transform our data to the one we want, we use pivot_longer() and pivot_wider().\n\nStarts with a data set,\n\npivot_longer() ``lengthens” data, adding more rows and decreasing the number of columns.\npivot_wider() ``widens” data, adding more columns and decreasing the number of rows.\n\n\n\n\nTo fix these problems, we’ll need the functions pivot_longer() and pivot_wider()\n\npivot_longer() starts with a data set and add more rows to it. Make the data set longer\npivot_wider() starts with a data set and add more columns to it. Make the data set wider\n\nTo change the left data set to the right data set, we use pivot_longer(), because the transformed data set has more rows and will typically has less columns as well.\nTo change the right data set to the left data set, we use pivot_wider(), because the transformed data set has more columns and will typically has less rows as well."
  },
  {
    "objectID": "slides/14-tidyr.html#pivot_longer-and-pivot_wider-1",
    "href": "slides/14-tidyr.html#pivot_longer-and-pivot_wider-1",
    "title": "Tidying Data 🧹",
    "section": "\npivot_longer() and pivot_wider()\n",
    "text": "pivot_longer() and pivot_wider()\n\n\n\nthe gif here illustrate the idea of pivot_longer() and pivot_wider() function."
  },
  {
    "objectID": "slides/14-tidyr.html#data-salescustomers.csv",
    "href": "slides/14-tidyr.html#data-salescustomers.csv",
    "title": "Tidying Data 🧹",
    "section": "Data: sales/customers.csv",
    "text": "Data: sales/customers.csv\n\ncustomers &lt;- read_csv(\"data/sales/customers.csv\")\n\n\n\nwider (\\(2 \\times 4\\))\nmore columns\n\ncustomers\n\n# A tibble: 2 × 4\n  customer_id item_1 item_2       item_3\n        &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;        &lt;chr&gt; \n1           1 bread  milk         banana\n2           2 milk   toilet paper &lt;NA&gt;  \n\n\n\nlonger (\\(6 \\times 3\\))\nmore rows by pivot_longer()\n\n\n# A tibble: 6 × 3\n  customer_id item_no item        \n        &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;       \n1           1 item_1  bread       \n2           1 item_2  milk        \n3           1 item_3  banana      \n4           2 item_1  milk        \n5           2 item_2  toilet paper\n6           2 item_3  &lt;NA&gt;        \n\n\n\n\n\nAnd the original customers data is in this wider format, where I have one row per customer. We have two customers and so two rows in the data frame.\nand then we have individual columns for the items they bought. The first customer bought 3 items, bread, milk, banana and the second customer bought two items, milk and toilet paper, so the the item_3 column value is NA.\nBut this data format may not be what we want.\nIn fact, what we want to do for this particular example is to have it in a format where one row per customer per item, so I can do further analysis.\nso we wanna go from wider to longer format, because the format we want has more rows and less columns."
  },
  {
    "objectID": "slides/14-tidyr.html#pivot_longer",
    "href": "slides/14-tidyr.html#pivot_longer",
    "title": "Tidying Data 🧹",
    "section": "pivot_longer()",
    "text": "pivot_longer()\n\n\n\ndata: data frame\ncols: columns to pivot into longer format (1960, 1970, 2010)\n\n\n\ndata |&gt; pivot_longer(\n    cols, \n    names_to = \"name\", \n    values_to = \"value\")\n\n\n\n\nSo we are going to use a function pivot_longer().\nLike other functions in tidyverse, the first argument is again a data frame.\nthen we give it the columns we want to pivot into the longer format\n\n\n\n\n\nSource: https://tavareshugo.github.io/r-intro-tidyverse-gapminder/09-reshaping/index.html"
  },
  {
    "objectID": "slides/14-tidyr.html#pivot_longer-1",
    "href": "slides/14-tidyr.html#pivot_longer-1",
    "title": "Tidying Data 🧹",
    "section": "pivot_longer()",
    "text": "pivot_longer()\n\n\n\n\n\n\nnames_to: name of the column where column names of pivoted variables go (year)\n\n\n\ndata |&gt; pivot_longer(\n    cols, \n    names_to = \"name\", \n    values_to = \"value\")\n\n\n\n\n\n\n\n\nSource: https://tavareshugo.github.io/r-intro-tidyverse-gapminder/09-reshaping/index.html\n\n\n\n\n\nand then we give the argument [names_to] the name of the column (in the transformed longer data) where column names of pivoted variables (in the original wider data) go, which is a character string."
  },
  {
    "objectID": "slides/14-tidyr.html#pivot_longer-2",
    "href": "slides/14-tidyr.html#pivot_longer-2",
    "title": "Tidying Data 🧹",
    "section": "pivot_longer()",
    "text": "pivot_longer()\n\n\n\n\n\n\n\nvalues_to: name of the column where data values in pivoted variables go (metric)\n\n\n\ndata |&gt; pivot_longer(\n    cols, \n    names_to = \"name\", \n    values_to = \"value\")\n\n\n\n\n\n\n\n\nSource: https://tavareshugo.github.io/r-intro-tidyverse-gapminder/09-reshaping/index.html\n\n\n\n\n\nand finally we give the argument [values_to] the name of the column (in the transformed longer data) where data values of pivoted variables (in the original wider data) go, which is also a character string.\nSo basically we are constructing two new variables in the new longer data set, and we are going to give their name as a character string, so they can be placed in the headers for those columns."
  },
  {
    "objectID": "slides/14-tidyr.html#customers-rightarrow-purchases",
    "href": "slides/14-tidyr.html#customers-rightarrow-purchases",
    "title": "Tidying Data 🧹",
    "section": "customers \\(\\rightarrow\\) purchases",
    "text": "customers \\(\\rightarrow\\) purchases\n\n\n\ncustomers\n\n# A tibble: 2 × 4\n  customer_id item_1 item_2       item_3\n        &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;        &lt;chr&gt; \n1           1 bread  milk         banana\n2           2 milk   toilet paper &lt;NA&gt;  \n\n\n\n\npurchases &lt;- customers |&gt; pivot_longer(\n    # variables item_1 to item_3 \n    # to be pivoted into longer format \n    cols = item_1:item_3,\n    \n    # col name of the names of item_1:item_3\n    # item_1 item_2 and item_3 \n    names_to = \"item_no\",\n    \n    # col name of the values of item_1:item_3\n    values_to = \"item\"\n    )\n\n\n\n\npurchases\n\n# A tibble: 6 × 3\n  customer_id item_no item        \n        &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;       \n1           1 item_1  bread       \n2           1 item_2  milk        \n3           1 item_3  banana      \n4           2 item_1  milk        \n5           2 item_2  toilet paper\n6           2 item_3  &lt;NA&gt;        \n\n\nIn customers data,\n\nNames item_1, item_2, item_3 are values of variable item_no in purchases\nValues bread, milk, etc are values of variable item in purchases\n\n\n\n\nLet’s see how the function actually works in the customers example.\nSuppose we start with the customers data set which is in a wider format.\nAnd we wanna pivot it into a longer format.\nthe columns I wanna pivot are the ones that have information about the items that customers bought, which are item1, item 2, and item3.\nSo I write item1:item3 (we can also use any helper function to select columns)\nOK Now, the column names item_1 item_2, item_3 should be in a new column in the transformed longer data set whose column name is called item_no.\nANd the values in those three columns (the cells in the original data) should go into another new column in the in the transformed longer data set whose column name is called item that basically shows what the customers had purchased.\nSo again the column names of the original wider data go into a new column called item_no\nand the values of the column names of the original wider data go into a new column called item.\nAnd I end up with a longer data set called purchases with 6 rows and 3 columns"
  },
  {
    "objectID": "slides/14-tidyr.html#why-pivot",
    "href": "slides/14-tidyr.html#why-pivot",
    "title": "Tidying Data 🧹",
    "section": "Why Pivot?",
    "text": "Why Pivot?\n\nThe next step of your analysis needs it.\nThe new purchases data set and the prices data can now be joined together with the common key variable item. \n\n\n\n\n\nprices &lt;- read_csv(\"./data/sales/prices.csv\")\nprices\n\n# A tibble: 5 × 2\n  item         price\n  &lt;chr&gt;        &lt;dbl&gt;\n1 avocado       0.5 \n2 banana        0.15\n3 bread         1   \n4 milk          0.8 \n5 toilet paper  3   \n\n\n\n\npurchases |&gt; \n    left_join(prices) #&lt;&lt;\n\n# A tibble: 6 × 4\n  customer_id item_no item         price\n        &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;        &lt;dbl&gt;\n1           1 item_1  bread         1   \n2           1 item_2  milk          0.8 \n3           1 item_3  banana        0.15\n4           2 item_1  milk          0.8 \n5           2 item_2  toilet paper  3   \n6           2 item_3  &lt;NA&gt;         NA   \n\n\n\n\n\nWhy do we want to pivot our data?\nMost likely, because the next step of your analysis needs it.\nSuppose we have another data set called prices as shown on the left that contains price of grocery items\nAfter pivoting our data, the new purchases data set and the prices data can now be joined together with the common key variable item.\nWith the joined data set, we can further calculate total revenue for example."
  },
  {
    "objectID": "slides/14-tidyr.html#pivot_wider",
    "href": "slides/14-tidyr.html#pivot_wider",
    "title": "Tidying Data 🧹",
    "section": "pivot_wider()",
    "text": "pivot_wider()\n\n\n\ndata: data frame\nnames_from: which column variable in the long format contains the what should be column names in the wide format (year)\n\n\n\ndata |&gt; pivot_wider(\n    names_from = column_variable_1, \n    values_from = column_variable_2)\n\n\n\n\n\n\n\n\nSource: https://tavareshugo.github.io/r-intro-tidyverse-gapminder/09-reshaping/index.html"
  },
  {
    "objectID": "slides/14-tidyr.html#pivot_wider-1",
    "href": "slides/14-tidyr.html#pivot_wider-1",
    "title": "Tidying Data 🧹",
    "section": "pivot_wider()",
    "text": "pivot_wider()\n\n\n\ndata: data frame\nvalues_from: which column variable in the long format contains the what should be values in the new columns in the wide format (metric)\n\n\n\ndata |&gt; pivot_wider(\n    names_from = column_variable_1, \n    values_from = column_variable_2)\n\n\n\n\n\n\n\n\nSource: https://tavareshugo.github.io/r-intro-tidyverse-gapminder/09-reshaping/index.html"
  },
  {
    "objectID": "slides/14-tidyr.html#purchases-rightarrow-customers",
    "href": "slides/14-tidyr.html#purchases-rightarrow-customers",
    "title": "Tidying Data 🧹",
    "section": "purchases \\(\\rightarrow\\) customers",
    "text": "purchases \\(\\rightarrow\\) customers\n\n\n\npurchases\n\n# A tibble: 6 × 3\n  customer_id item_no item        \n        &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;       \n1           1 item_1  bread       \n2           1 item_2  milk        \n3           1 item_3  banana      \n4           2 item_1  milk        \n5           2 item_2  toilet paper\n6           2 item_3  &lt;NA&gt;        \n\n\n\n\npurchases |&gt; \n    pivot_wider(              \n        names_from = item_no, \n        values_from = item    \n    ) \n\n# A tibble: 2 × 4\n  customer_id item_1 item_2       item_3\n        &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;        &lt;chr&gt; \n1           1 bread  milk         banana\n2           2 milk   toilet paper &lt;NA&gt;  \n\n\n\n\n\nAll right. In fact we can also go back from a longer data to a wider data, which is the original data set we start with.\n\ndata: data frame\n\nnames_from: which column variable in the long format contains what should be column names in the wide format\n\nvalues_from: which column variable in the long format contains what should be (cell) values in the new columns in the wide format\nNotice that item_no and item are not quoted because they are variables that exist in our data frame purchases.\nWe don’t construct new variables as we do when creating a data set in a longer format.\nOK. That’s pivoting, changing data set from wider to longer, or longer to wider format."
  },
  {
    "objectID": "slides/14-tidyr.html#section-2",
    "href": "slides/14-tidyr.html#section-2",
    "title": "Tidying Data 🧹",
    "section": "",
    "text": "Source: FiveThirtyEight"
  },
  {
    "objectID": "slides/14-tidyr.html#section-3",
    "href": "slides/14-tidyr.html#section-3",
    "title": "Tidying Data 🧹",
    "section": "",
    "text": "17-tidyr \nIn lab.qmd ## Lab 17 section,\n\n\nImport trump.csv. Call it trump_data as below on the left.\nUse pivot_longer() to transform trump_data into the data set trump_longer on the right.\n\n\n\n\n\ntrump_data\n\n# A tibble: 2,702 × 4\n  subgroup date       approval disapproval\n  &lt;chr&gt;    &lt;date&gt;        &lt;dbl&gt;       &lt;dbl&gt;\n1 Voters   2020-10-04     44.7        52.2\n2 Adults   2020-10-04     43.2        52.6\n3 Adults   2020-10-03     43.2        52.6\n4 Voters   2020-10-03     45.0        51.7\n5 Adults   2020-10-02     43.3        52.4\n6 Voters   2020-10-02     44.5        52.1\n# ℹ 2,696 more rows\n\n\n\n\ntrump_longer &lt;- ______________\n    pivot_longer(\n        cols = ____________,\n        names_to = _______________,\n        values_to = _______________\n    ) \n\n\n\n# A tibble: 5,404 × 4\n  subgroup date       rating_type rating_value\n  &lt;chr&gt;    &lt;date&gt;     &lt;chr&gt;              &lt;dbl&gt;\n1 Voters   2020-10-04 approval            44.7\n2 Voters   2020-10-04 disapproval         52.2\n3 Adults   2020-10-04 approval            43.2\n4 Adults   2020-10-04 disapproval         52.6\n5 Adults   2020-10-03 approval            43.2\n6 Adults   2020-10-03 disapproval         52.6\n# ℹ 5,398 more rows"
  },
  {
    "objectID": "slides/14-tidyr.html#section-4",
    "href": "slides/14-tidyr.html#section-4",
    "title": "Tidying Data 🧹",
    "section": "",
    "text": "BONUS 💰: Use trump_longer to generate a plot like the one below."
  },
  {
    "objectID": "slides/14-tidyr.html#pd.wide_to_long",
    "href": "slides/14-tidyr.html#pd.wide_to_long",
    "title": "Tidying Data 🧹",
    "section": "pd.wide_to_long()",
    "text": "pd.wide_to_long()\n\nimport numpy as np\nimport pandas as pd\n\n\ncustomers = pd.read_csv('./data/sales/customers.csv')\ncustomers\n\n   customer_id item_1        item_2  item_3\n0            1  bread          milk  banana\n1            2   milk  toilet paper     NaN\n\npurchases = pd.wide_to_long(df = customers,\n                            stubnames = ['item'], \n                            i = 'customer_id', \n                            j = 'item_no', sep = '_')\npurchases\n\n                             item\ncustomer_id item_no              \n1           1               bread\n2           1                milk\n1           2                milk\n2           2        toilet paper\n1           3              banana\n2           3                 NaN"
  },
  {
    "objectID": "slides/14-tidyr.html#pd.pivot",
    "href": "slides/14-tidyr.html#pd.pivot",
    "title": "Tidying Data 🧹",
    "section": "pd.pivot()",
    "text": "pd.pivot()\n\npurchases = purchases.reset_index()\npurchases\n\n   customer_id  item_no          item\n0            1        1         bread\n1            2        1          milk\n2            1        2          milk\n3            2        2  toilet paper\n4            1        3        banana\n5            2        3           NaN\n\npurchases.pivot(index = \"customer_id\", columns = \"item_no\", values = \"item\")\n\nitem_no          1             2       3\ncustomer_id                             \n1            bread          milk  banana\n2             milk  toilet paper     NaN\n\n\n\n\n\n\nmath3570-s25.github.io/website"
  },
  {
    "objectID": "slides/03-posit.html#integrated-development-environment",
    "href": "slides/03-posit.html#integrated-development-environment",
    "title": "Posit Cloud ☁️",
    "section": "Integrated Development Environment",
    "text": "Integrated Development Environment\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR and Python are programming languages.\n\nPosit Cloud offers two integrated development environments (IDE):\n\nRStudio\nJupyterLab/Jupyter Notebook\n\n\n\nwhich are software for efficiently writing computer programs.\n\nWe’ll use Posit Cloud to write R and Python code.\nThe first tool we need is Posit Cloud which is a cloud service provided by the company Posit.   \n\nR is not a general-purpose programming language like python or java, but it is specifically for data science. And that’s probably why you don’t learn R in an intro programming course.\nSo you can view Python as a smart phone. It can do many different things, phone, camera, email, social media. But R is like a high quality camera. You cannot use it to write emails, text messages, but it produces high quality photos.\nRStudio is not a programming language, but a software application.\nCode itself is just a text file. You can use any text editor or software to write your code.\nSo RStudio makes programming in R more easily and efficiently. It provides so many useful functions for you that doing data science becomes a piece of cake.\nToday, You are gonna have a chance to play with different panes and functions in RStudio. OK."
  },
  {
    "objectID": "slides/03-posit.html#posit-cloud---data-science-wo-hardware-hassles",
    "href": "slides/03-posit.html#posit-cloud---data-science-wo-hardware-hassles",
    "title": "Posit Cloud ☁️",
    "section": "☁️ Posit Cloud - Data Science w/o hardware hassles",
    "text": "☁️ Posit Cloud - Data Science w/o hardware hassles\n\n😎 Implement R/Python programs without needing to install R/Python and the IDE in your laptop!\n😎 Posit Cloud lets you do, share and learn data science entirely online!\n\n\n\n😞 Get everything ready locally: Lots of friction\n\nDownload and install R/Python\nDownload and install IDE\nInstall wanted R/Python packages:\n\ntidymodels\ntidyverse\nNumPy\n…\n\n\nDownload and install tools like Git\n\n\n\n\n🤓 Posit Cloud: Much less friction\n\n\n\n\n\n\n\n\n\nGo to https://posit.cloud/\n\nLog in\n&gt; hello world!\n\n\n\n\n\n\nWhy I choose posit cloud for you to code in R? Well if I want every one of you use R/Python and RStudio locally in your computer, you have to (_____). And we need some magic to make sure everyone gets the coding environment ready.\nInstead, with the Cloud-based solution, you just need to login, then you start writing code right away.\nPosit Cloud provides you with the latest version of R and RStudio. No installation is required.\nDoesn’t mean you should always use Posit Cloud version. It’s not free if you need more resources.\nIf later you program a lot, you should absolutely install them locally into your laptop."
  },
  {
    "objectID": "slides/03-posit.html#install-posit-cloud",
    "href": "slides/03-posit.html#install-posit-cloud",
    "title": "Posit Cloud ☁️",
    "section": "Install Posit Cloud",
    "text": "Install Posit Cloud\n\n\n\nStep 1: In the Posit website https://posit.co/, choose Products &gt; Posit Cloud as shown below."
  },
  {
    "objectID": "slides/03-posit.html#install-posit-cloud-1",
    "href": "slides/03-posit.html#install-posit-cloud-1",
    "title": "Posit Cloud ☁️",
    "section": "Install Posit Cloud",
    "text": "Install Posit Cloud\n\nStep 2: Click GET STARTED.\nStep 3: Cloud Student &gt; Sign Up using your Marquette email address.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfile:///Users/chenghanyu/Dropbox/academia/books/r/teach-r-online-master/01-cloud/01-cloud.html#37"
  },
  {
    "objectID": "slides/03-posit.html#new-projects",
    "href": "slides/03-posit.html#new-projects",
    "title": "Posit Cloud ☁️",
    "section": "New Projects",
    "text": "New Projects\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe will talk about Git/GitHub shortly."
  },
  {
    "objectID": "slides/03-posit.html#workspaces",
    "href": "slides/03-posit.html#workspaces",
    "title": "Posit Cloud ☁️",
    "section": "Workspaces",
    "text": "Workspaces\n\nWhen you create an account on Posit Cloud you get a workspace of your own.\nYou can add a new workspace (click + New Space in sidebar) and control its permissions."
  },
  {
    "objectID": "slides/03-posit.html#welcome-to-3570-data-science",
    "href": "slides/03-posit.html#welcome-to-3570-data-science",
    "title": "Posit Cloud ☁️",
    "section": "Welcome to 3570 Data Science!",
    "text": "Welcome to 3570 Data Science!\n\n\nI’m sending you a link via email for joining the course workspace 2025-spring-math-3570. Please join.\n\n\n\n\n\n\n\n\n\n\nGo to D2l to send Posit Cloud invitation\nSubject Posit Cloud Invitation Message https://posit.cloud/spaces/598911/join?access_code=6SiLjVJc37hZPq5Qi6uvzip3vtPCE1z46u0dwKig\nBest, Dr. Yu"
  },
  {
    "objectID": "slides/03-posit.html#section-1",
    "href": "slides/03-posit.html#section-1",
    "title": "Posit Cloud ☁️",
    "section": "",
    "text": "In the bar, click workspace 2025-spring-math-3570.\nIn the workspace, click New Project &gt; New RStudio Project to get into the IDE.\nIn Untitled Project, name your project as 3570-project.\nIn the Console pane, write R code: a string \"Hello WoRld!\" or math 2 + 4.\nTools &gt; Global Options &gt; Appearance to select your favorite editor theme."
  },
  {
    "objectID": "slides/03-posit.html#more-tips",
    "href": "slides/03-posit.html#more-tips",
    "title": "Posit Cloud ☁️",
    "section": "More Tips",
    "text": "More Tips\n\nRead the Posit Cloud Documentation"
  },
  {
    "objectID": "slides/03-posit.html#panes",
    "href": "slides/03-posit.html#panes",
    "title": "Posit Cloud ☁️",
    "section": "Panes",
    "text": "Panes\n\n\nIn RStudio, there are 4 main panes, source pane, console pane, pane for environment/history and version control, and the pane for files plots packages and help page.\nSource pane is where you write your code. Your code will not be evaluated or interpreted until you “run” them or source them to the console.\nTry to write your code in R/Python scripts in the Source, so that the code can be saved and reused later.\nYou type code into the Console if the code is short or you want to do some quick calculations or analysis. The code you type in the Console will not be saved in a script.\nIn the environment/history, you can check any objects you create in the R/Python environment and you can also view your command history in the history tab.\nAnd you will see how the pane for file/plot/package/help can be used as we learn more about RStudio."
  },
  {
    "objectID": "slides/03-posit.html#r-script",
    "href": "slides/03-posit.html#r-script",
    "title": "Posit Cloud ☁️",
    "section": "R Script",
    "text": "R Script\n\nA R script is a .R file that contains R code.\nTo create a R script, go to File &gt; New &gt; R Script, or click the green-plus icon on the topleft corner, and select R Script.\n\n\n\nHere you see in this r script, I create two objects x and y, and I also load the data called mtcars into R environment.\nDon’t worry if you don’t know these syntax. I will teach you basic R syntax and programming next week."
  },
  {
    "objectID": "slides/03-posit.html#run-code",
    "href": "slides/03-posit.html#run-code",
    "title": "Posit Cloud ☁️",
    "section": "Run Code",
    "text": "Run Code\n\n\nRun: run the current line or selection of code.\n\n\nctrl + enter (Win) or cmd + enter (Mac)\n\n\n\nIcon right to the Run: re-run the previous code.\n\n\nalt + ctrl + p (Win) or option + cmd + p (Mac)\n\n\n\nSource: run all the code in the R script.\n\n\nshift + ctrl + s (Win) or shift + cmd + s (Mac)\n\n\n\nSource with Echo: run all the code in the R script with the code printed in the console.\n\n\nshift + ctrl + enter (Win) or shift + cmd + enter (Mac)\n\n\n\n\n\n\nSource: run all the code in the R script with NO output\n\nSource with Echo: run all the code in the R script and show output\n\nDepending on your purpose, you can run code line by line or run the entire code.\nTo run the R code line by line, Click Run icon to run the current line or selection of code. Or use key-binding ctrl + enter (windows) or cmd + enter (mac)"
  },
  {
    "objectID": "slides/03-posit.html#environment-tab",
    "href": "slides/03-posit.html#environment-tab",
    "title": "Posit Cloud ☁️",
    "section": "Environment Tab",
    "text": "Environment Tab\n\nThe (global) environment is where we are currently working.\nAnything created or imported into the current R/Python session is stored in the environment and shown in the Environment tab.\n\nAfter we run the R script, objects stored in the environment are\n\nData set mtcars\n\nObject x storing integer values 1 to 10.\nObject y storing three numeric values 3, 5, 9.\n\n\n\n\n\nAnything created or imported into the current R session is stored in our environment and shown in the Environment tab.\nWe’ll talk about the R data type in detail later."
  },
  {
    "objectID": "slides/03-posit.html#python-script",
    "href": "slides/03-posit.html#python-script",
    "title": "Posit Cloud ☁️",
    "section": "Python Script",
    "text": "Python Script\n\nA Python script is a .py file that contains Python code.\nTo create a Python script, go to File &gt; New &gt; Python Script, or click the green-plus icon on the topleft corner, and select Python Script."
  },
  {
    "objectID": "slides/03-posit.html#run-python-code",
    "href": "slides/03-posit.html#run-python-code",
    "title": "Posit Cloud ☁️",
    "section": "Run Python Code",
    "text": "Run Python Code\n\nRunning Python code may need to update some packages. Please say YES!\nWhen you run the Python code in the R console, or type reticulate::repl_python(), the console will switch from R to Python.\nIn the Python console &gt;&gt;&gt; quit to switch back to the R console.\n\n\n\n\n\n\n\n\n\nREPL = Read, Evaluate, Print, and Loop\nor type reticulate::repl_python()"
  },
  {
    "objectID": "slides/03-posit.html#environment-tab-1",
    "href": "slides/03-posit.html#environment-tab-1",
    "title": "Posit Cloud ☁️",
    "section": "Environment Tab",
    "text": "Environment Tab\n\nAfter we run the Python script, the object stored in the environment is\n\nObject b storing a string Hello World!\n\n\n\n\n\n\nAnything created or imported into the current R session is stored in our environment and shown in the Environment tab.\nWe’ll talk about the R data type in detail later."
  },
  {
    "objectID": "slides/03-posit.html#history-tab",
    "href": "slides/03-posit.html#history-tab",
    "title": "Posit Cloud ☁️",
    "section": "History Tab",
    "text": "History Tab\n\nThe History tab keeps a record of all previous commands.\n\n\nsave icon: save all history to a file\n\nTo Console: send the selected commands to the console.\n\nTo Source: inserted the selected commands into the current script."
  },
  {
    "objectID": "slides/03-posit.html#history-tab-1",
    "href": "slides/03-posit.html#history-tab-1",
    "title": "Posit Cloud ☁️",
    "section": "History Tab",
    "text": "History Tab\n\nThe History tab keeps a record of all previous commands.\n\n\nsave icon: save all history to a file\n\nTo Console: send the selected commands to the console.\n\nTo Source: inserted the selected commands into the current script.\n\n\n\n\nIn the console pane, use ⬆️ to show the previous commands."
  },
  {
    "objectID": "slides/03-posit.html#r-packages",
    "href": "slides/03-posit.html#r-packages",
    "title": "Posit Cloud ☁️",
    "section": "R Packages 📦",
    "text": "R Packages 📦\n\nWhen we start a R session, only built-in packages like base, stats, graphics, etc are available.\nInstalling packages is an easy way to get access to others data and functions.\n\n\n and more!\n\nA language with many great add-on packages can become a very useful language.\npackages: which is a collection of functions and data for people to use."
  },
  {
    "objectID": "slides/03-posit.html#installing-r-packages",
    "href": "slides/03-posit.html#installing-r-packages",
    "title": "Posit Cloud ☁️",
    "section": "Installing R Packages 📦",
    "text": "Installing R Packages 📦\n\n\n\nTo install a package, for example, the ggplot2 package, we use the command\n\n\ninstall.packages(\"ggplot2\")\n\n\n\n\n\n\n\n\n\n\n\n\nIn the right-bottom pane, Packages &gt; Install"
  },
  {
    "objectID": "slides/03-posit.html#loading-r-packages",
    "href": "slides/03-posit.html#loading-r-packages",
    "title": "Posit Cloud ☁️",
    "section": "Loading R Packages 📦",
    "text": "Loading R Packages 📦\n\n\n\nWhat happened when you run\n\nggplot(mpg, aes(x = displ, \n                y = hwy, \n                colour = class)) + \n    geom_point()\n\n\n\n\nTo use any function or data in ggplot2, we write ggplot2:: followed by the name of the function or data.\n\n\nggplot2::ggplot(ggplot2::mpg, \n                ggplot2::aes(\n                    x = displ, \n                    y = hwy, \n                    colour = class)\n                ) + \n    ggplot2::geom_point()\n\n\n\n\n\nWe can load the package into our R session using library().\n\nWith library(ggplot2), R knows the function and data are from the ggplot2 package.\n\n\nlibrary(ggplot2)\nggplot(mpg, aes(x = displ, \n                y = hwy, \n                colour = class)) + \n    geom_point()"
  },
  {
    "objectID": "slides/03-posit.html#help",
    "href": "slides/03-posit.html#help",
    "title": "Posit Cloud ☁️",
    "section": "Help",
    "text": "Help\n\nDon’t know how a function works or what a data set is about ❓\n👉 Simply type ? followed by the data name or function name like\n\n\n?mean\n?mpg\n\n\n\nWhat does the function mean() do? What is the size of mpg?\n\n\n\n\n\n\n\n\n\n\n\nA document will show up in the Help tab, teaching you how to use the function or explaining the data set."
  },
  {
    "objectID": "slides/03-posit.html#section-4",
    "href": "slides/03-posit.html#section-4",
    "title": "Posit Cloud ☁️",
    "section": "",
    "text": "01-Running R Script\n\nLoad R package ggplot2 into your Posit Cloud.\n\n\n## install the package if you haven't!\n________(ggplot2)\n\n\nCreate a R script named lab01-run-script.R in your 3570-project.\nCopy and paste the code below into the script, and save it.\n\n\nbar &lt;- ggplot(data = diamonds) + \n    geom_bar(mapping = aes(x = cut, fill = cut), \n             show.legend = FALSE, width = 1) + \n    theme(aspect.ratio = 1) +\n    labs(x = NULL, y = NULL)\nbar + coord_flip()\nbar + coord_polar()\n\n\nSource the script. A pretty plot showing up?!  \n\n\n\n\n\n\n\nmath3570-s25.github.io/website"
  },
  {
    "objectID": "slides/04-git.html#git-and-github",
    "href": "slides/04-git.html#git-and-github",
    "title": "Git and GitHub \n",
    "section": "Git and GitHub",
    "text": "Git and GitHub\n\n\n\n\n\n\n\n\n\n\n\n\nGit is a version control system – like Track Changes features from MS Word, on steroids.\nIt’s not the only version control system, but it’s a popular one.\n\n\n\n\n\n\n\n\n\n\n\n\nGitHub is a home for Git-based projects (repository, or repo) on the cloud – like Dropbox but much better.\nWe’ll use GitHub for web hosting homework.\n\n\n\n\nR and RStudio are two different things. Same here. Git and GitHub are two different things.\nGit is a version control system like Track Changes features from Microsoft Word, but it is much more powerful.\nBasically Git helps us keep track of changes or progress of projects, so we can more easily manage our project because we can check what we did on our project on any given day.\nI’ll talk more about version control in a minute.\nGitHub is the home for Git-based projects (repository, or repo) on the internet – like Dropbox but much better.\nOnce we put those projects on the cloud in GitHub, we share our projects with others, usually our collaborators, or the entire team, so every team member can work on this project, make changes, and Git and GitHub will record who, when, and what the changes are made.\nI don’t need to teach you data science this way, but I hope you will appreciate I introduce git/github to you because knowing version control is really important for a developer."
  },
  {
    "objectID": "slides/04-git.html#versioning",
    "href": "slides/04-git.html#versioning",
    "title": "Git and GitHub \n",
    "section": "Versioning",
    "text": "Versioning\n\n\n\n\n\nSource: Data Science in a Box Unit 1 - Deck 3\n\n\n\n\n\nSo think about this figure here. Versioning is like this. If you are playing Lego, and you want to build a house using Lego bricks, you would lay them out layer by layer, and you might along the way actually record what’s happening at each step.\nBase floor, walls, pillars, roof."
  },
  {
    "objectID": "slides/04-git.html#versioning-with-human-readable-messages",
    "href": "slides/04-git.html#versioning-with-human-readable-messages",
    "title": "Git and GitHub \n",
    "section": "Versioning with human readable messages",
    "text": "Versioning with human readable messages\n\nInformative messages: let the next person know what happened with each change.\n\n\n\n\n\n\nSource: Data Science in a Box Unit 1 - Deck 3\n\n\n\n\n\nVersion control with git feels a lit more like this, where you have the versions, but then you actually have some human readable messages.\nRemember usually there are several people working on the same project, Adding a message on a particular version of your work let other people know what changes you made in this version comparing to the previous version.\nEven the project is an individual project, adding messages remind ourselves of what we did previously at each stage of the work.\nIn Git, The first commit which is a human readable message you make in a repository is always called the first commit or initial commit.\nThen after that you get to choose what you wanna say about it.\nLike here in version 2, we have built back and front of the base, and then in version 3, finished building base, so we are actually letting the next person who come after you that could be you looking back at a project of yours or somebody else you are collaborating with know what happened with each change  \n\nInstallation instruction.\nfurniture assembly guide"
  },
  {
    "objectID": "slides/04-git.html#why-need-version-control",
    "href": "slides/04-git.html#why-need-version-control",
    "title": "Git and GitHub \n",
    "section": "Why Need Version Control",
    "text": "Why Need Version Control\n\n\nThink if you are not using version control, you very much can end up in a situation like this where you have a document you are working on, and you know we are humans feel like ok i’m almost done, I’m going to call this particular version I have final.doc.\nBut then you actually get some maybe revision comments from your advisor, and then that becomes final_rev2.doc. And you go back and forth lots of times. At the end, it’s everything like final, final3, final10, final_last whatever, it just keeps going.\nThe thing is these file names are not really very informative because final or final revisions don’t really say anything.\nBut if you really had tagged the changes you make between the final and the final 2, that could actually be informative if you actually have to go back to them."
  },
  {
    "objectID": "slides/04-git.html#how-we-use-git-and-github",
    "href": "slides/04-git.html#how-we-use-git-and-github",
    "title": "Git and GitHub \n",
    "section": "How We Use Git and GitHub",
    "text": "How We Use Git and GitHub\n\nOn GitHub, I create organization math3570-s25 and repos.\n\n\n\n\n\n\nSource: Data Science in a Box Unit 1 - Deck 3\n\n\n\n\n\nHow are we going to use Git/GitHub in this class?\nWe have a course organization (2024-spring-math-3570) I created on GitHub.\nWithin the organization, there will be a bunch of repositories I created for you.\nThink each repo as a project you will be working on. It is basically your homework assignment."
  },
  {
    "objectID": "slides/04-git.html#how-we-use-git-and-github-1",
    "href": "slides/04-git.html#how-we-use-git-and-github-1",
    "title": "Git and GitHub \n",
    "section": "How We Use Git and GitHub",
    "text": "How We Use Git and GitHub\n\nYou clone the repo I create for you to your Posit Cloud as an project.\n\n\n\n\n\n\nSource: Data Science in a Box Unit 1 - Deck 3\n\n\n\n\n\nAnd what you will do is you are going to go to your GitHub, find the repo that’s named after you, and then clone this as an rstudio project.\nWe talked about creating projects in our rstudio, but just lauching them there within Rstudio.\nThis time we are going to create a project from GitHub, and that’s called cloning"
  },
  {
    "objectID": "slides/04-git.html#how-we-use-git-and-github-2",
    "href": "slides/04-git.html#how-we-use-git-and-github-2",
    "title": "Git and GitHub \n",
    "section": "How We Use Git and GitHub",
    "text": "How We Use Git and GitHub\n\nYou push your updated work in Posit Cloud back to GitHub.\n\n\n\n\n\n\nSource: Data Science in a Box Unit 1 - Deck 3\n\n\n\n\n\nSo you are going to clone them in Posit Cloud, and then you are going to do your assignment, write R code, and finally version control your files with Git.\nSo along the way, as you make some changes, you are going to tag these changes as commits, then every once a while, you are going to push your changes back to the repo, which means that by the deadline of an assignment, your changes need to appear in your repo, because what I will be looking at for you is not what’s happening in Posit Cloud, but actually what’s happening on GitHub. The process of of uploading your new version of work into GitHub is called Push\n\nYou push your updated work in Rstudio back to GitHub, so that as your collaborator, I can see your updated work."
  },
  {
    "objectID": "slides/04-git.html#git-ready-for-data-science",
    "href": "slides/04-git.html#git-ready-for-data-science",
    "title": "Git and GitHub \n",
    "section": "Git Ready for Data Science",
    "text": "Git Ready for Data Science\n\n\nGo to https://github.com/ to create a GitHub account if you don’t have one.\n\nUse the same username and email address of your Posit Cloud.\n\n\n\nAccount (topright) &gt; Settings\n\n\nEmails &gt; Uncheck “Keep my email address private” (Link your R/Python work to GitHub)\n\nPublic Profile &gt; Name and nice picture!\n\n\nShare your GitHub username at https://forms.office.com/r/RUmTn3gadG, so I can invite you to join our course organization math3570-s25.\n\n\n\nVerify your GitHub email Adjust your GitHub settings for a more pleasant GitHub experience.\nWe’ll work with R, RStudio, Git, and GitHub together, like a real data scientist!"
  },
  {
    "objectID": "slides/04-git.html#git-ready-for-data-science-1",
    "href": "slides/04-git.html#git-ready-for-data-science-1",
    "title": "Git and GitHub \n",
    "section": "Git Ready for Data Science",
    "text": "Git Ready for Data Science\n\nPlease accept my invitation to join the GitHub organization math3570-s25.\n\n\n\nuse ghclass_code.R and add usernames in students vector.\nCheck Who is already in and make sure there are 29 of them."
  },
  {
    "objectID": "slides/04-git.html#git-and-github-tips",
    "href": "slides/04-git.html#git-and-github-tips",
    "title": "Git and GitHub \n",
    "section": "Git and GitHub Tips",
    "text": "Git and GitHub Tips\n\nPosit Cloud has installed Git for us! 😄\nThere are millions of git commands, and very few people know them all.\n99% of the time you will use Git to add, commit, push, and pull.\n\nok, that’s an exaggeration, but there are a lot of them\n\n\n\n\nIf you google for help and this is the solution…\nSkip that and move on to the next resource!\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe will be doing Git things and interfacing with GitHub through RStudio. \n\nIf you google for help you might come across methods for doing these things in the command line.\nSkip that and move on to the next resource unless you feel comfortable trying it out."
  },
  {
    "objectID": "slides/04-git.html#connect-posit-cloud-and-github-step-1",
    "href": "slides/04-git.html#connect-posit-cloud-and-github-step-1",
    "title": "Git and GitHub \n",
    "section": "Connect Posit Cloud and GitHub: Step 1",
    "text": "Connect Posit Cloud and GitHub: Step 1\n\nPosit Cloud cannot recognize your GitHub account unless you connect them each other.\nIn Posit Cloud, click on your name on the top-right corner to open the right menu.\nClick on Authentication."
  },
  {
    "objectID": "slides/04-git.html#connect-posit-cloud-and-github-step-2",
    "href": "slides/04-git.html#connect-posit-cloud-and-github-step-2",
    "title": "Git and GitHub \n",
    "section": "Connect Posit Cloud and GitHub: Step 2",
    "text": "Connect Posit Cloud and GitHub: Step 2\n\nIn the Authentication window, check the box for Enabled.\n\n\n\nWhen check Enabled, will jump to GitHub page shown in the next."
  },
  {
    "objectID": "slides/04-git.html#connect-posit-cloud-and-github-step-3",
    "href": "slides/04-git.html#connect-posit-cloud-and-github-step-3",
    "title": "Git and GitHub \n",
    "section": "Connect Posit Cloud and GitHub: Step 3",
    "text": "Connect Posit Cloud and GitHub: Step 3\n\nFor your GitHub page, click on the green box that says “Authorize posit-hosted”."
  },
  {
    "objectID": "slides/04-git.html#connect-posit-cloud-and-github-step-4",
    "href": "slides/04-git.html#connect-posit-cloud-and-github-step-4",
    "title": "Git and GitHub \n",
    "section": "Connect Posit Cloud and GitHub: Step 4",
    "text": "Connect Posit Cloud and GitHub: Step 4\n\n\n\nBack to the Authentication of Posit Cloud, check Private repo access also enabled.\n\n\nMake sure math3570-s25 shows up under Organization access.\nClick on Grant.\nClick on the green box “Authorize posit-hosted”.\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhen check Private repo access also enabled, will jump to GitHub page as shown."
  },
  {
    "objectID": "slides/04-git.html#connect-posit-cloud-and-github-step-5",
    "href": "slides/04-git.html#connect-posit-cloud-and-github-step-5",
    "title": "Git and GitHub \n",
    "section": "Connect Posit Cloud and GitHub: Step 5",
    "text": "Connect Posit Cloud and GitHub: Step 5\n\nOnce you’re done, both of these boxes should be checked."
  },
  {
    "objectID": "slides/04-git.html#connect-posit-cloud-and-github-step-6",
    "href": "slides/04-git.html#connect-posit-cloud-and-github-step-6",
    "title": "Git and GitHub \n",
    "section": "Connect Posit Cloud and GitHub: Step 6",
    "text": "Connect Posit Cloud and GitHub: Step 6\n\nConfirm that you’ve linked up your GitHub and Posit Cloud accounts GitHub settings &gt; Applications. Should see Posit Cloud listed as an authorized app under Authorized OAuth Apps.\n\n\n\nIf you see RStudio is under the Authorized Apps, congratulations! Your RStudio and GitHub are now linked together!"
  },
  {
    "objectID": "slides/04-git.html#github-to-posit-cloud-step-1",
    "href": "slides/04-git.html#github-to-posit-cloud-step-1",
    "title": "Git and GitHub \n",
    "section": "GitHub to Posit Cloud: Step 1",
    "text": "GitHub to Posit Cloud: Step 1\n\nEach of your assignments will begin with the following steps.\nGo to the repo named hw00-yourusername I created for you.\n\n\nhttps://mine-cetinkaya-rundel.github.io/teach-r-online/ - OK. Now let’s see how to clone a repo in GitHub to your RStudio.\n\nUse the code ::: {.cell layout-align=“center”}\n\nThis repo contains a template you can build on to complete your assignment.\n\n:::"
  },
  {
    "objectID": "slides/04-git.html#github-to-posit-cloud-step-2",
    "href": "slides/04-git.html#github-to-posit-cloud-step-2",
    "title": "Git and GitHub \n",
    "section": "GitHub to Posit Cloud: Step 2",
    "text": "GitHub to Posit Cloud: Step 2\n\n\nClick on the green Code button, select HTTPS.\nClick on the clipboard icon on the right to copy the repo URL, such as https://github.com/math3570-s25/hw00-chenghanyu.git"
  },
  {
    "objectID": "slides/04-git.html#github-to-posit-cloud-step-3",
    "href": "slides/04-git.html#github-to-posit-cloud-step-3",
    "title": "Git and GitHub \n",
    "section": "GitHub to Posit Cloud: Step 3",
    "text": "GitHub to Posit Cloud: Step 3\n\nGo to Posit Cloud and into the course workspace 2025-spring-math-3570.\nNew Project &gt; New Project from Git Repo.\n\n\nYou will need to click on the down arrow next to the New Project button to see this option."
  },
  {
    "objectID": "slides/04-git.html#github-to-posit-cloud-step-4",
    "href": "slides/04-git.html#github-to-posit-cloud-step-4",
    "title": "Git and GitHub \n",
    "section": "GitHub to Posit Cloud: Step 4",
    "text": "GitHub to Posit Cloud: Step 4\n\nCopy and paste the URL of your assignment repo into the dialog box.\nHit OK, and you’re good to go!"
  },
  {
    "objectID": "slides/04-git.html#github-to-posit-cloud-step-5",
    "href": "slides/04-git.html#github-to-posit-cloud-step-5",
    "title": "Git and GitHub \n",
    "section": "GitHub to Posit Cloud: Step 5",
    "text": "GitHub to Posit Cloud: Step 5\n\nClick hw00-yourusername to do your assignment in Posit Cloud!\n\n\n\nDone! We learned the entire process of cloning a repo on GitHub to Posit Cloud as a project.\nNext, we’ll see how to keep your revision record (commit) and send (push) the latest revised version of your work from Posit Cloud to GitHub!"
  },
  {
    "objectID": "slides/04-git.html#personal-access-token-pat-step-1",
    "href": "slides/04-git.html#personal-access-token-pat-step-1",
    "title": "Git and GitHub \n",
    "section": "Personal Access Token (PAT): Step 1",
    "text": "Personal Access Token (PAT): Step 1\n\nGitHub has removed the support for Password Authentication for Git operations.\nBefore we can send our work in Posit Cloud to GitHub, we need Personal Access Token (PAT)\nSettings &gt; Developer settings\n\n\n\nGitHub has removed the support for Password Authentication for Git operations.\nfor more safety.\nfrom 08/13/2021."
  },
  {
    "objectID": "slides/04-git.html#personal-access-token-pat-step-2",
    "href": "slides/04-git.html#personal-access-token-pat-step-2",
    "title": "Git and GitHub \n",
    "section": "Personal Access Token (PAT): Step 2",
    "text": "Personal Access Token (PAT): Step 2"
  },
  {
    "objectID": "slides/04-git.html#personal-access-token-pat-step-3",
    "href": "slides/04-git.html#personal-access-token-pat-step-3",
    "title": "Git and GitHub \n",
    "section": "Personal Access Token (PAT): Step 3",
    "text": "Personal Access Token (PAT): Step 3"
  },
  {
    "objectID": "slides/04-git.html#personal-access-token-pat-step-4",
    "href": "slides/04-git.html#personal-access-token-pat-step-4",
    "title": "Git and GitHub \n",
    "section": "Personal Access Token (PAT): Step 4",
    "text": "Personal Access Token (PAT): Step 4"
  },
  {
    "objectID": "slides/04-git.html#personal-access-token-pat-step-5",
    "href": "slides/04-git.html#personal-access-token-pat-step-5",
    "title": "Git and GitHub \n",
    "section": "Personal Access Token (PAT): Step 5",
    "text": "Personal Access Token (PAT): Step 5\n\nCopy and paste your PAT to a secrete and safe space!!"
  },
  {
    "objectID": "slides/04-git.html#posit-cloud-to-github-step-1---edit-your-file",
    "href": "slides/04-git.html#posit-cloud-to-github-step-1---edit-your-file",
    "title": "Git and GitHub \n",
    "section": "Posit Cloud to GitHub: Step 1 - Edit your file",
    "text": "Posit Cloud to GitHub: Step 1 - Edit your file\n\nOpen the quarto file hw-00-test.qmd, in YAML change the author to your name.\nClick Render to generate your beautiful document. (If asked to install any packages, please do!)"
  },
  {
    "objectID": "slides/04-git.html#posit-cloud-to-github-step-2---commit-changes",
    "href": "slides/04-git.html#posit-cloud-to-github-step-2---commit-changes",
    "title": "Git and GitHub \n",
    "section": "Posit Cloud to GitHub: Step 2 - Commit changes",
    "text": "Posit Cloud to GitHub: Step 2 - Commit changes\n\nGo to the Git tab in your RStudio.\nClick on Commit. This shows you the difference between the last committed state of the document and its current state that includes your changes.\nCheck Staged box to add files to be committed.\nWrite “Update author’s name” in the Commit message box and hit Commit."
  },
  {
    "objectID": "slides/04-git.html#posit-cloud-to-github-step-3---push-changes",
    "href": "slides/04-git.html#posit-cloud-to-github-step-3---push-changes",
    "title": "Git and GitHub \n",
    "section": "Posit Cloud to GitHub: Step 3 - Push changes",
    "text": "Posit Cloud to GitHub: Step 3 - Push changes\n\nWe’ve made an update and committed this change locally.\nIt’s time to push the changes to your repo on GitHub, so that others (Dr. Yu) can see your changes.\nClick on Push.\nIn the prompted dialogue box, enter your GitHub user name, and your password (PAT).\n\n\nhttps://inbo.github.io/git-course/course_rstudio.html"
  },
  {
    "objectID": "slides/04-git.html#posit-cloud-to-github-step-3---updated-repo",
    "href": "slides/04-git.html#posit-cloud-to-github-step-3---updated-repo",
    "title": "Git and GitHub \n",
    "section": "Posit Cloud to GitHub: Step 3 - Updated Repo",
    "text": "Posit Cloud to GitHub: Step 3 - Updated Repo\n\nBack to your GitHub repo and refresh it.\nThe online repo is now synced with your local project in Posit Cloud."
  },
  {
    "objectID": "slides/04-git.html#resources",
    "href": "slides/04-git.html#resources",
    "title": "Git and GitHub \n",
    "section": "Resources",
    "text": "Resources\n\n\n\nCreate a personal access token (PAT)\nTwo-factor authentication\nGit hands-on session within RStudio\nHappy Git and GitHub for the useR\nHappier version control with Git and GitHub\n\n\n\n\n\n\n\n\n\n\n\n\nExercise: Click on the more button in the git pane and select Shell Type git config –global credential.helper store Type exit to quit the shell \n\n\n\n\n\n\n\n\n\nmath3570-s25.github.io/website"
  },
  {
    "objectID": "slides/12-dplyr-1.html#section-1",
    "href": "slides/12-dplyr-1.html#section-1",
    "title": "Data Wrangling - one data frame 🛠",
    "section": "",
    "text": "Welcome back\nThis week: introduce tools of tidyverse for data wrangling\nlearn how to easily clean or transform our data so that we can extract some important properties of the data, and the data are ready for visualization, modeling and analysis."
  },
  {
    "objectID": "slides/12-dplyr-1.html#grammar-of-data-wrangling-dplyr",
    "href": "slides/12-dplyr-1.html#grammar-of-data-wrangling-dplyr",
    "title": "Data Wrangling - one data frame 🛠",
    "section": "Grammar of Data Wrangling: dplyr 📦",
    "text": "Grammar of Data Wrangling: dplyr 📦\n\nbased on the concepts of functions as verbs that manipulate data frames\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmutate: create new columns from the existing1\n\n\nfilter: pick rows matching criteria\n\n\nslice: pick rows using index(es)\n\n\ndistinct: filter for unique rows\n\n\nselect: pick columns by name\n\n\nsummarise: reduce variables to values\n\ngroup_by: for grouped operations\n\narrange: reorder rows\n… (many more)\n\n\n\n\nSo Grammar of Data Wrangling is based on the concepts of functions as verbs that manipulate data frames. Using these verbs in coding is simple, intuitive and straightforward. They let you know what you are doing on your data.\nAnd the package that does this is called dplyr.\nThis package offers a variety of functions each of which is a verb, as listed here, mutate, filter, slice, distinct. Is distinct a verb??\nthere is no rule without an exception\nAnyway, we will be going through these functions that help us manipulate or transform our data. OK\nWe can use tibble::add_column() to add one or more columns to an existing data frame."
  },
  {
    "objectID": "slides/12-dplyr-1.html#rules-of-dplyr-functions",
    "href": "slides/12-dplyr-1.html#rules-of-dplyr-functions",
    "title": "Data Wrangling - one data frame 🛠",
    "section": "Rules of dplyr Functions",
    "text": "Rules of dplyr Functions\n\n\n\nFirst argument is always a data frame\nSubsequent arguments say what to do with that data frame\nAlways return a data frame\nDon’t modify in place\n\n\n\n\nSo there are four rules of dplyr functions.\nFirst argument is always a data frame\n\nSubsequent arguments say what to do with that data frame\n\nAlways return a data frame, so data frame in, data frame out.\nDon’t modify in place, meaning that when we apply a function of dplyr to the data, we are not changing that data frame. We have option to re-save our result, either overwrite the existing data frame that we have or as a separate object, but we are not modifying the data frame in place."
  },
  {
    "objectID": "slides/12-dplyr-1.html#data-us-gun-murders-by-state-for-2010",
    "href": "slides/12-dplyr-1.html#data-us-gun-murders-by-state-for-2010",
    "title": "Data Wrangling - one data frame 🛠",
    "section": "Data: US gun murders by state for 2010",
    "text": "Data: US gun murders by state for 2010\n\n(murders &lt;- read_csv(\"./data/murders.csv\"))\n\n# A tibble: 51 × 5\n  state      abb   region population total\n  &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt;\n1 Alabama    AL    South     4779736   135\n2 Alaska     AK    West       710231    19\n3 Arizona    AZ    West      6392017   232\n4 Arkansas   AR    South     2915918    93\n5 California CA    West     37253956  1257\n6 Colorado   CO    West      5029196    65\n# ℹ 45 more rows\n\n\n\nThe data set we are going to use as an illustrative example is again the murders data set in the dslabs package with the book Intro to Data Science\nIt is of R base data frame type with 51 observations and 5 variables.\nNotice that region variable here is a factor, which may not make sense and we can convert it into a character vector if needed.\nAnd we can change its data type to modern tibble data frame, again use as_tibble() function."
  },
  {
    "objectID": "slides/12-dplyr-1.html#adding-a-new-variable-column-with-mutate",
    "href": "slides/12-dplyr-1.html#adding-a-new-variable-column-with-mutate",
    "title": "Data Wrangling - one data frame 🛠",
    "section": "Adding a New Variable (Column) with mutate()\n",
    "text": "Adding a New Variable (Column) with mutate()\n\n\n\ndplyr::mutate() takes\n\na data frame as the 1st argument\nthe name and values of the variable as the 2nd argument using format name = values.\n\n\n\n\n(murders &lt;- murders |&gt;  \n     mutate(rate = total / population * 100000)) #&lt;&lt;\n\n# A tibble: 51 × 6\n  state      abb   region population total  rate\n  &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Alabama    AL    South     4779736   135  2.82\n2 Alaska     AK    West       710231    19  2.68\n3 Arizona    AZ    West      6392017   232  3.63\n4 Arkansas   AR    South     2915918    93  3.19\n5 California CA    West     37253956  1257  3.37\n6 Colorado   CO    West      5029196    65  1.29\n# ℹ 45 more rows\n\n\n\n\ntotal and population inside the function are not defined in our R environment.\ndplyr functions know to look for variables in the data frame provided in the 1st argument.\n\n\nOK now let’s begin playing the the data set.\nFirst, we can add a New Variable into the existing data set with the function mutate().\nRemember, variables are stored by columns, and so adding new variables means add more columns to the data set.\nThe function mutate() takes the data frame as a first argument and the name and values of the variable as a second argument using the convention name = values.\nHere, I compute the murder rate as the total number of murders divided by population and times 100,000. So the rate means the incidence rate per 100,000 people\n\ntotal and population inside the function are not defined in our R environment, but we didn’t get an error.\nFunctions in dplyr know to look for variables in the data frame provided in the first argument. total will have the values in murders_tbl$total.\nNow you can see the new data set has a new column variable rate shown in the last column.\nUse relocate() to change column positions, using the same syntax as select() to make it easy to move blocks of columns at once. \n\n\nmutate() creates new columns that are functions of existing variables. It can also modify (if the name is the same as an existing column) and delete columns (by setting their value to NULL). mutate( .data, …, .by = NULL, .keep = c(“all”, “used”, “unused”, “none”), .before = NULL, .after = NULL )"
  },
  {
    "objectID": "slides/12-dplyr-1.html#filtering-observations-rows-with-filter",
    "href": "slides/12-dplyr-1.html#filtering-observations-rows-with-filter",
    "title": "Data Wrangling - one data frame 🛠",
    "section": "Filtering Observations (Rows) with filter()\n",
    "text": "Filtering Observations (Rows) with filter()\n\n\n\ndplyr::filter() takes a\n\ndata frame as the 1st argument\n\nconditional statement as the 2nd. (pick rows matching criteria)\n\n\n\n\n# filter the data table to only show the entries for which \n# the murder rate is lower than 0.7\nmurders |&gt; \n    filter(rate &lt; 0.7) #&lt;&lt;\n\n# A tibble: 5 × 6\n  state         abb   region        population total  rate\n  &lt;chr&gt;         &lt;chr&gt; &lt;chr&gt;              &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Hawaii        HI    West             1360301     7 0.515\n2 Iowa          IA    North Central    3046355    21 0.689\n3 New Hampshire NH    Northeast        1316470     5 0.380\n4 North Dakota  ND    North Central     672591     4 0.595\n5 Vermont       VT    Northeast         625741     2 0.320\n\n\n\nAll right. We add columns by mutate() function, and we pick observations (rows) with filter() function.\n\nfilter() function again takes the data frame as the first argument and then the conditional statement as the second.\nSo we pick rows by matching the criteria of the conditional statement in the second argument of the filter() function.\nFor example, here I filter the data table to only show the obs for which the murder rate is lower than 0.71 Note that when a condition evaluates to NA the row will be dropped, unlike base subsetting with [."
  },
  {
    "objectID": "slides/12-dplyr-1.html#filter-for-many-conditions-at-once",
    "href": "slides/12-dplyr-1.html#filter-for-many-conditions-at-once",
    "title": "Data Wrangling - one data frame 🛠",
    "section": "\nfilter() for Many Conditions at Once",
    "text": "filter() for Many Conditions at Once\n\nmurders |&gt;  \n    filter(rate &gt; 0.1 & rate &lt; 0.7,  #&lt;&lt;\n           region == \"Northeast\")  #&lt;&lt;\n\n# A tibble: 2 × 6\n  state         abb   region    population total  rate\n  &lt;chr&gt;         &lt;chr&gt; &lt;chr&gt;          &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 New Hampshire NH    Northeast    1316470     5 0.380\n2 Vermont       VT    Northeast     625741     2 0.320\n\n\n\nWe can actually use several conditions at once to filter the observations\nFor example, here we want the observations whose murder rate is between 0.1 and 0.71, and their region is Northeast.\nYou can see that only two observations satisfy the conditions, New Hampshire and Vermont.\nUse one single & to have a logical vector\nYou can also write rate &gt;= 0.1, rate &lt;= 0.71. This way we separate the condition rate &gt;= 0.1 & rate &lt;= 0.71 into 2 conditions.\nTheoretically You can provide as many conditions as you want. The conditions are combined with &"
  },
  {
    "objectID": "slides/12-dplyr-1.html#logical-operators",
    "href": "slides/12-dplyr-1.html#logical-operators",
    "title": "Data Wrangling - one data frame 🛠",
    "section": "Logical Operators",
    "text": "Logical Operators\n\n\n\n\n\n\n\n\noperator\ndefinition\noperator\ndefinition\n\n\n\n&lt;\nless than\n\nx | y\n\n\nx OR y\n\n\n\n&lt;=\nless than or equal to\nis.na(x)\nif x is NA\n\n\n\n&gt;\ngreater than\n!is.na(x)\nif x is not NA\n\n\n\n&gt;=\ngreater than or equal to\nx %in% y\nif x is in y\n\n\n\n==\nexactly equal to\n!(x %in% y)\nif x is not in y\n\n\n\n!=\nnot equal to\n!x\nnot x\n\n\n\nx & y\n\nx AND y\n\n\n\n\n\n\n\nWe have talked about this. These are logical operators you can use in the conditions of the filter() function."
  },
  {
    "objectID": "slides/12-dplyr-1.html#slice-for-certain-rows-using-indexes",
    "href": "slides/12-dplyr-1.html#slice-for-certain-rows-using-indexes",
    "title": "Data Wrangling - one data frame 🛠",
    "section": "\nslice() for Certain Rows using Indexes",
    "text": "slice() for Certain Rows using Indexes\n\n# 3rd to 6th row\nmurders |&gt; \n    slice(3:6)\n\n# A tibble: 4 × 6\n  state      abb   region population total  rate\n  &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Arizona    AZ    West      6392017   232  3.63\n2 Arkansas   AR    South     2915918    93  3.19\n3 California CA    West     37253956  1257  3.37\n4 Colorado   CO    West      5029196    65  1.29\n\n\n\n\nHow do we subset rows using matrix indexing?\n\n\n\n\nmurders[3:6, ]\n\n# A tibble: 4 × 6\n  state      abb   region population total  rate\n  &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Arizona    AZ    West      6392017   232  3.63\n2 Arkansas   AR    South     2915918    93  3.19\n3 California CA    West     37253956  1257  3.37\n4 Colorado   CO    West      5029196    65  1.29\n\n\n\nOK. Slice. We use slice() function to subset observations or rows using indexes.\nSame as other functions, the first argument is a data frame, so I use the pipe operator sending murders_tbl data set to the slice function.\nIt is the same as treating a data drame as a matrix and subsetting the rows, which is the usual way we do before learning this function.\nSo here we extract row 3 to row 6 of the data set.\nmicrobenchmark::microbenchmark(slice(murders_tbl, 3:6), murders_tbl[3:6, ])\nYou cannot(can?) write murders_tbl[3:6, ] as a function call. How? slice_head() and slice_tail() select the first or last rows. slice_sample() randomly selects rows. slice_min() and slice_max() select rows with highest or lowest values of a variable."
  },
  {
    "objectID": "slides/12-dplyr-1.html#distinct-to-filter-for-unique-rows",
    "href": "slides/12-dplyr-1.html#distinct-to-filter-for-unique-rows",
    "title": "Data Wrangling - one data frame 🛠",
    "section": "\ndistinct() to Filter for Unique Rows",
    "text": "distinct() to Filter for Unique Rows\n\n# Select only unique/distinct rows from a data frame\nmurders |&gt; distinct(region)  ## default\n\n# A tibble: 4 × 1\n  region       \n  &lt;chr&gt;        \n1 South        \n2 West         \n3 Northeast    \n4 North Central\n\nmurders |&gt; distinct(region, .keep_all = TRUE) ## keep all other variables\n\n# A tibble: 4 × 6\n  state       abb   region        population total  rate\n  &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;              &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Alabama     AL    South            4779736   135  2.82\n2 Alaska      AK    West              710231    19  2.68\n3 Connecticut CT    Northeast        3574097    97  2.71\n4 Illinois    IL    North Central   12830632   364  2.84\n\n\n\nWe can use distinct() function to select only unique/distinct rows from a data frame.\nFor example here, we use variable region to decide the unique rows. By default, the function only gives us the unique values of the variable region.\nDo you wonder why we have the order South, West, Northeast, and North Central?\nActually, these values are the values of some rows.\nIf we keep all variables, we see that the south is the south for Alabama, west for alaska, northeast for connecticut, and North central for illinois.\ndistinct() functions grabs rows that first has each of the unique values of region variable.\nSo Alabama is the first observation that has value South, Alaska is the first observation that has value West, Connecticut is the first observation that has value Northeast, and Illinois is the first observation that has value North Central.\nmicrobenchmark::microbenchmark(distinct(murders_tbl, region), as_tibble(unique(murders_tbl$region)))"
  },
  {
    "objectID": "slides/12-dplyr-1.html#distinct-grabs-first-row-of-the-unique-value",
    "href": "slides/12-dplyr-1.html#distinct-grabs-first-row-of-the-unique-value",
    "title": "Data Wrangling - one data frame 🛠",
    "section": "\ndistinct() Grabs First Row of The Unique Value",
    "text": "distinct() Grabs First Row of The Unique Value\n\nmurders |&gt; distinct(region, .keep_all = TRUE)\n\n# A tibble: 4 × 6\n  state       abb   region        population total  rate\n  &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;              &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Alabama     AL    South            4779736   135  2.82\n2 Alaska      AK    West              710231    19  2.68\n3 Connecticut CT    Northeast        3574097    97  2.71\n4 Illinois    IL    North Central   12830632   364  2.84\n\n\n\nmurders |&gt; slice(1:5)\n\n# A tibble: 5 × 6\n  state      abb   region population total  rate\n  &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Alabama    AL    South     4779736   135  2.82\n2 Alaska     AK    West       710231    19  2.68\n3 Arizona    AZ    West      6392017   232  3.63\n4 Arkansas   AR    South     2915918    93  3.19\n5 California CA    West     37253956  1257  3.37"
  },
  {
    "objectID": "slides/12-dplyr-1.html#selecting-columns-with-select",
    "href": "slides/12-dplyr-1.html#selecting-columns-with-select",
    "title": "Data Wrangling - one data frame 🛠",
    "section": "Selecting Columns with select()\n",
    "text": "Selecting Columns with select()\n\n\nIn dplyr::select(), the 1st argument is a data frame, followed by variable names being selected in the data.\nThe order of variable names matters!\n\n\nnames(murders)\n\n[1] \"state\"      \"abb\"        \"region\"     \"population\" \"total\"     \n[6] \"rate\"      \n\n\n\n# select three columns, assign this to a new object\nmurders |&gt; select(region, rate, state)\n\n# A tibble: 51 × 3\n  region  rate state     \n  &lt;chr&gt;  &lt;dbl&gt; &lt;chr&gt;     \n1 South   2.82 Alabama   \n2 West    2.68 Alaska    \n3 West    3.63 Arizona   \n4 South   3.19 Arkansas  \n5 West    3.37 California\n6 West    1.29 Colorado  \n# ℹ 45 more rows\n\n\n\nfilter(), slice() and distinct()are functions for picking rows.\nselect() is a function for picking columns or variables.\nHere, I select three columns region, rate, and state.\nNotice that the order of variable names matters! The original data set has variable order “state” “abb” “region” “population” “total” “rate”.\nBut the resulting data frame will have the variables or columns ordered as region, rate, state because this is the order you specify in the select().\nIf you don’t know the column names, you can select by position. murders_tbl %&gt;% select(3, 6, 1)"
  },
  {
    "objectID": "slides/12-dplyr-1.html#select-to-exclude-variables",
    "href": "slides/12-dplyr-1.html#select-to-exclude-variables",
    "title": "Data Wrangling - one data frame 🛠",
    "section": "\nselect() to Exclude Variables",
    "text": "select() to Exclude Variables\n\n## exclude variable population\nmurders |&gt; select(-population)\n\n# A tibble: 51 × 5\n  state      abb   region total  rate\n  &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt;\n1 Alabama    AL    South    135  2.82\n2 Alaska     AK    West      19  2.68\n3 Arizona    AZ    West     232  3.63\n4 Arkansas   AR    South     93  3.19\n5 California CA    West    1257  3.37\n6 Colorado   CO    West      65  1.29\n# ℹ 45 more rows\n\n\n\nIf you want to exclude some variables, just provide a vector of variables you want to remove, and put a minus sign in front of it.\nHere we remove the population variable."
  },
  {
    "objectID": "slides/12-dplyr-1.html#select-a-range-of-variables",
    "href": "slides/12-dplyr-1.html#select-a-range-of-variables",
    "title": "Data Wrangling - one data frame 🛠",
    "section": "\nselect() a Range of Variables",
    "text": "select() a Range of Variables\n\nnames(murders)\n\n[1] \"state\"      \"abb\"        \"region\"     \"population\" \"total\"     \n[6] \"rate\"      \n\n## from region to rate\nmurders |&gt; select(region:rate)\n\n# A tibble: 51 × 4\n  region population total  rate\n  &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 South     4779736   135  2.82\n2 West       710231    19  2.68\n3 West      6392017   232  3.63\n4 South     2915918    93  3.19\n5 West     37253956  1257  3.37\n6 West      5029196    65  1.29\n# ℹ 45 more rows\n\n\n\nWe can also select a range of variables.\nFor example, we select all variables for region to rate by using region:rate, just as we create a sequence of numbers from 1 to 5 using 1:5.\nmurders_tbl %&gt;% select(3:6)"
  },
  {
    "objectID": "slides/12-dplyr-1.html#select-variables-with-certain-characteristics",
    "href": "slides/12-dplyr-1.html#select-variables-with-certain-characteristics",
    "title": "Data Wrangling - one data frame 🛠",
    "section": "\nselect() Variables with Certain Characteristics",
    "text": "select() Variables with Certain Characteristics\n\n\nstarts_with() is a tidy-select helper function.\n\n\nmurders |&gt; select(starts_with(\"r\"))\n\n# A tibble: 51 × 2\n  region  rate\n  &lt;chr&gt;  &lt;dbl&gt;\n1 South   2.82\n2 West    2.68\n3 West    3.63\n4 South   3.19\n5 West    3.37\n6 West    1.29\n# ℹ 45 more rows\n\n\n\nWe can also some helper functions to select variables with some condition.\nFor example, we can use a helper function starts_with() to select variables whose name starts with letter “r”.\nAnd so region and rate variables are selected."
  },
  {
    "objectID": "slides/12-dplyr-1.html#select-variables-with-certain-characteristics-1",
    "href": "slides/12-dplyr-1.html#select-variables-with-certain-characteristics-1",
    "title": "Data Wrangling - one data frame 🛠",
    "section": "\nselect() Variables with Certain Characteristics",
    "text": "select() Variables with Certain Characteristics\n\n\nends_with() is a tidy-select helper function.\n\n\nmurders |&gt; select(ends_with(\"ion\"))\n\n# A tibble: 51 × 2\n  region population\n  &lt;chr&gt;       &lt;dbl&gt;\n1 South     4779736\n2 West       710231\n3 West      6392017\n4 South     2915918\n5 West     37253956\n6 West      5029196\n# ℹ 45 more rows\n\n\n\nWe can also select variables whose name ends with “ion”\nAnd so region and population variables are selected."
  },
  {
    "objectID": "slides/12-dplyr-1.html#tidy-select-helpers",
    "href": "slides/12-dplyr-1.html#tidy-select-helpers",
    "title": "Data Wrangling - one data frame 🛠",
    "section": "\ntidy-select Helpers1\n",
    "text": "tidy-select Helpers1\n\n\n\nstarts_with(): Starts with a prefix\n\nends_with(): Ends with a suffix\n\ncontains(): Contains a literal string\n\nnum_range(): Matches a numerical range like x01, x02, x03\n\none_of(): Matches variable names in a character vector\n\neverything(): Matches all variables\n\nlast_col(): Select last variable, possibly with an offset\n\nmatches(): Matches a regular expression (a sequence of symbols/characters expressing a string/pattern to be searched for within text)\n\n\nHere is a list of select helpers.\nI am not able to go through every helper in detail. But they can be very useful depending on your goal.\nAbsolutely check their help page to learn how to use them and review the examples in the help page. OK.\nSee help for any of these functions for more info, e.g. ?num_range."
  },
  {
    "objectID": "slides/12-dplyr-1.html#rationale-for-pipe-operator",
    "href": "slides/12-dplyr-1.html#rationale-for-pipe-operator",
    "title": "Data Wrangling - one data frame 🛠",
    "section": "Rationale for Pipe Operator",
    "text": "Rationale for Pipe Operator\n\nHow do we show three variables (state, region, rate) for states that have murder rates below 0.7?\n\n\nMethod 1: Define the intermediate object new_table\n\n\n\nnew_table &lt;- select(murders, state, region, rate) \nfilter(new_table, rate &lt; 0.7)\n\n# A tibble: 5 × 3\n  state         region         rate\n  &lt;chr&gt;         &lt;chr&gt;         &lt;dbl&gt;\n1 Hawaii        West          0.515\n2 Iowa          North Central 0.689\n3 New Hampshire Northeast     0.380\n4 North Dakota  North Central 0.595\n5 Vermont       Northeast     0.320\n\n\n\nRemember we talked about the pipe operator, right? But we haven’t really used it often.\nBut it kinda make much sense to use the pipe operator for data manipulation using dplyr functions.\nBecause the first argument of dplyr function is always a data frame and its function output is also a data frame, which can be the input of another dplyr function.\nSo if we wanna manipulate our data set via several different actions using the dplyr functions step by step, pipe operator can be very useful. Let’s see why.\nHow do we show three variables (state, region, rate) for states that have murder rate below 0.71?\nWe can first select three variables state, region, rate, and save the resulting output to an object new_table, and then apply filter() function on the new_table to get the observations having murder rate less than 0.71\nIn fact, the object new_table is unnecessary. The table is not what we want, and any object created in the R environment occupies some memory space."
  },
  {
    "objectID": "slides/12-dplyr-1.html#rationale-for-pipe-operator-1",
    "href": "slides/12-dplyr-1.html#rationale-for-pipe-operator-1",
    "title": "Data Wrangling - one data frame 🛠",
    "section": "Rationale for Pipe Operator",
    "text": "Rationale for Pipe Operator\n\nHow do we show three variables (state, region, rate) for states that have murder rates below 0.7?\n\n\nMethod 2: Apply one function onto the other with no intermediate object\n\n\n## not so easy to read and understand\nfilter(select(murders, state, region, rate), rate &lt; 0.7) \n\n# A tibble: 5 × 3\n  state         region         rate\n  &lt;chr&gt;         &lt;chr&gt;         &lt;dbl&gt;\n1 Hawaii        West          0.515\n2 Iowa          North Central 0.689\n3 New Hampshire Northeast     0.380\n4 North Dakota  North Central 0.595\n5 Vermont       Northeast     0.320\n\n\n\nIf we don’t use new_table object, we can put the code select(murders_tbl, state, region, rate) directly on the first argument of filter() function as the data input.\nThis gives us the same resulting data frame.\nHowever, the code is not very easy to read and understand because when we read the code from left to right, it starts with filter, and then select, but we actually do the selection first. Also, the second argument or the condition used in the filter() function is at the end of the code, which is far away from the function name at the beginning."
  },
  {
    "objectID": "slides/12-dplyr-1.html#rationale-for-pipe-operator-2",
    "href": "slides/12-dplyr-1.html#rationale-for-pipe-operator-2",
    "title": "Data Wrangling - one data frame 🛠",
    "section": "Rationale for Pipe Operator",
    "text": "Rationale for Pipe Operator\n\nThe code that looks like a verbal description of what we want to do without intermediate objects:\n\n\ndata &gt; select() &gt; data after selecting &gt; filter() &gt; data after selecting and filtering\n\n\nmurders |&gt; \n    select(state, region, rate) |&gt;  \n    filter(rate &lt; 0.7)\n\n# A tibble: 5 × 3\n  state         region         rate\n  &lt;chr&gt;         &lt;chr&gt;         &lt;dbl&gt;\n1 Hawaii        West          0.515\n2 Iowa          North Central 0.689\n3 New Hampshire Northeast     0.380\n4 North Dakota  North Central 0.595\n5 Vermont       Northeast     0.320\n\n\n\nPipe Operator let us write code that looks more like a description of what we want to do without intermediate objects.\nWe start with the original data set, then we select variables, and then we filter observations.\nSo our code can be like It’s more clear and intuitive, right?"
  },
  {
    "objectID": "slides/12-dplyr-1.html#summarizing-data-summarize",
    "href": "slides/12-dplyr-1.html#summarizing-data-summarize",
    "title": "Data Wrangling - one data frame 🛠",
    "section": "Summarizing Data – summarize()\n",
    "text": "Summarizing Data – summarize()\n\n\n\nsummarize() provides a data frame that summarizes the statistics we compute.\n\n\nheights &lt;- read_csv(\"./data/heights.csv\")\nglimpse(heights)\n\nRows: 1,050\nColumns: 2\n$ sex    &lt;chr&gt; \"Male\", \"Male\", \"Male\", \"Male\", \"Male\", \"Female\", \"Female\", \"Fe…\n$ height &lt;dbl&gt; 75, 70, 68, 74, 61, 65, 66, 62, 66, 67, 72, 72, 69, 68, 69, 66,…\n\n\n\nThe summarize() function in dplyr provides a way to compute summary statistics.\nAgain, its first argument and output are always data frames.\nWe are gonna use another data set heights in the dslabs package to demonstrate the usage of function.\nThe data set only has two variables, sex and height.\nheight is a variable, but heights is the data set"
  },
  {
    "objectID": "slides/12-dplyr-1.html#summarizing-data-summarize-1",
    "href": "slides/12-dplyr-1.html#summarizing-data-summarize-1",
    "title": "Data Wrangling - one data frame 🛠",
    "section": "Summarizing Data – summarize()\n",
    "text": "Summarizing Data – summarize()\n\n\n(s &lt;- heights |&gt; \n    filter(sex == \"Female\") |&gt; \n    summarize(avg = mean(height),  \n              stdev = sd(height),\n              med = median(height), \n              min = min(height)))\n\n# A tibble: 1 × 4\n    avg stdev   med   min\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1  64.9  3.76  65.0    51\n\ns$avg\n\n[1] 64.9\n\ns$min\n\n[1] 51\n\n\n\nsummarise() produces a new data frame that is not any variant of the original data frame.\n\n\nSuppose we want to find the mean and standard deviation of female height and store the two values as a data frame, we can start with the data set heights, then filter or grab the observations that have sex Female, and then with the filtered data, use the summarize function to create a data frame of two variables “average” and “standard_deviation” computed from the variable height.\nYou see that the resulting object s is a data frame with two variables.\nNotice that summarise() changes the data frame entirely, it collapses rows down to a single summary statistic, and removes all columns that are irrelevant to the calculation. Basically, the resulting df is not any variant of the original df anymore.\n\nsummarise() changes the data frame entirely, it collapses rows down to a single summary statistic, and removes all columns that are irrelevant to the calculation."
  },
  {
    "objectID": "slides/12-dplyr-1.html#summarizing-data-summarize-2",
    "href": "slides/12-dplyr-1.html#summarizing-data-summarize-2",
    "title": "Data Wrangling - one data frame 🛠",
    "section": "Summarizing Data – summarize()\n",
    "text": "Summarizing Data – summarize()\n\n\nOne variable quans that has 3 values. The output is a 3 by 1 data frame.\n\n\n(s2 &lt;- heights |&gt;  \n    filter(sex == \"Female\") |&gt; \n    summarize(quans = quantile(height, c(0.1, 0.5, 0.9))))\n\n# A tibble: 3 × 1\n  quans\n  &lt;dbl&gt;\n1  61  \n2  65.0\n3  69  \n\n\n\nwe will get a data frame with more than one row if the function we use in summarize() return a vector.\nFor example here, we compute the 01, 0.5, and 0.9 quantile of variable height, and call it quantiles. Then the resulting data frame will have 3 rows, basically a column vector with 3 elements. str(s2)"
  },
  {
    "objectID": "slides/12-dplyr-1.html#grouping-group_by",
    "href": "slides/12-dplyr-1.html#grouping-group_by",
    "title": "Data Wrangling - one data frame 🛠",
    "section": "Grouping – group_by()\n",
    "text": "Grouping – group_by()\n\n\n(heights_group &lt;- heights |&gt; \n     group_by(sex))  #&lt;&lt;\n\n# A tibble: 1,050 × 2\n# Groups:   sex [2]\n  sex    height\n  &lt;chr&gt;   &lt;dbl&gt;\n1 Male       75\n2 Male       70\n3 Male       68\n4 Male       74\n5 Male       61\n6 Female     65\n# ℹ 1,044 more rows\n\n\n\nclass(heights_group)\n\n[1] \"grouped_df\" \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\n\nheights_group is a grouped data frame.\nTibbles are similar, but see Groups: sex [2] after grouping data by sex.\nsummarize() behaves differently when acting on grouped_df.\n\n\nA common operation in data exploration is to first split data into groups and then compute summaries for each group.\nTo group a data set by some variable, we can use group_by() function.\nHere, we group the heights data set by the variable sex.\nOutputs are similar, but we see Groups: sex [2] after grouping data by sex. [2] means there are two groups.\nAnd now the heights_group data set has a new class called grouped_df."
  },
  {
    "objectID": "slides/12-dplyr-1.html#group-and-summarize-group_by-summarize",
    "href": "slides/12-dplyr-1.html#group-and-summarize-group_by-summarize",
    "title": "Data Wrangling - one data frame 🛠",
    "section": "Group and Summarize: group_by() + summarize()\n",
    "text": "Group and Summarize: group_by() + summarize()\n\n\n\nsummarize() applies the summarization to each group separately.\n\n\nheights |&gt; \n    group_by(sex) |&gt; \n    summarize(avg = mean(height), stdev = sd(height), \n              med = median(height), min = min(height))\n\n# A tibble: 2 × 5\n  sex      avg stdev   med   min\n  &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Female  64.9  3.76  65.0    51\n2 Male    69.3  3.61  69      50\n\n\n\n\nmurders |&gt;  \n    group_by(region) |&gt; \n    summarize(median_rate = median(rate))\n\n# A tibble: 4 × 2\n  region        median_rate\n  &lt;chr&gt;               &lt;dbl&gt;\n1 North Central        1.97\n2 Northeast            1.80\n3 South                3.40\n4 West                 1.29\n\n\n\nThe summarize() function applies the summarization to each group separately.\nHere we use the same summarize() function and compute the average and sd of the variable height as we previous did.\nBut if the the data set is a grouped data frame grouped by sex, the summarized output will show the avg and sd for each group, make and female separately.\nAnother example is that we first group the murders data by region, then when we compute the median murder rate, it will get the median murder rate for each region.\nThis is quite helpful when we want to explore the relationship between numerical and categorical variables. Like here, we discover that the murder rate in the south is the highest.\nYou can absolutely include some statistics summary in your project proposal when you describe your data."
  },
  {
    "objectID": "slides/12-dplyr-1.html#sorting-rows-in-data-frames-arrange",
    "href": "slides/12-dplyr-1.html#sorting-rows-in-data-frames-arrange",
    "title": "Data Wrangling - one data frame 🛠",
    "section": "Sorting Rows in Data Frames – arrange()\n",
    "text": "Sorting Rows in Data Frames – arrange()\n\n\n\narrange() orders entire data tables.\n\n\n## order the states by population size\nmurders |&gt;  \n    arrange(population)\n\n# A tibble: 51 × 6\n  state                abb   region        population total   rate\n  &lt;chr&gt;                &lt;chr&gt; &lt;chr&gt;              &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1 Wyoming              WY    West              563626     5  0.887\n2 District of Columbia DC    South             601723    99 16.5  \n3 Vermont              VT    Northeast         625741     2  0.320\n4 North Dakota         ND    North Central     672591     4  0.595\n5 Alaska               AK    West              710231    19  2.68 \n6 South Dakota         SD    North Central     814180     8  0.983\n# ℹ 45 more rows\n\n\n\nFor ordering entire data tables, the dplyr function arrange() is useful.\nWe get to decide which column to sort by.\nIf we want to sort the observations of murders data set by population size, we just need to pipe the data set into arrange function and specify population variable.\nHow do we do the same thing with base R grammar, not tidyverse grammar?\nmurders[order(murders$population), ]"
  },
  {
    "objectID": "slides/12-dplyr-1.html#section-3",
    "href": "slides/12-dplyr-1.html#section-3",
    "title": "Data Wrangling - one data frame 🛠",
    "section": "",
    "text": "15-dplyr  \nIn lab.qmd ## Lab 15 section, import the murders.csv data and\n\nAdd (mutate) the variable rate = total / population * 100000 to murders data (as I did).\nFilter states that are in region Northeast or West and their murder rate is less than 1.\nSelect variables state, region, rate.\n\n\nPrint the output table after you do 1. to 3., and save it as object my_states.\nGroup my_states by region. Then summarize data by creating variables avg and stdev that compute the mean and standard deviation of rate.\nArrange the summarized table by avg."
  },
  {
    "objectID": "slides/12-dplyr-1.html#section-4",
    "href": "slides/12-dplyr-1.html#section-4",
    "title": "Data Wrangling - one data frame 🛠",
    "section": "",
    "text": "_______ &lt;- _______ |&gt; \n    mutate(_______) |&gt; \n    filter(_______) |&gt; \n    select(_______)\n\n_______ |&gt;  \n    group_by(______) |&gt; \n    summarize(______) |&gt; \n    arrange(_______)\n\n\n\n\n          state    region  rate\n1        Hawaii      West 0.515\n2         Idaho      West 0.766\n3         Maine Northeast 0.828\n4 New Hampshire Northeast 0.380\n5        Oregon      West 0.940\n6          Utah      West 0.796\n7       Vermont Northeast 0.320\n8       Wyoming      West 0.887\n\n\n# A tibble: 2 × 3\n  region      avg stdev\n  &lt;fct&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1 West      0.781 0.164\n2 Northeast 0.509 0.278"
  },
  {
    "objectID": "slides/12-dplyr-1.html#section-6",
    "href": "slides/12-dplyr-1.html#section-6",
    "title": "Data Wrangling - one data frame 🛠",
    "section": "",
    "text": "import numpy as np\nimport pandas as pd\n\n\nmurders = pd.read_csv('./data/murders.csv')\nmurders\n\n                   state abb         region  population  total\n0                Alabama  AL          South     4779736    135\n1                 Alaska  AK           West      710231     19\n2                Arizona  AZ           West     6392017    232\n3               Arkansas  AR          South     2915918     93\n4             California  CA           West    37253956   1257\n5               Colorado  CO           West     5029196     65\n6            Connecticut  CT      Northeast     3574097     97\n7               Delaware  DE          South      897934     38\n8   District of Columbia  DC          South      601723     99\n9                Florida  FL          South    19687653    669\n10               Georgia  GA          South     9920000    376\n11                Hawaii  HI           West     1360301      7\n12                 Idaho  ID           West     1567582     12\n13              Illinois  IL  North Central    12830632    364\n14               Indiana  IN  North Central     6483802    142\n15                  Iowa  IA  North Central     3046355     21\n16                Kansas  KS  North Central     2853118     63\n17              Kentucky  KY          South     4339367    116\n18             Louisiana  LA          South     4533372    351\n19                 Maine  ME      Northeast     1328361     11\n20              Maryland  MD          South     5773552    293\n21         Massachusetts  MA      Northeast     6547629    118\n22              Michigan  MI  North Central     9883640    413\n23             Minnesota  MN  North Central     5303925     53\n24           Mississippi  MS          South     2967297    120\n25              Missouri  MO  North Central     5988927    321\n26               Montana  MT           West      989415     12\n27              Nebraska  NE  North Central     1826341     32\n28                Nevada  NV           West     2700551     84\n29         New Hampshire  NH      Northeast     1316470      5\n30            New Jersey  NJ      Northeast     8791894    246\n31            New Mexico  NM           West     2059179     67\n32              New York  NY      Northeast    19378102    517\n33        North Carolina  NC          South     9535483    286\n34          North Dakota  ND  North Central      672591      4\n35                  Ohio  OH  North Central    11536504    310\n36              Oklahoma  OK          South     3751351    111\n37                Oregon  OR           West     3831074     36\n38          Pennsylvania  PA      Northeast    12702379    457\n39          Rhode Island  RI      Northeast     1052567     16\n40        South Carolina  SC          South     4625364    207\n41          South Dakota  SD  North Central      814180      8\n42             Tennessee  TN          South     6346105    219\n43                 Texas  TX          South    25145561    805\n44                  Utah  UT           West     2763885     22\n45               Vermont  VT      Northeast      625741      2\n46              Virginia  VA          South     8001024    250\n47            Washington  WA           West     6724540     93\n48         West Virginia  WV          South     1852994     27\n49             Wisconsin  WI  North Central     5686986     97\n50               Wyoming  WY           West      563626      5"
  },
  {
    "objectID": "slides/12-dplyr-1.html#new-variables-.assign",
    "href": "slides/12-dplyr-1.html#new-variables-.assign",
    "title": "Data Wrangling - one data frame 🛠",
    "section": "New Variables .assign\n",
    "text": "New Variables .assign\n\n\ndplyr::mutate()\nHave to use murders.total and murders.population instead of total and popution.\n\n\nmurders = murders.assign(\n    rate = round(murders.total / murders.population * 100000, 2))\n\n\nmurders.head(5)\n\n        state abb region  population  total  rate\n0     Alabama  AL  South     4779736    135  2.82\n1      Alaska  AK   West      710231     19  2.68\n2     Arizona  AZ   West     6392017    232  3.63\n3    Arkansas  AR  South     2915918     93  3.19\n4  California  CA   West    37253956   1257  3.37"
  },
  {
    "objectID": "slides/12-dplyr-1.html#filter-rows-.query",
    "href": "slides/12-dplyr-1.html#filter-rows-.query",
    "title": "Data Wrangling - one data frame 🛠",
    "section": "Filter Rows .query\n",
    "text": "Filter Rows .query\n\n\ndplyr::filter()\nConditions must be a string to be evaluated!\nCannot write murders.rate, and should use rate.\n\n\nmurders.query(expr=\"rate &lt; 0.7\")\n\n            state abb         region  population  total  rate\n11         Hawaii  HI           West     1360301      7  0.51\n15           Iowa  IA  North Central     3046355     21  0.69\n29  New Hampshire  NH      Northeast     1316470      5  0.38\n34   North Dakota  ND  North Central      672591      4  0.59\n45        Vermont  VT      Northeast      625741      2  0.32"
  },
  {
    "objectID": "slides/12-dplyr-1.html#select-columns-.filter",
    "href": "slides/12-dplyr-1.html#select-columns-.filter",
    "title": "Data Wrangling - one data frame 🛠",
    "section": "Select Columns .filter\n",
    "text": "Select Columns .filter\n\n\ndplyr::select()\nHave to be strings\n\n\nmurders.filter(items=['region', 'rate', 'state'])\n\n           region   rate                 state\n0           South   2.82               Alabama\n1            West   2.68                Alaska\n2            West   3.63               Arizona\n3           South   3.19              Arkansas\n4            West   3.37            California\n5            West   1.29              Colorado\n6       Northeast   2.71           Connecticut\n7           South   4.23              Delaware\n8           South  16.45  District of Columbia\n9           South   3.40               Florida\n10          South   3.79               Georgia\n11           West   0.51                Hawaii\n12           West   0.77                 Idaho\n13  North Central   2.84              Illinois\n14  North Central   2.19               Indiana\n15  North Central   0.69                  Iowa\n16  North Central   2.21                Kansas\n17          South   2.67              Kentucky\n18          South   7.74             Louisiana\n19      Northeast   0.83                 Maine\n20          South   5.07              Maryland\n21      Northeast   1.80         Massachusetts\n22  North Central   4.18              Michigan\n23  North Central   1.00             Minnesota\n24          South   4.04           Mississippi\n25  North Central   5.36              Missouri\n26           West   1.21               Montana\n27  North Central   1.75              Nebraska\n28           West   3.11                Nevada\n29      Northeast   0.38         New Hampshire\n30      Northeast   2.80            New Jersey\n31           West   3.25            New Mexico\n32      Northeast   2.67              New York\n33          South   3.00        North Carolina\n34  North Central   0.59          North Dakota\n35  North Central   2.69                  Ohio\n36          South   2.96              Oklahoma\n37           West   0.94                Oregon\n38      Northeast   3.60          Pennsylvania\n39      Northeast   1.52          Rhode Island\n40          South   4.48        South Carolina\n41  North Central   0.98          South Dakota\n42          South   3.45             Tennessee\n43          South   3.20                 Texas\n44           West   0.80                  Utah\n45      Northeast   0.32               Vermont\n46          South   3.12              Virginia\n47           West   1.38            Washington\n48          South   1.46         West Virginia\n49  North Central   1.71             Wisconsin\n50           West   0.89               Wyoming"
  },
  {
    "objectID": "slides/12-dplyr-1.html#grouping-.groupby-.agg",
    "href": "slides/12-dplyr-1.html#grouping-.groupby-.agg",
    "title": "Data Wrangling - one data frame 🛠",
    "section": "Grouping .groupby + .agg\n",
    "text": "Grouping .groupby + .agg\n\n\ndplyr::group_by() + dplyr::summarize()\n\n\nheights = pd.read_csv('./data/heights.csv')\n\n\nheights.groupby(by='sex')\n\n&lt;pandas.core.groupby.generic.DataFrameGroupBy object at 0x362dfeff0&gt;\n\n\n\n\n## a data frame\nheights.groupby(by='sex').agg(func=['mean', 'std', 'median', 'min'])\n\n           height                           \n             mean       std     median   min\nsex                                         \nFemale  64.939424  3.760656  64.980315  51.0\nMale    69.314755  3.611024  69.000000  50.0"
  },
  {
    "objectID": "slides/12-dplyr-1.html#sorting-.sort_values",
    "href": "slides/12-dplyr-1.html#sorting-.sort_values",
    "title": "Data Wrangling - one data frame 🛠",
    "section": "Sorting .sort_values\n",
    "text": "Sorting .sort_values\n\n\ndplyr::arrange()\n\n\nmurders.sort_values('population').head(5)\n\n                   state abb         region  population  total   rate\n50               Wyoming  WY           West      563626      5   0.89\n8   District of Columbia  DC          South      601723     99  16.45\n45               Vermont  VT      Northeast      625741      2   0.32\n34          North Dakota  ND  North Central      672591      4   0.59\n1                 Alaska  AK           West      710231     19   2.68\n\n\n\n\ndplyr::arrange(desc())\n\n\nmurders.sort_values('rate', ascending = False).head(5)\n\n                   state abb         region  population  total   rate\n8   District of Columbia  DC          South      601723     99  16.45\n18             Louisiana  LA          South     4533372    351   7.74\n25              Missouri  MO  North Central     5988927    321   5.36\n20              Maryland  MD          South     5773552    293   5.07\n40        South Carolina  SC          South     4625364    207   4.48\n\n\n\n\n\n\nmath3570-s25.github.io/website"
  },
  {
    "objectID": "slides/11-interactive-viz.html#boring-static-ggplot",
    "href": "slides/11-interactive-viz.html#boring-static-ggplot",
    "title": "Interactive Visualization 📈",
    "section": "Boring Static ggplot",
    "text": "Boring Static ggplot\n\n\nJust a scatter plot showing the relationship between hwy and displ. And that’s it.\nIt cannot provide any other information or functionality."
  },
  {
    "objectID": "slides/11-interactive-viz.html#informative-inteactive-ggplot",
    "href": "slides/11-interactive-viz.html#informative-inteactive-ggplot",
    "title": "Interactive Visualization 📈",
    "section": "Informative Inteactive ggplot",
    "text": "Informative Inteactive ggplot\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow about this!\nWe can actually create a more informative Inteactive ggplot with more functionality!\nYou see here, if we put our cursor on any data point, the exact value of hwy and displ will be shown ot us.\nAlso, several useful funcitons are shown on the top of the plot.\nWe can download the plot.\nWe can zoom the plot.\nWe can drag the plot.\nWe can also select any data points we are interested and like to further investigate.\nNotice that the interactive data table are automatically changed to show the selected data point information.\nHow cool is that!\nhttps://www.rebeccabarter.com/blog/2017-04-20-interactive/"
  },
  {
    "objectID": "slides/11-interactive-viz.html#plotly",
    "href": "slides/11-interactive-viz.html#plotly",
    "title": "Interactive Visualization 📈",
    "section": "\nPlotly 📦",
    "text": "Plotly 📦\n\nTo create a plotly object\n\ndirectly initializing a plotly object with plot_ly(), plot_geo(), etc.\ntransforming a ggplot2 object via ggplotly() into a plotly object\n\n\nBoth are powered by the JavaScript graphing library plotly.js, so many of the same concepts and tools for one interface can be reused in the other.\n\n\nBoth approaches have somewhat complementary strengths and weaknesses, so it can pay off to learn both approaches. Moreover, both approaches are an implementation of the Grammar of Graphics and both are powered by the JavaScript graphing library plotly.js"
  },
  {
    "objectID": "slides/11-interactive-viz.html#plot_ly",
    "href": "slides/11-interactive-viz.html#plot_ly",
    "title": "Interactive Visualization 📈",
    "section": "plot_ly()",
    "text": "plot_ly()\n\nMapping homeownership to x yields a bar chart\n\n\n\nlibrary(plotly)\nloans &lt;- readr::read_csv(\"./data/loans.csv\")\nloans |&gt; plot_ly(x = ~homeownership) \n\n\n\n\n# plot_ly(loans, x = loans$homeownership)\n# plot_ly(loans, x = ~homeownership, type = \"histogram\")\n\nplotly tries to find a sensible geometric representation of that information for us plot_ly(loans, x = ~homeownership, type = “histogram”) ‘bar’, ‘barpolar’, ‘box’, ‘candlestick’, ‘carpet’, ‘choropleth’, ‘choroplethmapbox’, ‘cone’, ‘contour’, ‘contourcarpet’, ‘densitymapbox’, ‘funnel’, ‘funnelarea’, ‘heatmap’, ‘heatmapgl’, ‘histogram’, ‘histogram2d’, ‘histogram2dcontour’, ‘icicle’, ‘image’, ‘indicator’, ‘isosurface’, ‘mesh3d’, ‘ohlc’, ‘parcats’, ‘parcoords’, ‘pie’, ‘pointcloud’, ‘sankey’, ‘scatter’, ‘scatter3d’, ‘scattercarpet’, ‘scattergeo’, ‘scattergl’, ‘scattermapbox’, ‘scatterpolar’, ‘scatterpolargl’, ‘scatterternary’, ‘splom’, ‘streamtube’, ‘sunburst’, ‘surface’, ‘table’, ‘treemap’, ‘violin’, ‘volume’, ‘waterfall’"
  },
  {
    "objectID": "slides/11-interactive-viz.html#plot_ly-1",
    "href": "slides/11-interactive-viz.html#plot_ly-1",
    "title": "Interactive Visualization 📈",
    "section": "plot_ly()",
    "text": "plot_ly()\n\nloans |&gt; plot_ly(x = ~homeownership, color = I(\"pink\"), stroke = I(\"green3\"), span = I(5))\n\n\n\n\n\n\nWe can specify the bar color we like using color argument.\nNote that we cannot simply use the name of color as we do in R plotting, but have to add the function I().\nIt is because when we call the plot_ly(), it actually translate the R code into Javascript, and for some reason, we need to add I() to make the code work.\nIf you like to change the border color of the bar, you can specify a color in the stroke argument.\nSpan controls the width of the border. # doesn’t produce black bars plot_ly(loans, x = ~homeownership, color = “black”)"
  },
  {
    "objectID": "slides/11-interactive-viz.html#plot_ly-2",
    "href": "slides/11-interactive-viz.html#plot_ly-2",
    "title": "Interactive Visualization 📈",
    "section": "plot_ly()",
    "text": "plot_ly()\n\nMapping homeownership & grade to x & y yields a heatmap\n\n\n\nloans |&gt; plot_ly(x = ~homeownership, y = ~grade)\n\n\n\n\n# plot_ly(loans, x = ~homeownership, y = ~grade, type = \"histogram2d\")\n\n\nColor in cells represents the the count of some type of homeownership and the grade of loans.\nFor example, we know there are 1285 loans that is classified as grade A, and the loan applicant has a mortgage.\nThe most frequency is grade B and mortgage."
  },
  {
    "objectID": "slides/11-interactive-viz.html#plot_ly-3",
    "href": "slides/11-interactive-viz.html#plot_ly-3",
    "title": "Interactive Visualization 📈",
    "section": "plot_ly()",
    "text": "plot_ly()\n\nMapping homeownership & grade to x & color yields a dodged bar chart \n\n\n\nloans |&gt; plot_ly(x = ~homeownership, color = ~grade)\n\n\n\n\n# plot_ly(loans, x = ~homeownership, color = ~grade, type = \"histogram\")\n\n\nWe actually create a bar chart of grade of loan separated by homeownership, and each bar has a color corresponding to a grade of loan.\n\n\n\n\nloans |&gt; plot_ly(x = ~homeownership, \n        color = ~grade, colors = \"Accent\")"
  },
  {
    "objectID": "slides/11-interactive-viz.html#layout",
    "href": "slides/11-interactive-viz.html#layout",
    "title": "Interactive Visualization 📈",
    "section": "layout()",
    "text": "layout()\n\nThe 1st argument is a plotly object.\nOther arguments include legend, margins, size, etc.\n\n\nplotly::layout(p = plot_ly(loans, x = ~homeownership),\n               title = \"My beatiful bar chart\")\n\n\n\n\n\n\nIf we want to decorate our plot, in plotly, we use the layout function.\nYou can also change the X-label and Y-label in the layout function.\n\nlayout( # all of layout’s properties: /r/reference/#layout title = “Unemployment”, # layout’s title: /r/reference/#layout-title xaxis = list( # layout’s xaxis is a named list. List of valid keys: /r/reference/#layout-xaxis title = “Time”, # xaxis’s title: /r/reference/#layout-xaxis-title showgrid = F), # xaxis’s showgrid: /r/reference/#layout-xaxis-showgrid yaxis = list( # layout’s yaxis is a named list. List of valid keys: /r/reference/#layout-yaxis title = “uidx”) # yaxis’s title: /r/reference/#layout-yaxis-title )"
  },
  {
    "objectID": "slides/11-interactive-viz.html#add_-functions",
    "href": "slides/11-interactive-viz.html#add_-functions",
    "title": "Interactive Visualization 📈",
    "section": "add_*() Functions",
    "text": "add_*() Functions\n\nDefine how to render data into geometric objects, add_contour(), add_boxplot(), etc.\nadd_markers() for scatterplots.\n\n\n# plot_ly(mpg, x = ~cty, y = ~hwy, type = \"scatter\", mode = \"markers\", alpha = 0.5)\nbase_plot &lt;- mpg |&gt; plot_ly(x = ~cty, y = ~hwy)\nbase_plot |&gt; add_markers(alpha = 0.7, size = 2)\n\n\n\n\n\n\nOne advantage of using add_* family functions is that, if we haven’t decided what kind of plot we’d like to generate, we can first create a base plotly object, and then add any geometric object we like later.\nWe can try several geometric objects, and choose our favorite one. plot_ly(mpg, x = ~cty, y = ~hwy, type = “scatter”, mode = “markers”, alpha = 0.5)"
  },
  {
    "objectID": "slides/11-interactive-viz.html#add_paths",
    "href": "slides/11-interactive-viz.html#add_paths",
    "title": "Interactive Visualization 📈",
    "section": "add_paths()",
    "text": "add_paths()\n\nbase_plot |&gt; add_paths()\n\n\n\n\n\n\nHere we add another geometry path. You can see that using point markers makes more sense in this case.\nBut the point is, we can repeatedly using the same base"
  },
  {
    "objectID": "slides/11-interactive-viz.html#color",
    "href": "slides/11-interactive-viz.html#color",
    "title": "Interactive Visualization 📈",
    "section": "Color",
    "text": "Color\n\n## alpha here is \"setting\", not \"mapping\"\np &lt;- mpg |&gt; plot_ly(x = ~cty, y = ~hwy, alpha = 0.7) \np |&gt; add_markers(color = ~factor(cyl), size = 3)\n\n\n\n\n\n\nmap the number of cylinders to point color.\nBecause the variable is actually numerical, I make it categorical as a factor before doing the mapping."
  },
  {
    "objectID": "slides/11-interactive-viz.html#symbols",
    "href": "slides/11-interactive-viz.html#symbols",
    "title": "Interactive Visualization 📈",
    "section": "Symbols",
    "text": "Symbols\n\np |&gt; add_markers(symbol = ~factor(cyl), color = I(\"red\"))\n\n\n\n\n\n\nWe can also use different symbols or point shapes to represent different number of cylinders. Very simple, we just use the symbol argument instead.\nIn ggplot2, we use “shape”"
  },
  {
    "objectID": "slides/11-interactive-viz.html#add_lines",
    "href": "slides/11-interactive-viz.html#add_lines",
    "title": "Interactive Visualization 📈",
    "section": "add_lines()",
    "text": "add_lines()\n\n\nPlot\nCode\n\n\n\n\np &lt;- tx5 |&gt; plot_ly(x = ~date, y = ~median)\np |&gt; add_lines(linetype = ~city)\n\n\n\n\n\n\n\n\n\n\ntop5 &lt;- txhousing |&gt; \n    group_by(city) |&gt; \n    summarise(m = mean(sales, na.rm = TRUE)) |&gt; \n    arrange(desc(m)) |&gt; \n    top_n(5)\ntx5 &lt;- semi_join(txhousing, top5, by = \"city\")\np &lt;- tx5 |&gt; plot_ly(x = ~date, y = ~median)\np |&gt; add_lines(linetype = ~city)\n\n\n\n\n\nWe can also create a line plot. It is useful if you have some time series data.\nHere I create a data called tx5, and I am trying see the trend of the median home price of the 5 cities in Texas.\nFirst, we can create plotly object, assigning the x and y variables, which are date and median.\nThen we can add the line plot, one linetype for one city."
  },
  {
    "objectID": "slides/11-interactive-viz.html#ggplotly",
    "href": "slides/11-interactive-viz.html#ggplotly",
    "title": "Interactive Visualization 📈",
    "section": "ggplotly()",
    "text": "ggplotly()\n\n\nplotly::ggplotly() translate ggplot2 to plotly.\n\n\np &lt;- loans |&gt; \n    ggplot(aes(x = debt_to_income, y = interest_rate)) +\n    geom_point(alpha = 0.5) +\n    theme_bw()\nggplotly(p)\n\n\n\n\n\n\nIf you think the syntax is hard and not intuitive, and you love using ggplot, well here is good news.\nThe function ggplotly() translate ggplot2 to plotly.\nYou just create your ggplot, save it as an object, and then plug the object into the ggplotly function.\nBang! your ggplot becomes interactive!\nHow cool is that! Very cool and convenient!\nThat’s one of the reasons why we learn ggplot!\nBut so far the translation is not 100 percent working."
  },
  {
    "objectID": "slides/11-interactive-viz.html#ggplotly-1",
    "href": "slides/11-interactive-viz.html#ggplotly-1",
    "title": "Interactive Visualization 📈",
    "section": "ggplotly()",
    "text": "ggplotly()\n\nEasily compare levels of grade (loan quality) by leveraging the legend filtering capabilities.\n\n\np &lt;- loans |&gt; ggplot(aes(x = log(debt_to_income), color = grade)) + \n    geom_freqpoly(stat = \"density\") + xlim(0, 5) + theme_bw()\nggplotly(p)"
  },
  {
    "objectID": "slides/11-interactive-viz.html#section-3",
    "href": "slides/11-interactive-viz.html#section-3",
    "title": "Interactive Visualization 📈",
    "section": "",
    "text": "14-plotly \nIn lab.qmd ## Lab 14 section,\n\nLoad tidyverse and plotly and the loans.csv data.\nGenerate a plot using plotly. An example is shown below. Welcome to create a more fancy one!\n\n\n\n\n\n\n\n\n\n# x = interest_rate, y = grade won't work\ngg &lt;- loans |&gt; ggplot(aes(x = grade, y = interest_rate, color = grade)) + \n    geom_boxplot() + theme_minimal() + coord_flip()\nggplotly(gg)"
  },
  {
    "objectID": "slides/11-interactive-viz.html#dumbell-chart",
    "href": "slides/11-interactive-viz.html#dumbell-chart",
    "title": "Interactive Visualization 📈",
    "section": "Dumbell Chart",
    "text": "Dumbell Chart\n\n\nPlot\nCode\n\n\n\n\n\n\n\n\n\n\n\n\nmpg |&gt; \n    group_by(model) |&gt; \n    summarise(c = mean(cty), h = mean(hwy)) |&gt; \n    mutate(model = forcats::fct_reorder(model, c)) |&gt; \n    plot_ly() |&gt; \n    add_segments(x = ~c, y = ~model,\n                 xend = ~h, yend = ~model, \n                 color = I(\"gray\"), showlegend = FALSE) |&gt; \n    add_markers(x = ~c, y = ~model, \n                color = I(\"blue\"), \n                name = \"mpg city\") |&gt; \n    add_markers(x = ~h, y = ~model, \n                color = I(\"red\"),\n                name  = \"mpg highway\") |&gt; \n    plotly::layout(xaxis = list(title = \"Miles per gallon\"))"
  },
  {
    "objectID": "slides/11-interactive-viz.html#maps",
    "href": "slides/11-interactive-viz.html#maps",
    "title": "Interactive Visualization 📈",
    "section": "Maps",
    "text": "Maps\n\n\nPlot\nCode\n\n\n\n\n\n\n\n\n\n\n\n\npop_den &lt;- datasets::state.x77[, \"Population\"] / state.x77[, \"Area\"]\n\ng &lt;- list(scope = 'usa',\n          projection = list(type = 'albers usa'),\n          lakecolor = toRGB('white'))\n\nplot_geo() |&gt; \n    add_trace(z = ~pop_den, text = state.name, span = I(0),\n              locations = state.abb, locationmode = 'USA-states') |&gt; \n    plotly::layout(geo = g)"
  },
  {
    "objectID": "slides/11-interactive-viz.html#d-scatterplots",
    "href": "slides/11-interactive-viz.html#d-scatterplots",
    "title": "Interactive Visualization 📈",
    "section": "3D Scatterplots",
    "text": "3D Scatterplots\n\nmpg |&gt; plot_ly(x = ~cty, y = ~hwy, z = ~cyl) |&gt; \n    add_markers(color = ~factor(cyl))"
  },
  {
    "objectID": "slides/11-interactive-viz.html#d-surfaces",
    "href": "slides/11-interactive-viz.html#d-surfaces",
    "title": "Interactive Visualization 📈",
    "section": "3D Surfaces",
    "text": "3D Surfaces\n\nx &lt;- 1:nrow(datasets::volcano); y &lt;- 1:ncol(datasets::volcano)\nplot_ly() |&gt; add_surface(x = ~x, y = ~y, z = ~volcano)"
  },
  {
    "objectID": "slides/11-interactive-viz.html#animations-using-frames",
    "href": "slides/11-interactive-viz.html#animations-using-frames",
    "title": "Interactive Visualization 📈",
    "section": "Animations using Frames",
    "text": "Animations using Frames\n\nlibrary(gapminder)\np &lt;- gapminder |&gt; ggplot(aes(gdpPercap, lifeExp, color = continent)) +\n  geom_point(aes(size = pop, frame = year, ids = country)) +\n  scale_x_log10()\n\nggplotly(p)\n\n\n\n\n\nNow, along with data and layout, frames is added to the keys that figure allows. Your frames key points to a list of figures, each of which will be cycled through upon instantiation of the plot."
  },
  {
    "objectID": "slides/11-interactive-viz.html#dynamic-bar-chart-using-gganimate",
    "href": "slides/11-interactive-viz.html#dynamic-bar-chart-using-gganimate",
    "title": "Interactive Visualization 📈",
    "section": "Dynamic Bar Chart using gganimate\n",
    "text": "Dynamic Bar Chart using gganimate\n\n\n\n\n\n\nSource: https://github.com/amrrs/animated_bar_charts_in_R\n\n\n\n\n\n\n\n\nmath3570-s25.github.io/website"
  },
  {
    "objectID": "slides/09-ggplot2.html#plotting-systems-base-lattice-and-ggplot2",
    "href": "slides/09-ggplot2.html#plotting-systems-base-lattice-and-ggplot2",
    "title": "Data Visualization – ggplot2 📊",
    "section": "\nPlotting Systems: base, lattice and ggplot2\n",
    "text": "Plotting Systems: base, lattice and ggplot2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot2\n\nhas the most powerful functionality.\nis more beautiful?\nhas larger file size that occupies more memory space and has longer render time.\n\n\nWe already learned a little bit about R plotting, right? In fact R has three main plotting systems, the base package, lattice package, and the ggplot2 package.\nThere are lots of tools and packages that greatly extend the ggplot2 functionality, as I listed here.\nBasically, ggplot2 has the most powerful functionality than the other two. It can create lots of graphs that the other two cannot, and ggplot2 is more beautiful than the other two, I think. But one disadvantage of ggplot2 is that it’s size is larger than the other two, occupying more memory spaces than the other two, and the rendering time is longer."
  },
  {
    "objectID": "slides/09-ggplot2.html#the-ggplot2-grammar",
    "href": "slides/09-ggplot2.html#the-ggplot2-grammar",
    "title": "Data Visualization – ggplot2 📊",
    "section": "The ggplot2 Grammar",
    "text": "The ggplot2 Grammar\n\nThree main components:\n\n      \n\n\n\n\n\n\nGrammar element\nWhat it is\n\n\n\nData\nThe data frame used for plotting\n\n\nGeometry\n\nThe geometric shape that represents the data\ne.g., point, boxplot, histogram\n\n\n\n\nAesthetic mapping\n\nThe aesthetics of the geometric object\ne.g., color, size, shape\n\n\n\n\n\n\nHow we define the mapping depends on what geometry we are using.\n\n\n\nggplot(data = &lt;DATASET&gt;, mapping = aes(&lt;MAPPINGS&gt;)) + \n       &lt;GEOM_FUNCTION&gt;() +\n       other options/layers\n\n\n\nData: the data input of ggplot2 is always a data frame, not a vector, or matrix.\nGeometry: defines what kind of plot we are going to make.\nAesthetic mapping: basically tell ggplot2 how we decorate the plot and make it more visible or more informative. For example, use different point colors or sizes for different categories, such male and female\nStructure of the code for ggplots can be summarized as the following code."
  },
  {
    "objectID": "slides/09-ggplot2.html#mpg-data",
    "href": "slides/09-ggplot2.html#mpg-data",
    "title": "Data Visualization – ggplot2 📊",
    "section": "mpg Data",
    "text": "mpg Data\n\nggplot2::mpg\n\n# A tibble: 234 × 11\n  manufacturer model      displ  year   cyl trans  drv     cty   hwy fl    class\n  &lt;chr&gt;        &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt;  &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt;\n1 audi         a4           1.8  1999     4 auto(… f        18    29 p     comp…\n2 audi         a4           1.8  1999     4 manua… f        21    29 p     comp…\n3 audi         a4           2    2008     4 manua… f        20    31 p     comp…\n4 audi         a4           2    2008     4 auto(… f        21    30 p     comp…\n5 audi         a4           2.8  1999     6 auto(… f        16    26 p     comp…\n6 audi         a4           2.8  1999     6 manua… f        18    26 p     comp…\n7 audi         a4           3.1  2008     6 auto(… f        18    27 p     comp…\n8 audi         a4 quattro   1.8  1999     4 manua… 4        18    26 p     comp…\n# ℹ 226 more rows\n\n\n\nHere shows the mpg data set saved in ggplot2.\nIt is a tibble with 11 variables, including ……\nWe are gonna use it as an example to learn to create a ggplot."
  },
  {
    "objectID": "slides/09-ggplot2.html#section-3",
    "href": "slides/09-ggplot2.html#section-3",
    "title": "Data Visualization – ggplot2 📊",
    "section": "",
    "text": "Plot\nCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(data = mpg,\n       mapping = aes(x = displ, \n                     y = hwy, \n                     color = class)) + \n    geom_point() +\n    labs(title = \"Engine Size v.s. Fuel Efficiency\",\n         subtitle = \"Dimensions for class\",\n         x = \"Engine displacement (litres)\", y = \"Highway (mpg)\",\n         color = \"Type of car\",\n         caption = \"Source: http://fueleconomy.gov\")\n\n\n\n\n\nHere shows a ggplot, showing the relationship between mpg and engine displacement. We have titles, labels, and footnote.\nAnd we also use different colors to show different types of car. Right.\nThe code is right here. We are gonna create this plot step by step by step OK."
  },
  {
    "objectID": "slides/09-ggplot2.html#section-4",
    "href": "slides/09-ggplot2.html#section-4",
    "title": "Data Visualization – ggplot2 📊",
    "section": "",
    "text": "Start with the mpg data frame\n\n\n\n\nlibrary(ggplot2)\nggplot(data = mpg) #&lt;&lt;\n\n\n\n\n\n\n\n\n\n\n\n\n\nRemember the data input is always a data frame.\n\nWhen you call the function ggplot(), but without any geometry, R just renders a plot background colored in gray."
  },
  {
    "objectID": "slides/09-ggplot2.html#section-5",
    "href": "slides/09-ggplot2.html#section-5",
    "title": "Data Visualization – ggplot2 📊",
    "section": "",
    "text": "Start with the mpg data frame, map engine displacement to the x-axis\n\n\n\n\nggplot(data = mpg,\n       mapping = aes(x = displ)) #&lt;&lt;\n\n\n\ndispl is the variable name in mpg.\n\n\n\n\n\n\n\n\n\n\n\nR will create tick marks and label of x-axis for you.\n\n\n\n\nThen after specifying the data set, we can start decorating our plot.\nRemember we are going to create a scatter plot of displacement and miles pewr gallon.\nSo we can first map engine displacement to the x-axis using mapping = aes(x = displ)\ndispl is the variable name in the mpg data set.\nR will create some default tick marks and label of x-axis for you."
  },
  {
    "objectID": "slides/09-ggplot2.html#section-6",
    "href": "slides/09-ggplot2.html#section-6",
    "title": "Data Visualization – ggplot2 📊",
    "section": "",
    "text": "Start with the mpg data frame, map engine displacement to the x-axis and map highway miles per gallon to the y-axis.\n\n\n\n\nggplot(data = mpg,\n       mapping = aes(x = displ,\n                     y = hwy)) #&lt;&lt;\n\n\nSpecify y = hwy in the same aes() of the mapping argument as x = displ, separated by comma.\n\n\n\n\n\n\n\n\n\n\n\n\n\nThen we map highway miles per gallon to the y-axis by specifying y = hwy in aesthetics\n\nhwy is the variable name in the mpg data set.\nR will create some default tick marks and label of y-axis for you.\nNow we have variables in both x and y axis. It’s time to define the geometry of the plot. That is, tell ggplot, what kind of plot you want!"
  },
  {
    "objectID": "slides/09-ggplot2.html#section-7",
    "href": "slides/09-ggplot2.html#section-7",
    "title": "Data Visualization – ggplot2 📊",
    "section": "",
    "text": "Start with the mpg data frame, map engine displacement to the x-axis and map highway miles per gallon to the y-axis. Represent each observation with a point\n\n\n\n\nggplot(data = mpg,\n       mapping = aes(x = displ, \n                     y = hwy)) + \n  geom_point() #&lt;&lt;\n\n\nTo define a geometry, add a geom layer.\n\n\nDon’t miss + sign!\n\n\nFor scatterplots we add points, and use geom_point()\nLots of geoms\n\n\n\n\n\n\n\n\n\n\n\n\ngeom (geometric object) - What’s the next? Remember we use different colors of points to represent different car types, right? - Which part of code you think we can use to color the points? - aesthetics in the mapping! - By default, ggplot generates black solid points, each representing an observation’s hwy and displ value."
  },
  {
    "objectID": "slides/09-ggplot2.html#section-8",
    "href": "slides/09-ggplot2.html#section-8",
    "title": "Data Visualization – ggplot2 📊",
    "section": "",
    "text": "Start with the mpg data frame, map engine displacement to the x-axis and map highway miles per gallon to the y-axis. Represent each observation with a point and map type of car (class) to the color of each point.\n\n\n\n\nggplot(data = mpg,\n       mapping = \n         aes(x = displ, \n             y = hwy, \n             color = class)) + #&lt;&lt;\n  geom_point()\n\n\nAdd color = class in aes() of the mapping argument, where class is the variable name for type of car.\nggplot automatically generates a legend on the right.\n\n\n\n\n\n\n\n\n\n\n\n\n\nTo map type of car (class) to the color of each point, add color = class in aes() of the mapping argument\nAnd now you can see that each color represent a type of car.\nggplot automatically generates a default legend on the right, where the title of the legend is the variable name, and the names of legend are the variable values.\nOK. We are almost done. The rest are just adding titles x, y labels. Let’s see how."
  },
  {
    "objectID": "slides/09-ggplot2.html#section-9",
    "href": "slides/09-ggplot2.html#section-9",
    "title": "Data Visualization – ggplot2 📊",
    "section": "",
    "text": "Start with the mpg data frame, map engine displacement to the x-axis and map highway miles per gallon to the y-axis. Represent each observation with a point and map type of car (class) to the color of each point. Title the plot “Engine Size v.s. Fuel Efficiency”\n\n\n\n\n\nggplot(data = mpg,\n       mapping = aes(x = displ, \n                     y = hwy, \n                     color = class)) + \n  geom_point() +\n  labs(\n    title=\"Engine Size vs. Fuel Efficiency\" #&lt;&lt;\n    )\n\n\nAdd any labels in labs() layer.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can add any labels in labs() layer.\nHere we set title = “Engine Size v.s. Fuel Efficiency”"
  },
  {
    "objectID": "slides/09-ggplot2.html#section-10",
    "href": "slides/09-ggplot2.html#section-10",
    "title": "Data Visualization – ggplot2 📊",
    "section": "",
    "text": "Start with the mpg data frame, map engine displacement to the x-axis and map highway miles per gallon to the y-axis. Represent each observation with a point and map type of car (class) to the color of each point. Title the plot “Engine Size vs. Fuel Efficiency”, add the subtitle “Dimensions for class”\n\n\n\n\n\nggplot(data = mpg,\n       mapping = aes(x = displ, \n                     y = hwy, \n                     color = class)) + \n  geom_point() +\n  labs(\n    title=\"Engine Size vs. Fuel Efficiency\",\n    subtitle=\"Dimensions for class\" #&lt;&lt;\n    ) \n\n\nAdd a subtitle in labs()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can also add a subtitle title “Dimensions for class”.\nBTW, we can change the font size, color and position of the title. Here is just the default setting.\nIn theme(plot.title = element_text(size = 20, color = “#1b98e0”)\nhttps://statisticsglobe.com/ggplot2-title-subtitle-with-different-size-and-color-in-r\nhttps://en.wikipedia.org/wiki/Point_(typography)\nhttps://stackoverflow.com/questions/17311917/ggplot2-the-unit-of-size\nWe will talk about that if time permitted. Or I can ask you in homework and you can learn by yourself."
  },
  {
    "objectID": "slides/09-ggplot2.html#section-11",
    "href": "slides/09-ggplot2.html#section-11",
    "title": "Data Visualization – ggplot2 📊",
    "section": "",
    "text": "Start with the mpg data frame, map engine displacement to the x-axis and map highway miles per gallon to the y-axis. Represent each observation with a point and map type of car (class) to the color of each point. Title the plot “Engine Size vs. Fuel Efficiency”, add the subtitle “Dimensions for class”, label the x and y axes as “Engine displacement (litres)” and “Highway (mpg)”, respectively\n\n\n\n\n\nggplot(data = mpg,\n       mapping = aes(x = displ, \n                     y = hwy, \n                     color = class)) + \n  geom_point() +\n  labs(\n    title = \"Engine Size vs. Fuel Efficiency\",\n    subtitle = \"Dimensions for class\",\n    x = \"Engine displacement (litres)\", #&lt;&lt;\n    y = \"Highway (mpg)\" #&lt;&lt;\n    ) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe then label the x and y axes as “Engine displacement (litres)” and “Highway (mpg)”, respectively."
  },
  {
    "objectID": "slides/09-ggplot2.html#section-12",
    "href": "slides/09-ggplot2.html#section-12",
    "title": "Data Visualization – ggplot2 📊",
    "section": "",
    "text": "Start with the mpg data frame, map engine displacement to the x-axis and map highway miles per gallon to the y-axis. Represent each observation with a point and map type of car (class) to the color of each point. Title the plot “Engine Size vs. Fuel Efficiency”, add the subtitle “Dimensions for class”, label the x and y axes as “Engine displacement (litres)” and “Highway (mpg)”, respectively, label the legend “Type of car”\n\n\n\n\n\nggplot(data = mpg,\n       mapping = aes(x = displ, \n                     y = hwy, \n                     color = class)) + \n  geom_point() +\n  labs(\n    title = \"Engine Size vs. Fuel Efficiency\",\n    subtitle = \"Dimensions for class\",\n    x = \"Engine displacement (litres)\", \n    y = \"Highway (mpg)\",\n    color = \"Type of car\" #&lt;&lt;\n    ) \n\n\nThe legend is generated when we map type of car (class) to color.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe label the legend “Type of car” using color = “Type of car”. Why?\nBecause the legend is generated when we map type of car to color.\nThe color title is the legend title."
  },
  {
    "objectID": "slides/09-ggplot2.html#section-13",
    "href": "slides/09-ggplot2.html#section-13",
    "title": "Data Visualization – ggplot2 📊",
    "section": "",
    "text": "Start with the mpg data frame, map engine displacement to the x-axis and map highway miles per gallon to the y-axis. Represent each observation with a point and map type of car (class) to the color of each point. Title the plot “Engine Size vs. Fuel Efficiency”, add the subtitle “Dimensions for class”, label the x and y axes as “Engine displacement (litres)” and “Highway (mpg)”, respectively, label the legend “Type of car”, and add a caption for the data source.\n\n\n\n\n\nggplot(data = mpg,\n       mapping = aes(x = displ, \n                     y = hwy, \n                     color = class)) + \n  geom_point() +\n  labs(\n    title = \"Engine Size vs. Fuel Efficiency\",\n    subtitle = \"Dimensions for class\",\n    x = \"Engine displacement (litres)\", \n    y = \"Highway (mpg)\",\n    color = \"Type of car\",\n    caption=\"Source: http://fueleconomy.gov\" #&lt;&lt;\n    ) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFinally, we can add a caption for the data source using caption argument\nThen we are done! We have this beautiful scatter plot!"
  },
  {
    "objectID": "slides/09-ggplot2.html#section-14",
    "href": "slides/09-ggplot2.html#section-14",
    "title": "Data Visualization – ggplot2 📊",
    "section": "",
    "text": "Start with the mpg data frame, map engine displacement to the x-axis and map highway miles per gallon to the y-axis. Represent each observation with a point and map type of car (class) to the color of each point. Title the plot “Engine Size vs. Fuel Efficiency”, add the subtitle “Dimensions for class”, label the x and y axes as “Engine displacement (litres)” and “Highway (mpg)”, respectively, label the legend “Type of car”, and add a caption for the data source. Finally, use a discrete color scale that is designed to be perceived by viewers with common forms of color blindness.\n\n\n\n\n\nggplot(data = mpg,\n       mapping = aes(x = displ, \n                     y = hwy, \n                     color = class)) + \n  geom_point() +\n  labs(\n    title = \"Engine Size vs. Fuel Efficiency\",\n    subtitle = \"Dimensions for class\",\n    x = \"Engine displacement (litres)\", \n    y = \"Highway (mpg)\",\n    color = \"Type of car\",\n    caption = \"Source: http://fueleconomy.gov\"\n    ) +\n  scale_colour_viridis_d() #&lt;&lt;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnd if we are considerate enough, we can use a discrete color scale that is designed to be perceived by viewers with common forms of color blindness.\n=======================================\nLet’s continue our discussion of ggplot2. We learned there are three main components of ggplot2, the data, which is a data frame, the geometry object, and aesthetics mapping.\nAnd we are free to add more layers with the plus sign to manipulate or put more features on the plot.\nIn fact, we can actually save a ggplot as an object, and we can recreate the plot by just printing the object out. Let’s see how."
  },
  {
    "objectID": "slides/09-ggplot2.html#section-15",
    "href": "slides/09-ggplot2.html#section-15",
    "title": "Data Visualization – ggplot2 📊",
    "section": "",
    "text": "11-ggplot2  \nIn lab.qmd ## Lab 11 section,\n\nUse readr::read_csv() to import the data penguins.csv into your R workspace.\nGenerate the following ggplot:"
  },
  {
    "objectID": "slides/09-ggplot2.html#section-16",
    "href": "slides/09-ggplot2.html#section-16",
    "title": "Data Visualization – ggplot2 📊",
    "section": "",
    "text": "penguins &lt;- read_csv(_________________)\n________ |&gt; \n  ggplot(mapping = ____(x = ______________,\n                        y = ______________,\n                        colour = ________)) +\n  geom______() +\n  ____(title = ____________________,\n       _________ = \"Dimensions for Adelie, Chinstrap, and Gentoo Penguins\",\n       x = _____________, y = _______________,\n       _______ = \"Species\",\n       _______ = \"Source: Palmer Station LTER / palmerpenguins package\")"
  },
  {
    "objectID": "slides/09-ggplot2.html#assign-a-plot-to-an-object",
    "href": "slides/09-ggplot2.html#assign-a-plot-to-an-object",
    "title": "Data Visualization – ggplot2 📊",
    "section": "Assign a Plot to an Object",
    "text": "Assign a Plot to an Object\n\n\n\np &lt;- ggplot(data = mpg,\n            mapping = \n                aes(x = displ, \n                    y = hwy, \n                    color = class)) + \n    geom_point()\nclass(p)\n\n[1] \"gg\"     \"ggplot\"\n\np\n\n\n\n\n\n\n\n\n\n\np + labs(\n      title = \"Engine Size vs. Fuel Efficiency\",\n      subtitle = \"Dimensions for class\",\n      x = \"Engine displacement (litres)\", \n      y = \"Highway (mpg)\",\n      color = \"Type of car\",\n      caption = \"Source: http://fueleconomy.gov\"\n    )\n\n\n\n\n\n\n\n\n\n\n\nSo one advantage of ggplot is that you can Assign a ggplot to an Object that has its own class ggplot.\nbase R plotting system is not able to assign an object to a plot for rendering.\nhere, I assign the plot to the object called “p”. When I print it out, it shows the ggplot.\nThis object “p” stores the scatter plot structure, and can be saved for later use.\nFor example, we can add labels on the existent ggplot object. And if we want to use the same scatter plot but with a different labels or any other features, just add the new labels or features to the object “p”.\nSo this way we don’t need to type the basic ggplot structure all over again.\nIt’s quite useful if you wanna generate the same plot but with different decorations. Maybe here you want red labels, and at another place you want blue labels, for example."
  },
  {
    "objectID": "slides/09-ggplot2.html#theme-options",
    "href": "slides/09-ggplot2.html#theme-options",
    "title": "Data Visualization – ggplot2 📊",
    "section": "Theme Options",
    "text": "Theme Options\nOptions include\ntheme_grey() (default), theme_bw(), theme_dark(), theme_classic(), etc.\n\n\n\np + theme_bw()\n\n\n\n\n\n\n\n\n\np + theme_dark()\n\n\n\n\n\n\n\n\n\n\nOK theme. You can add a theme layer theme() to your plot to tweak the display of the theme the plot is currently using, including title, axis labels, etc. Check theme() in the help page. You will learn which components of a plot can be changed.\nSome theme options you can use include theme_grey() (default), theme_bw(), theme_dark(), theme_classic(), etc\nTo use another theme, we just add its corresponding theme function to the plot.\nHere shows how the black/white theme and dark theme look like."
  },
  {
    "objectID": "slides/09-ggplot2.html#add-on-ggthemes",
    "href": "slides/09-ggplot2.html#add-on-ggthemes",
    "title": "Data Visualization – ggplot2 📊",
    "section": "Add-on 📦: ggthemes\n",
    "text": "Add-on 📦: ggthemes\n\n\nMany other themes are added by the package ggthemes.\nCheck package website, ggplot2 extensions, and ALL YOUR FIGURE ARE BELONG TO US for more themes.\n\n\n\n\np + ggthemes::theme_economist()\n\n\n\n\n\n\n\n\n\np + ggthemes::theme_fivethirtyeight()\n\n\n\n\n\n\n\n\n\n\nAs I mentioned before, many people are really into ggplot2, and lots of add-on packages have been created for ggplot2, that greatly extend its functionalities.\nFor example, there is a package called ggthemes that provide more theme options for us.\nHere I showed you the same scatter plot but in economist and fivethirtyeight theme."
  },
  {
    "objectID": "slides/09-ggplot2.html#customize-theme",
    "href": "slides/09-ggplot2.html#customize-theme",
    "title": "Data Visualization – ggplot2 📊",
    "section": "Customize Theme",
    "text": "Customize Theme\n\nUse theme() to tweak the display of the current theme, including title, axis labels, etc. Check ?theme.\n\n\n\n\n\np + theme(\n    panel.background = \n        element_rect(fill = \"#FFCC00\",\n                     colour = \"blue\",\n                     linewidth = 2.5,\n                     linetype = \"solid\"),\n    plot.background = \n        element_rect(fill = \"lightblue\"),\n    axis.line = \n        element_line(linewidth = 0.5, \n                     linetype = \"solid\",\n                     colour = \"red\")\n    )\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn conjunction with the theme system, the element_ functions specify the display of how non-data components of the plot are drawn.\nelement_blank(): draws nothing, and assigns no space.\nelement_rect(): borders and backgrounds.\nelement_line(): lines.\nelement_text(): text.\npanel.background: background of plotting area plot.background: background of the entire plot"
  },
  {
    "objectID": "slides/09-ggplot2.html#aesthetics-options",
    "href": "slides/09-ggplot2.html#aesthetics-options",
    "title": "Data Visualization – ggplot2 📊",
    "section": "Aesthetics options",
    "text": "Aesthetics options\nCommonly used characteristics of plotting characters that can be mapped to a specific variable in the data are\n\ncolour\nshape\nsize\n\nalpha (transparency)\n\n\nRemember that we map color to type of car in the scatter plot of hwy mpg and displacement.\nother options can be mapped to a specific variable in the data as well, such as shape, size and alpha that controls the transparency of your geometric objects."
  },
  {
    "objectID": "slides/09-ggplot2.html#colour",
    "href": "slides/09-ggplot2.html#colour",
    "title": "Data Visualization – ggplot2 📊",
    "section": "Colour",
    "text": "Colour\n\n\n\nggplot(\n  data = mpg,\n  mapping = aes(\n    x = displ, \n    y = hwy, \n    color = class)) + #&lt;&lt;\n  geom_point()\n\n\n\n\n\n\n\n\n\n\n\n\nYes, we have seen this."
  },
  {
    "objectID": "slides/09-ggplot2.html#shape",
    "href": "slides/09-ggplot2.html#shape",
    "title": "Data Visualization – ggplot2 📊",
    "section": "Shape",
    "text": "Shape\nMapped to a different variable than colour\n\n\n\nggplot(\n  data = mpg,\n  mapping = aes(\n    x = displ, \n    y = hwy, \n    color = class,\n    shape = drv)) + #&lt;&lt;\n  geom_point()\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can map color to type of car, the class variable, and map point shape to another variable, here the drive type.\nThis way, we have more information in one figure. For a single point or an observation, we can learn its displacement and highway mpg values, and we can also learn its class, the car type by color and drive train type by point shape."
  },
  {
    "objectID": "slides/09-ggplot2.html#shape-1",
    "href": "slides/09-ggplot2.html#shape-1",
    "title": "Data Visualization – ggplot2 📊",
    "section": "Shape",
    "text": "Shape\nMapped to same variable as colour\n\n\n\nggplot(\n  data = mpg,\n  mapping = aes(\n    x = displ, \n    y = hwy, \n    color = class,\n    shape = class)) + #&lt;&lt;\n  geom_point()\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can of course map color and shape to the same variable.\nHere, we use both color and point shape to classify or categorize the type of car.\nBut you guys need to think if it is meaningful and helpful, or it is just redundant, and make it hard to read the plot."
  },
  {
    "objectID": "slides/09-ggplot2.html#size",
    "href": "slides/09-ggplot2.html#size",
    "title": "Data Visualization – ggplot2 📊",
    "section": "Size",
    "text": "Size\n\n\n\nggplot(\n  data = mpg,\n  mapping = aes(\n    x = displ, \n    y = hwy, \n    color = class,\n    shape = class,\n    size = cty)) + #&lt;&lt;\n  geom_point()\n\n\n\n\n\n\n\n\n\n\n\n\n\nOK, Size. Here, we use color and shape to indicate car type, and we use point size to represent city mpg. The higher city mpg, the bigger the point is.\nYou can see that the plot is not very clear and visible. So it is not always good to include much information in one single plot.\nYes, the plot contains lots of information, but we may not be able to read those information."
  },
  {
    "objectID": "slides/09-ggplot2.html#alpha",
    "href": "slides/09-ggplot2.html#alpha",
    "title": "Data Visualization – ggplot2 📊",
    "section": "Alpha",
    "text": "Alpha\n\n\n\nggplot(\n  data = mpg,\n  mapping = aes(\n    x = displ, \n    y = hwy, \n    color = class,\n    shape = class,\n    size = cty,\n    alpha = year)) + #&lt;&lt;\n  geom_point()\n\n\n\n\n\n\n\n\n\n\n\n\n\nHere we further map the transparency of points, alpha to the variable year. So the older the car is, the more transparent the point is.\nWe use lots of aesthetics options at the same time in one figure. Again, in practice this may not be a good idea, and the plot may not visualize the data well.\nIf you are interested in data visualization, there are lots of studies out there talking about what makes a good plot. My suggestion is, don’t put too much information in one single plot. This will make it hard to read."
  },
  {
    "objectID": "slides/09-ggplot2.html#mapping-vs.-setting",
    "href": "slides/09-ggplot2.html#mapping-vs.-setting",
    "title": "Data Visualization – ggplot2 📊",
    "section": "Mapping vs. Setting",
    "text": "Mapping vs. Setting\n\n\nMapping\n\nDetermine the size, alpha, etc.\n\nbased on the values of a variable in the data.\n\nGoes into aes().\n\n\n\nggplot(data = mpg,\n       mapping = aes(x = displ, y = hwy, \n                     size = cty, alpha = year)) + #&lt;&lt;\n    geom_point()\n\n\n\n\n\n\n\n\n\n\nOK. Now I want to talk about the difference between mapping and setting.\nFirst, the aesthetic options such as color, size, shape, alpha can be used in both mapping and setting.\nWhen we use these options in mapping arguments, wrapped by aes() function, we actually map these options to some variables. In other words, we use those options to represents the values of the variables. Like here, the point size is used to represent the city mpg, the different point transparency are for different car years.\nSo there is a mapping between aesthetics options and variables.\nAlright setting. When we use the aesthetics options as a geometry setting, the aesthetics are pure decoration of your plot, the aesthetics are not used to represent any other variable values.\nLook at the example here. If we want to set point size at 5 and point transparency at 0.5, we put size = 5, alpha = 0.5 in the geometry function geom_point(), not in the mapping argument.\nAnd the result is that, all the points in the scatter plot will have size 5 and alpha 0.5. And it is true for all observations and variables. It is not related to any other variables as mapping does. OK."
  },
  {
    "objectID": "slides/09-ggplot2.html#mapping-vs.-setting-1",
    "href": "slides/09-ggplot2.html#mapping-vs.-setting-1",
    "title": "Data Visualization – ggplot2 📊",
    "section": "Mapping vs. Setting",
    "text": "Mapping vs. Setting\n\n\nSetting\n\nDetermine the size, alpha, etc.\n\nnot based on the values of a variable in the data.\n\ngoes into geom_*().\n\n\n\nggplot(data = mpg,\n       mapping = aes(x = displ, y = hwy)) +\n    geom_point(size = 5, alpha = 0.5) #&lt;&lt;\n\n\n\n\n\n\n\n\n\n\nSo here is the summary.\n(geom_point() in the example, but we’ll learn other geoms soon!)"
  },
  {
    "objectID": "slides/09-ggplot2.html#faceting-1",
    "href": "slides/09-ggplot2.html#faceting-1",
    "title": "Data Visualization – ggplot2 📊",
    "section": "Faceting",
    "text": "Faceting\n\nOne way to add additional variables’ information is with aesthetics. But we see that putting all information in one plot may not be a good idea.\nAnother way, particularly useful for categorical variables, is to\n\nsplit your plot into facets, smaller plots that each display one subset of the data.\n\nUseful for exploring conditional relationships and large data.\n\n\nYou see that one way to add additional variables’ information is with aesthetics mapping. But we see that putting all information in one plot may not be a good idea.\nWe can actually present our data using another way, particularly useful for categorical variables, which is split your plot into the so-called facets, so each smaller plot display one subset of the data conditional on some categorical variable.\nThe idea is, we can map color to gender in a one single plot, or we can create two small plots, one for male, and the other for female. OK."
  },
  {
    "objectID": "slides/09-ggplot2.html#section-19",
    "href": "slides/09-ggplot2.html#section-19",
    "title": "Data Visualization – ggplot2 📊",
    "section": "",
    "text": "ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + \n    geom_point() + \n    facet_wrap(~ cyl, ncol = 2) #&lt;&lt;\n\n\n\nHow about we want to create a scatter plot conditional on just one variable, say cylinder?\nInstead of facet_grid(), we can use facet_wrap() function.\nInside the parenthesis, we use ~ followed by the variable name cyl.\nAnd the ggplot will automatically create a display, so that each smaller plot is normally rectangular.\nIf you don’t like the default display, you can specify any number of rows or columns you like.\nFor example, here the number of column is 3."
  },
  {
    "objectID": "slides/09-ggplot2.html#section-20",
    "href": "slides/09-ggplot2.html#section-20",
    "title": "Data Visualization – ggplot2 📊",
    "section": "",
    "text": "ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + \n    geom_point() + \n    facet_grid(drv ~ cyl)  #&lt;&lt;\n\n\n\nSuppose again we would like to see the relationship between hwy and displacement.\nBut now we want to see their relationship given at a different number of cylinders and type of drive trains.\nAnd we can create several scatterplots, each at a particular number of cylinders and type of drive trains.\nHow do we create facets?\nWe can use facet_grid() command to create a matrix-like plot defined by row and column faceting variables, which are usually categorical variables. Inside the parenthesis, we put the row variable ~ column variable.\nSo here, drive values, 4, f, r defines the rows, and cylinder values 4, 5, 6, 8 defines the columns.\nAnd each smaller plot is a scatter plot with some value of drive and some value of cylinder.\nFor example, the top right one is the scatter plot of hwy mpg and displacement when drive is 4 and cylinder is 8."
  },
  {
    "objectID": "slides/09-ggplot2.html#facet-and-color",
    "href": "slides/09-ggplot2.html#facet-and-color",
    "title": "Data Visualization – ggplot2 📊",
    "section": "Facet and Color",
    "text": "Facet and Color\n\nggplot(data = mpg, mapping = aes(x = displ, y = hwy, color = drv)) +\n    geom_point() + \n    facet_grid(drv ~ cyl)\n\n\n\nWe can add color to faceting variables for sure.\nFor example here, we map color to variable drive, which is the row variable in faceting.\nAnd now each row has its own color."
  },
  {
    "objectID": "slides/09-ggplot2.html#facet-and-color-with-no-legend",
    "href": "slides/09-ggplot2.html#facet-and-color-with-no-legend",
    "title": "Data Visualization – ggplot2 📊",
    "section": "Facet and Color with no Legend",
    "text": "Facet and Color with no Legend\n\nggplot(data = mpg, mapping = aes(x = displ, y = hwy, color = drv)) +\n    geom_point() + \n    facet_grid(drv ~ cyl) +\n    guides(color = \"none\") #&lt;&lt;\n\n\ntheme(legend.position = “none”) - Since each row is for one value of drive, it’s pretty clear to see which color is for which value of drive. - If you don’t want the legend, use guides() and set color = FALSE. - Basically guides() can set or remove the legend for a specific aesthetic option. If you have two aesthetics color and size, guides(color = FALSE) will only remove the legend for color and the legend for size will be still there. OK."
  },
  {
    "objectID": "slides/09-ggplot2.html#section-21",
    "href": "slides/09-ggplot2.html#section-21",
    "title": "Data Visualization – ggplot2 📊",
    "section": "",
    "text": "12-Faceting \nIn lab.qmd ## Lab 12 section,\n\n\nggplot(data = _______, mapping = aes(x = ______, y = ______, ______ = drv, shape = _____)) +\n    geom______(______ = 3, ______ = 0.8) + \n    facet_grid(______ ~ _______) +\n    guides(______ = \"none\")"
  },
  {
    "objectID": "slides/09-ggplot2.html#ggplot-for-python",
    "href": "slides/09-ggplot2.html#ggplot-for-python",
    "title": "Data Visualization – ggplot2 📊",
    "section": "ggplot for Python",
    "text": "ggplot for Python\n\nplotnine package\nSyntax are the same as ggplot in R.\n\n\nfrom plotnine import ggplot, geom_point, aes, stat_smooth, facet_wrap\n\n\n\n\n\n\n\n\n\n\n\n\n\nmath3570-s25.github.io/website"
  },
  {
    "objectID": "slides/08-import.html#readr-functions",
    "href": "slides/08-import.html#readr-functions",
    "title": "Data Importing \n",
    "section": "readr 📦 Functions",
    "text": "readr 📦 Functions\n\n\n\n\n\n\n\nFunction\nFormat\nTypical suffix\n\n\n\nread_table()\nwhite space separated values\ntxt\n\n\nread_csv()\ncomma separated values\ncsv\n\n\nread_csv2()\nsemicolon separated values\ncsv\n\n\nread_tsv()\ntab delimited separated values\ntsv\n\n\nread_fwf()\nfixed width files\ntxt\n\n\nread_delim()\ngeneral text file format, must define delimiter\ntxt\n\n\n\n\n\nBe careful: The suffix usually tells us what type of file it is, but no guarantee that these always match.\n\n\nreadr::read_lines(\"./data/murders.csv\", n_max = 3)  ## there is a header\n\n[1] \"state,abb,region,population,total\" \"Alabama,AL,South,4779736,135\"     \n[3] \"Alaska,AK,West,710231,19\"         \n\n\n\nreadr provides the following functions to read your data into R.\n\nBe careful: The suffix usually tells us what type of file it is, but no guarantee that these always match.\nIf you don’t want to open your data file, you can read several lines of your data in R using the function read_lines().\nFor example, I check the first three lines of the murders.csv file. And yes, it is a comma-separated-value or csv file.\nFixed width text files are special cases of text files where the format is specified by column widths, pad character and left/right alignment. Column widths are measured in units of characters. For example, if you have data in a text file where the first column always has exactly 10 characters, and the second column has exactly 5, the third has exactly 12 (and so on), this would be categorized as a fixed width text file."
  },
  {
    "objectID": "slides/08-import.html#reading-data",
    "href": "slides/08-import.html#reading-data",
    "title": "Data Importing \n",
    "section": "Reading Data",
    "text": "Reading Data\nread_csv() prints out a column specification giving us delimiter, name and type of each column.\n\nmurders_csv &lt;- read_csv(file = \"./data/murders.csv\")\n# Rows: 51 Columns: 5\n# ── Column specification ─────────────\n# Delimiter: \",\"\n# chr (3): state, abb, region\n# dbl (2): population, total\nhead(murders_csv)\n\n# A tibble: 6 × 5\n  state      abb   region population total\n  &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt;\n1 Alabama    AL    South     4779736   135\n2 Alaska     AK    West       710231    19\n3 Arizona    AZ    West      6392017   232\n4 Arkansas   AR    South     2915918    93\n5 California CA    West     37253956  1257\n6 Colorado   CO    West      5029196    65\n\n\n\n## View data in RStudio\nview(murders_csv)\n\n\nOK. Let’s try to read the murders.csv file into R. We use read_csv(), and in the first argument, we tell R its file path. Your path is generally not the same as my path, so you get to change it to your path.\nWhen we run read_csv(), it prints out a column specification that gives the name and type of each column."
  },
  {
    "objectID": "slides/08-import.html#missing-values",
    "href": "slides/08-import.html#missing-values",
    "title": "Data Importing \n",
    "section": "Missing Values",
    "text": "Missing Values\n\n\n\nWhich type is the column vector x? Why?\n\n\n\n\n\n\n\n\n\n\n\n\n\nType coercion1 happens and all column elements are transformed to character type.\n\n\nread_csv(\"./data/df-na.csv\")\n\n# A tibble: 9 × 3\n  x     y              z     \n  &lt;chr&gt; &lt;chr&gt;          &lt;chr&gt; \n1 1     a              hi    \n2 &lt;NA&gt;  b              hello \n3 3     Not applicable 9999  \n4 4     d              ola   \n5 5     e              hola  \n6 .     f              whatup\n7 7     g              wassup\n8 8     h              sup   \n9 9     i              &lt;NA&gt;  \n\n\n\n\n\n\nI have a csv file with 3 columns x, y, and z.\nIt looks like it should be some sort of numeric data. Right I have bunch of numbers here.\nCharacter string NA, but that’s just an NA. We have a period here, which is usually used as an NA as well.\nBut when we read this into R, we can see that it’s being read as a character.\nThe reason is that the period which is a character shows up, and type coercion happens and all column elements are transformed to character type.\nHow to solve this kind of problem. We want x to be double and the period is actually a missing value.\nImaging that if you have thousands of lines, you could very easily miss that period.\nA column with elements having different types, they’ll be coerced to the most flexible type. Types from least to most flexible: logical – integer – double – character."
  },
  {
    "objectID": "slides/08-import.html#solution-1-explicit-nas",
    "href": "slides/08-import.html#solution-1-explicit-nas",
    "title": "Data Importing \n",
    "section": "Solution 1: Explicit NAs",
    "text": "Solution 1: Explicit NAs\n\nBy default, read_csv() only recognizes ” “ and NA as a missing value.\nSpecify the values that are used to represent missing values by argument na.\n\n\nread_csv(\"./data/df-na.csv\", \n         na = c(\"\", \"NA\", \".\", \"9999\", \"Not applicable\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# A tibble: 9 × 3\n      x y     z     \n  &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; \n1     1 a     hi    \n2    NA b     hello \n3     3 &lt;NA&gt;  &lt;NA&gt;  \n4     4 d     ola   \n5     5 e     hola  \n6    NA f     whatup\n7     7 g     wassup\n8     8 h     sup   \n9     9 i     &lt;NA&gt;  \n\n\n\n\n\nThe function recognize string NA as missing value, but not period or any other character or strings.\nOne solution is to specify explicitly the value (or values) that are used to represent missing values.\nIf you know what sort of character are used to denote missing values in your data file, you can give those as part of na argument in the read_csv() function.\nFor example here, I treat ““,”NA”, “.”, “9999”, “Not applicable” all as missing values.\nAnd now the class of x is double, and all those character strings are denoted as NA in the loaded data set."
  },
  {
    "objectID": "slides/08-import.html#solution-2-specify-column-types",
    "href": "slides/08-import.html#solution-2-specify-column-types",
    "title": "Data Importing \n",
    "section": "Solution 2: Specify Column Types",
    "text": "Solution 2: Specify Column Types\n\n\n\nread_csv(\"./data/df-na.csv\", \n         col_types = cols(col_double(), \n                     col_character(), \n                     col_character()))\n\n# A tibble: 9 × 3\n      x y              z     \n  &lt;dbl&gt; &lt;chr&gt;          &lt;chr&gt; \n1     1 a              hi    \n2    NA b              hello \n3     3 Not applicable 9999  \n4     4 d              ola   \n5     5 e              hola  \n6    NA f              whatup\n7     7 g              wassup\n8     8 h              sup   \n9     9 i              &lt;NA&gt;  \n\n# Warning message:\n# One or more parsing issues, \n# call `problems()` \n# on your data frame for details\n\n\n\nproblems()\n# A tibble: 1 × 5\n#     row   col expected actual file \n#   &lt;int&gt; &lt;int&gt; &lt;chr&gt;    &lt;chr&gt;  &lt;chr&gt;\n# 1     7     1 a double .      \"\" \n\n\n\n\nAnother solution is to specify column types when you import your data.\nThis might be handy when you know what your column types should be.\nFor example, here I can specify the column types using the col_types argument.\nAll column types are wrapped up in the cols() command, that x is double, y is character and z is character as well.\nAns now you can see x becomes double.\nAnd here we actually get a warning. In row 6 and col x, we expect a double but it is actually a dot or period, which is a character, and so R treats it as NA, which is exactly what I want to do.\nBut R send a message telling us about this, and make sure this is what we want to do.\nThis option might be preferable if you cannot scan your data file, or don;t know what convention is being used for missing values in your data file, but you happen to know your column types.\nThe downside of this is that, here, Not applicable and 9999, they are all treated as valid character values, and they are not missing values. So be careful about this. You may need to manually clean your data."
  },
  {
    "objectID": "slides/08-import.html#column-types",
    "href": "slides/08-import.html#column-types",
    "title": "Data Importing \n",
    "section": "Column Types",
    "text": "Column Types\n\n\ntype function\ndata type\n\n\n\ncol_character()\ncharacter\n\n\ncol_date()\ndate\n\n\ncol_datetime()\nPOSIXct (date-time)\n\n\ncol_double()\ndouble (numeric)\n\n\ncol_factor()\nfactor\n\n\ncol_guess()\nlet readr guess (default)\n\n\ncol_integer()\ninteger\n\n\ncol_logical()\nlogical\n\n\ncol_number()\nnumbers mixed with non-number characters\n\n\ncol_numeric()\ndouble or integer\n\n\ncol_skip()\ndo not read\n\n\ncol_time()\ntime\n\n\n\n\nHere shows all possible column types you can use when importing your data into R. No need to memorize it. But just aware of them, and use them when you need to."
  },
  {
    "objectID": "slides/08-import.html#writing-data",
    "href": "slides/08-import.html#writing-data",
    "title": "Data Importing \n",
    "section": "Writing Data",
    "text": "Writing Data\n\n## Create tibbles using a row-by-row layout\n(df &lt;- tribble(\n  ~x, ~y,\n  1,  \"a\",\n  2,  \"b\",\n  3,  \"c\"\n))\n\n# A tibble: 3 × 2\n      x y    \n  &lt;dbl&gt; &lt;chr&gt;\n1     1 a    \n2     2 b    \n3     3 c    \n\n## same as tibble(x = 1:3, y = c(a, b, c))\n\n\n## save data to \"./data/df.csv\"\ndf |&gt; write_csv(file = \"./data/df.csv\")\n\n\nWe can also write our data to a csv file as well.\nHere I create a tibble called df, and then I use write_csv() function to write the data set df to the file df.csv."
  },
  {
    "objectID": "slides/08-import.html#read_rds-and-write_rds",
    "href": "slides/08-import.html#read_rds-and-write_rds",
    "title": "Data Importing \n",
    "section": "\nread_rds() and write_rds()\n",
    "text": "read_rds() and write_rds()\n\n\nWe save an R object (usually a data set) in .Rds in the R binary file format. 1\n\n\n\nreadr::write_rds(cars, \n                 file = \"./data/cars.rds\") \n# fs::dir_ls(path = \"./data\") |&gt; head(10)\n\n\n\n\nmy_car &lt;- readr::read_rds(file = \"./data/cars.rds\") \nhead(my_car, 3)\n\n  speed dist\n1     4    2\n2     4   10\n3     7    4\n\n\n\nWe save an R object (usually a data set) in .Rdsm the R binary file format.\nRemember we talked about RData format last time, right?\nR provides two file formats of its own for storing data, .RDS and .RData. RDS files can store a single R object, and RData files can store multiple R objects.\nUsually, if we save a data set, we use .Rds, and if we save several objects, and the objects are some variables or functions, we use .RData.\nRead the data back into R.\n\n\nCheck R built-in data sets using command data()."
  },
  {
    "objectID": "slides/08-import.html#section-4",
    "href": "slides/08-import.html#section-4",
    "title": "Data Importing \n",
    "section": "",
    "text": "10-Import Data \n\n\nIf you haven’t, install and load the tidyverse package.\n\nIn lab.qmd ## Lab 10 section,        \n\nImport ssa_male_prob.csv and ssa_female_prob.Rds in the data folder using read_csv() and call them ssa_male and ssa_female, respectively.\n\n\nssa_male &lt;- readr::read____(____________)\nssa_female &lt;- readr::read____(____________)\n\n\nPlot Age (x-axis) vs. LifeExp (y-axis) for Female. The type should be “line”, and the line color is red. Add x-label, y-label and title to your plot.\n\n\nplot(x = _____, y = _____, type = ______, col = ______,\n     xlab = ______, ylab = _______, main = ____________)\n\n\nUse lines() to add a line of Age (x-axis) vs. LifeExp (y-axis) for Male to the plot. The color is blue.\n\n\nlines(x = _____, y = _____, col = ______)\n\n\n\nlibrary(tidyverse)\nssa &lt;- read_csv(file = \"./data/ssa-death-probability.csv\")\nssa_male &lt;- ssa[ssa$Sex == \"Male\", ]\nssa_female &lt;- ssa[ssa$Sex == \"Female\", ]\nplot(x = ssa_female$Age, y = ssa_female$LifeExp, \n     type = \"l\", col = 2, lwd = 3,\n     xlab = \"Age\", ylab = \"Life Exp\",\n     main = \"Age vs. Life Exp by Gender\")\nlines(ssa_male$Age, ssa_male$LifeExp, col = 4, lwd = 3)"
  },
  {
    "objectID": "slides/08-import.html#readxl-functions",
    "href": "slides/08-import.html#readxl-functions",
    "title": "Data Importing \n",
    "section": "readxl 📦 Functions",
    "text": "readxl 📦 Functions\n\n\n\n\n\n\n\nFunction\nFormat\nTypical suffix\n\n\n\nread_excel()\nauto detect the format\nxls, xlsx\n\n\nread_xls()\noriginal format\nxls\n\n\nread_xlsx()\nnew format\nxlsx\n\n\n\n\nThe Microsoft Excel can have more than one sheet in one file.\nThe functions above read the first sheet by default.\nThe excel_sheets() gives us the names of all the sheets in an Excel file.\n\n\nlibrary(readxl)\nexcel_sheets(\"./data/2010_bigfive_regents.xls\")\n\n[1] \"Sheet1\" \"Sheet2\" \"Sheet3\"\n\n\n\nHere shows the main read excel functions. They are pretty similar to readr functions, but this time, your data file is not a text file, but a microsoft excel file.\nThe Microsoft Excel can have more than one sheet in one file.\nThe functions listed above read the first sheet by default.\nIf you don’t want open your excel file and check its sheet names, the excel_sheets() function gives us the names of all the sheets in an Excel file."
  },
  {
    "objectID": "slides/08-import.html#sheet-names",
    "href": "slides/08-import.html#sheet-names",
    "title": "Data Importing \n",
    "section": "Sheet Names",
    "text": "Sheet Names\n\nThe sheet names can be passed to the sheet argument to read sheets other than the first.\n\n\nexcel_sheets(\"./data/2010_bigfive_regents.xls\")\n\n[1] \"Sheet1\" \"Sheet2\" \"Sheet3\"\n\n(data_xls &lt;- read_xls(path = \"./data/2010_bigfive_regents.xls\", \n                      sheet = \"Sheet3\", \n                      skip = 1))\n\n# A tibble: 19 × 6\n  Scores `131024` `113804` `104201` `103886` `91756`\n   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;\n1     10       NA       64        8      227      34\n2     11        6       83       11      217      58\n3     12       23       87        7       28      67\n4     13        1       54       16      230      42\n5     14        3      145       18      303      57\n6     15       58      151       50      192      98\n7     16        1      129       13      156     125\n8     17       73      214       59      163     115\n# ℹ 11 more rows\n\n\n\nThe sheet names can be passed to the sheet argument in the functions to read sheets other than the first.\nFor example, here we ask R to read the Sheet1 in the favourite-food excel file.\nWe can also specify an integer that indicates the position of the sheet.\nWe don’t have a lab exercise on this. You have data and code is right here. You can practice and see if you can read the excel file. range = cell_rows(102:151)"
  },
  {
    "objectID": "slides/08-import.html#pd.read_csv",
    "href": "slides/08-import.html#pd.read_csv",
    "title": "Data Importing \n",
    "section": "pd.read_csv",
    "text": "pd.read_csv\n\nimport numpy as np\nimport pandas as pd\n\npy_df = pd.read_csv('./data/murders.csv')\npy_df.head()\n\n        state abb region  population  total\n0     Alabama  AL  South     4779736    135\n1      Alaska  AK   West      710231     19\n2     Arizona  AZ   West     6392017    232\n3    Arkansas  AR  South     2915918     93\n4  California  CA   West    37253956   1257"
  },
  {
    "objectID": "slides/08-import.html#pd.dataframe.to_csv",
    "href": "slides/08-import.html#pd.dataframe.to_csv",
    "title": "Data Importing \n",
    "section": "pd.DataFrame.to_csv",
    "text": "pd.DataFrame.to_csv\n\nw = {\"x\":[1, 2, 3], \n     \"y\":['a', 'b','c']}\nwdf = pd.DataFrame(w)\n\nwdf.to_csv(\"./data/wdf.csv\")\nmydf = pd.read_csv('./data/wdf.csv')\nmydf.head()\n\n   Unnamed: 0  x  y\n0           0  1  a\n1           1  2  b\n2           2  3  c\n\n\n\n## index = False means don't write row names\nwdf.to_csv(\"./data/wdf.csv\", index = False)\nmydf = pd.read_csv('./data/wdf.csv')\nmydf.head()\n\n   x  y\n0  1  a\n1  2  b\n2  3  c"
  },
  {
    "objectID": "slides/08-import.html#apache-arrow-for-r-and-python",
    "href": "slides/08-import.html#apache-arrow-for-r-and-python",
    "title": "Data Importing \n",
    "section": "\nApache Arrow for R and Python\n",
    "text": "Apache Arrow for R and Python\n\n\nApache Arrow develops big data systems to process and move data fast.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmath3570-s25.github.io/website"
  },
  {
    "objectID": "course-news.html",
    "href": "course-news.html",
    "title": "News/Announcements",
    "section": "",
    "text": "Any announcement will be posted in this page. The latest news will also be put on top of the main page.",
    "crumbs": [
      "Course information",
      "News/Annoucements"
    ]
  },
  {
    "objectID": "course-news.html#jan-17-2025",
    "href": "course-news.html#jan-17-2025",
    "title": "News/Announcements",
    "section": "Jan 17, 2025",
    "text": "Jan 17, 2025\n\nTA help desk hours at Cudahy Hall 301\n\nMonday: 1 – 2 PM\nTuesday: 12 – 1 PM,\nThursday: 12 – 2 PM",
    "crumbs": [
      "Course information",
      "News/Annoucements"
    ]
  },
  {
    "objectID": "course-news.html#jan-14-2025",
    "href": "course-news.html#jan-14-2025",
    "title": "News/Announcements",
    "section": "Jan 14, 2025",
    "text": "Jan 14, 2025\n\nNo office hours first week.",
    "crumbs": [
      "Course information",
      "News/Annoucements"
    ]
  },
  {
    "objectID": "course-news.html#jan-7-2025",
    "href": "course-news.html#jan-7-2025",
    "title": "News/Announcements",
    "section": "Jan 7, 2025",
    "text": "Jan 7, 2025\n\nThe background survey form is at https://forms.office.com/r/3ntBAWupYS.",
    "crumbs": [
      "Course information",
      "News/Annoucements"
    ]
  },
  {
    "objectID": "course-overview.html",
    "href": "course-overview.html",
    "title": "MATH/COSC 3570 Introduction to Data Science (Spring 2025)",
    "section": "",
    "text": "This course introduces main aspects of doing a practical data science project, from importing data to deploying what is learned from data. We start with learning popular data science tools such as basic R and Python programming, Git and GitHub, and interactive publishing system Quarto. Then we learn data importing, data visualization and data wrangling using both R and Python. The second half of the course focuses on several basic simulation and machine learning methods, including Monte Carlo simulation, linear regression, K-nearest neighbors, logistic regression, principal component analysis, and K-means clustering. We learn R tidyverse and tidymodels packages. For Python, Pandas, NumPy, and Scikit-Learn libraries are introduced.",
    "crumbs": [
      "Course information",
      "Overview"
    ]
  },
  {
    "objectID": "hw/hw3.html",
    "href": "hw/hw3.html",
    "title": "Homework 3: Probability, Statistics and Machine Learning",
    "section": "",
    "text": "Note: For any simulation or random sampling, set the random seed at your student ID number, for example set.seed(6145678)."
  },
  {
    "objectID": "hw/hw3.html#monte-carlo-simulation",
    "href": "hw/hw3.html#monte-carlo-simulation",
    "title": "Homework 3: Probability, Statistics and Machine Learning",
    "section": "1.1 Monte Carlo Simulation",
    "text": "1.1 Monte Carlo Simulation\n\n\n\n\n\n\n\n\n\n\n\n\nSuppose you are in a classroom with 30 people. If we assume this is a randomly selected group of 30 people, what is the chance that at least two people have the same birthday? Here we use a Monte Carlo simulation. For simplicity, we assume nobody was born on February 29.\n\n\n\nNote that birthdays can be represented as numbers between 1 and 365, so a sample of 30 birthdays can be obtained like this:\n\n\nn &lt;- 30\nbdays &lt;- sample(x = 1:365, size = n, replace = TRUE)\n\n\nTo check if in this particular set of 30 people we have at least two with the same birthday, we can use the function duplicated(), which returns TRUE whenever an element of a vector is a duplicate. Here is an example:\n\n\nduplicated(c(1, 2, 3, 1, 4, 3, 5))\n\n[1] FALSE FALSE FALSE  TRUE FALSE  TRUE FALSE\n\n\nThe second time 1 and 3 appear, we get a TRUE.\n\nTo check if two birthdays were the same, we simply use the any() and duplicated() functions like this:\n\n\nany(duplicated(bdays))\n\n[1] FALSE\n\n\nIn this case, we see that it did happen. At least two people had the same birthday.\nTo estimate the probability of a shared birthday in the group, repeat this experiment by sampling sets of 30 birthdays 10000 times, and find the relative frequency of the event that at least two people had the same birthday.\n\n## code\n# set.seed(your ID number)"
  },
  {
    "objectID": "hw/hw3.html#central-limit-theorem",
    "href": "hw/hw3.html#central-limit-theorem",
    "title": "Homework 3: Probability, Statistics and Machine Learning",
    "section": "1.2 Central Limit Theorem",
    "text": "1.2 Central Limit Theorem\nSuppose random variables \\(X_1, X_2, \\dots, X_n\\) are independent and follow Chi-squared distribution with degrees of freedom 1, \\(\\chi^2_{df=1}\\).\n\nUse dchisq() to plot \\(\\chi^2_{df=1}\\) distribution. Consider \\(x\\in (0, 5)\\).\n\n\n## code\n\n\nConsider three sample sizes \\(n = 2, 8, 100\\), and set the sample size of the sample mean \\(\\overline{X}_n\\) be \\(1000\\). Show the sampling distribution of \\(\\overline{X}_n\\), i.e., the collection \\(\\{\\overline{X}_n^{(m)}\\}_{m=1}^{1000}\\), looks more and more like Gaussian as \\(n\\) increases by making histograms of \\(\\overline{X}_n\\) samples with \\(n = 2, 8, 100\\). The procedure is the following:\n\nFor each \\(n = 2, 8, 100\\),\n\nDraw \\(n\\) values \\(x_1, x_2, \\dots, x_n\\) using rchisq(n, df = 1).\nCompute the mean of the \\(n\\) values, which is \\(\\overline{x}_n\\).\nRepeat i. and ii. 1000 times to obtain 1000 \\(\\overline{x}_n\\)s.\nPlot the histogram of these 1000 \\(\\overline{x}_n\\)s.\n\n\n## code\n# set.seed(your ID number)"
  },
  {
    "objectID": "hw/hw3.html#linear-regression",
    "href": "hw/hw3.html#linear-regression",
    "title": "Homework 3: Probability, Statistics and Machine Learning",
    "section": "2.1 Linear Regression",
    "text": "2.1 Linear Regression\nA pharmaceutical firm would like to obtain information on the relationship between the dose level and potency of a drug product. To do this, each of 15 test tubes is inoculated with a virus culture and incubated for 5 days at 30°C. Three test tubes are randomly assigned to each of the five different dose levels to be investigated (2, 4, 8, 16, and 32 mg). Each tube is injected with only one dose level, and the response of interest is obtained.\n\nImport dose.csv into your working session. The data set is not tidy. Use pivot_longer() to make it tidy as the shown tibble below. Call the tidy data set dose_tidy.\n\n\n## code\n\n## # A tibble: 15 × 3\n##    dose_level tube  response\n##         &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;\n##  1          2 tube1        5\n##  2          2 tube2        7\n##  3          2 tube3        3\n##  4          4 tube1       10\n##  5          4 tube2       12\n##  6          4 tube3       14\n##  7          8 tube1       15\n##  8          8 tube2       17\n##  9          8 tube3       18\n## 10         16 tube1       20\n## 11         16 tube2       21\n## 12         16 tube3       19\n## 13         32 tube1       23\n## 14         32 tube2       24\n## 15         32 tube3       29\n\n\nFit a simple linear regression with the predictor \\(\\texttt{dose level}\\) for response. Print the fitted result.\n\n\n## code\n\n\nWith (2), plot the data with a \\(95\\%\\) confidence interval for the mean response.\n\n\n## code\n\n\nFit a simple linear regression model with the predictor \\(\\texttt{ln(dose level)}\\) for response, where \\(\\ln = \\log_e\\). Print the fitted result.\n\n\n## code\n\n\nWith (4), plot the data \\((\\ln(\\text{dose level})_i, \\text{response}_i), i = 1, \\dots, 15\\) with a \\(95\\%\\) confidence interval for the mean response.\n\n\n## code\n\n\nDraw residual plots of Model in (2) and (4). According to the plots, which model you think is better?\n\n\n## code\n\n\nImport dose_tidy.csv and redo (2) using Python. Show the slope and intercept.\n\n\n\n# code\n\n\nUse Python to predict the response value when the dose level is 10 and 30.\n\n\n\n# code"
  },
  {
    "objectID": "hw/hw3.html#logistic-regression",
    "href": "hw/hw3.html#logistic-regression",
    "title": "Homework 3: Probability, Statistics and Machine Learning",
    "section": "2.2 Logistic Regression",
    "text": "2.2 Logistic Regression\n\nImport body.csv. Split the data into a training set and a test set. Set the random seed at your student ID number. Use 80:20 rule.\n\n\n# code\n# set.seed(your ID number)\n\n\nFit a logistic regression with the predictor HEIGHT using the training sample data. Find the probability that the subject is male given HEIGHT = 165.\n\n\n# code\n\n\nFit a logistic regression with the predictor BMI using the training sample data. Find the probability that the subject is male given BMI = 25.\n\n\n# code\n\n\nDo the classification on the test set for the model (2) and (3), and compute the test accuracy rate. Which model gives us higher accuracy rate?\n\n\n# code\n\n\nUse Python to split the body data into a training set and a test set.\n\n\n\n## code\n\n\nUse Python to fit a logistic regression with the predictor BMI using the training sample data. Find the probability that the subject is male given BMI = 25.\n\n\n\n# code\n\n\nUse Python to do the classification on the test set. Compute the test accuracy rate.\n\n\n\n# code"
  },
  {
    "objectID": "hw/hw3.html#k-nearest-neighbors-knn",
    "href": "hw/hw3.html#k-nearest-neighbors-knn",
    "title": "Homework 3: Probability, Statistics and Machine Learning",
    "section": "2.3 K-Nearest Neighbors (KNN)",
    "text": "2.3 K-Nearest Neighbors (KNN)\n\nFit the KNN with \\(K=1\\) and \\(10\\) using BMI on the training data and do the classification on the same test set used in logistic regression. Obtain the confusion matrix for the two \\(K\\)s. Which \\(K\\) performs better? Why?\n\n\n# code"
  },
  {
    "objectID": "hw/hw1.html",
    "href": "hw/hw1.html",
    "title": "Homework 1: Quarto, Basic Syntax and Data Importing",
    "section": "",
    "text": "Please introduce yourself. You can share anything, your hometown, major, family, hobbies, working experience, honors and awards, special skills, etc, yes anything! Your autobiography should include:\n\nAt least two paragraphs (Paragraphs are separated by a blank line)\nBold text\nItalic text\nText with both bold AND italic font (Not mentioned in class, but you should be able to figure it out)\nClickable text with a hyperlink\nBlockquote\nListed items\nemoji\n\nTo make your emoji works, add from: markdown+emoji in your YAML header, like\n---\ntitle: \"My Document\"\nfrom: markdown+emoji\n---\nThen add emoji to your writing by typing :EMOJICODE:. Check emoji cheatsheet.\n\nYour Self-Introduction:"
  },
  {
    "objectID": "hw/hw1.html#vector",
    "href": "hw/hw1.html#vector",
    "title": "Homework 1: Quarto, Basic Syntax and Data Importing",
    "section": "3.1 Vector",
    "text": "3.1 Vector\nUse the built-in data set LakeHuron that records annual measurements of the level, in feet, of Lake Huron 1875–1972.\n\nReturn a logical vector that shows whether the lake level is higher than the average level or not.\n\n\nReturn years that have a level higher than the average."
  },
  {
    "objectID": "hw/hw1.html#data-frame",
    "href": "hw/hw1.html#data-frame",
    "title": "Homework 1: Quarto, Basic Syntax and Data Importing",
    "section": "3.2 Data Frame",
    "text": "3.2 Data Frame\n\nMake the mtcars dataset as a tibble using as_tibble(). Call it tbl.\n\n\nPrint the sub data of tbl that contains the 11th to 15th rows and the last three columns.\n\n\nGrab the second and the third columns of tbl.\n\n\nExtract the fourth column of tbl as a numerical vector.\n\n\nStart with tbl, use the pipe operator |&gt; to do the followings sequentially.\n\nextract the first 10 observations (rows) using head()\nfind the column names colnames()\nsort the columns names using sort() in a decreasing order. (alphabetically from z to a)"
  },
  {
    "objectID": "hw/hw1.html#data-importing",
    "href": "hw/hw1.html#data-importing",
    "title": "Homework 1: Quarto, Basic Syntax and Data Importing",
    "section": "3.3 Data Importing",
    "text": "3.3 Data Importing\n\nUse readxl::read_excel() to read the data sales.xlsx in the data folder. Use arguments sheet, skip and col_names so that the output looks like\n# A tibble: 9 x 2\n  id      n    \n  &lt;chr&gt;   &lt;chr&gt;\n1 Brand 1 n    \n2 1234    8    \n3 8721    2    \n4 1822    3    \n5 Brand 2 n    \n6 3333    1    \n# … with 3 more rows\n\n\nUse readxl::read_excel() to read in the favourite-food.xlsx file in the data folder and call the data fav_food. Use the argument na to treat “N/A” and “99999” as a missing value. Print the data out."
  },
  {
    "objectID": "hw/hw1.html#pandas-data-frame",
    "href": "hw/hw1.html#pandas-data-frame",
    "title": "Homework 1: Quarto, Basic Syntax and Data Importing",
    "section": "4.1 Pandas Data Frame",
    "text": "4.1 Pandas Data Frame\n\nImport the data set mtcars.csv using pd.read_csv(). Then print the first five rows.\n\n\nUse method .iloc to obtain the first and fourth rows, and the second and third columns. Name the data dfcar.\n\n\nSet the row names of dfcar to Mazda and Hornet.\n\n\nUse method .loc to obtain row Hornet and column disp."
  },
  {
    "objectID": "hw/hw1.html#numpy-array",
    "href": "hw/hw1.html#numpy-array",
    "title": "Homework 1: Quarto, Basic Syntax and Data Importing",
    "section": "4.2 NumPy Array",
    "text": "4.2 NumPy Array\nIn class, we learned the R data structure matrix:\n\nmat &lt;- matrix(data = 1:6, nrow = 3, ncol = 2)\nmat[c(1, 3), 1] \nmat_c &lt;- matrix(data = c(7, 0, 0, 8, 2, 6), nrow = 3, ncol = 2)\ncbind(mat, mat_c)  \n\n\nUse NumPy methods to create an array equivalent to mat. Call it mat_py.\n\n\nSubset the mat_py so that the result is equivalent to mat[c(1, 3), 1].\n\n\nCreate an array equivalent to mat_c. Call it mat_py_c. Then combine them by columns using np.hstack()."
  },
  {
    "objectID": "weeks/week-15.html",
    "href": "weeks/week-15.html",
    "title": "Week 15",
    "section": "",
    "text": "Important",
    "crumbs": [
      "Weekly materials",
      "Week 15"
    ]
  },
  {
    "objectID": "weeks/week-15.html#participate",
    "href": "weeks/week-15.html#participate",
    "title": "Week 15",
    "section": "Participate",
    "text": "Participate\n🖥️ Slides - Principal Component Analysis\nr fontawesome::fa(\"table\") USArrests",
    "crumbs": [
      "Weekly materials",
      "Week 15"
    ]
  },
  {
    "objectID": "weeks/week-15.html#reading",
    "href": "weeks/week-15.html#reading",
    "title": "Week 15",
    "section": "Reading",
    "text": "Reading\n📖",
    "crumbs": [
      "Weekly materials",
      "Week 15"
    ]
  },
  {
    "objectID": "weeks/week-15.html#exercise",
    "href": "weeks/week-15.html#exercise",
    "title": "Week 15",
    "section": "Exercise",
    "text": "Exercise\n📋 Lab-23 Principal Component Analysis\nr fontawesome::fa(\"table\") iris\n\n\nBack to course schedule ⏎",
    "crumbs": [
      "Weekly materials",
      "Week 15"
    ]
  },
  {
    "objectID": "weeks/week-16.html",
    "href": "weeks/week-16.html",
    "title": "Week 16",
    "section": "",
    "text": "Important",
    "crumbs": [
      "Weekly materials",
      "Week 16"
    ]
  },
  {
    "objectID": "weeks/week-16.html#participate",
    "href": "weeks/week-16.html#participate",
    "title": "Week 16",
    "section": "Participate",
    "text": "Participate\n🖥️ Slides - K-Means Clustering\n Data - clus_data",
    "crumbs": [
      "Weekly materials",
      "Week 16"
    ]
  },
  {
    "objectID": "weeks/week-16.html#reading",
    "href": "weeks/week-16.html#reading",
    "title": "Week 16",
    "section": "Reading",
    "text": "Reading\n📖",
    "crumbs": [
      "Weekly materials",
      "Week 16"
    ]
  },
  {
    "objectID": "weeks/week-16.html#exercise",
    "href": "weeks/week-16.html#exercise",
    "title": "Week 16",
    "section": "Exercise",
    "text": "Exercise\n📋 Lab-24 K-Means Clustering\n palmerpenguins::penguins\n\nlibrary(palmerpenguins)\npeng &lt;- penguins[complete.cases(penguins), ] |&gt; \n    select(flipper_length_mm, bill_length_mm)\n\n\n\nBack to course schedule ⏎",
    "crumbs": [
      "Weekly materials",
      "Week 16"
    ]
  },
  {
    "objectID": "weeks/week-5-old.html",
    "href": "weeks/week-5-old.html",
    "title": "Week 6",
    "section": "",
    "text": "Important"
  },
  {
    "objectID": "weeks/week-5-old.html#participate",
    "href": "weeks/week-5-old.html#participate",
    "title": "Week 6",
    "section": "Participate",
    "text": "Participate\n🖥️ Slides - Data Importing\nr fontawesome::fa(\"table\") murders.csv\nr fontawesome::fa(\"table\") df-na.csv\nr fontawesome::fa(\"table\") cars.rds\nr fontawesome::fa(\"table\") 2010_bigfive_regents.xls"
  },
  {
    "objectID": "weeks/week-5-old.html#reading-and-resources",
    "href": "weeks/week-5-old.html#reading-and-resources",
    "title": "Week 6",
    "section": "Reading and Resources",
    "text": "Reading and Resources\n📖 R for Data Science - Data Import\n📖 R for Data Science - Data Visualization"
  },
  {
    "objectID": "weeks/week-5-old.html#exercise",
    "href": "weeks/week-5-old.html#exercise",
    "title": "Week 6",
    "section": "Exercise",
    "text": "Exercise\n📋 Lab-10 Data Importing\nr fontawesome::fa(\"table\") ssa_male_prob.csv\nr fontawesome::fa(\"table\") ssa_female_prob.Rds\n\n\nBack to course schedule ⏎"
  },
  {
    "objectID": "weeks/week-13.html",
    "href": "weeks/week-13.html",
    "title": "Week 13",
    "section": "",
    "text": "Important",
    "crumbs": [
      "Weekly materials",
      "Week 13"
    ]
  },
  {
    "objectID": "weeks/week-13.html#participate",
    "href": "weeks/week-13.html#participate",
    "title": "Week 13",
    "section": "Participate",
    "text": "Participate\n🖥️ Slides - Logistic Regression\nr fontawesome::fa(\"table\") Data - body",
    "crumbs": [
      "Weekly materials",
      "Week 13"
    ]
  },
  {
    "objectID": "weeks/week-13.html#reading",
    "href": "weeks/week-13.html#reading",
    "title": "Week 13",
    "section": "Reading",
    "text": "Reading\n📖",
    "crumbs": [
      "Weekly materials",
      "Week 13"
    ]
  },
  {
    "objectID": "weeks/week-13.html#exercise",
    "href": "weeks/week-13.html#exercise",
    "title": "Week 13",
    "section": "Exercise",
    "text": "Exercise\n📋 Lab-21 Logistic Regression\n\n\nBack to course schedule ⏎",
    "crumbs": [
      "Weekly materials",
      "Week 13"
    ]
  },
  {
    "objectID": "weeks/week-10.html",
    "href": "weeks/week-10.html",
    "title": "Week 10",
    "section": "",
    "text": "Important",
    "crumbs": [
      "Weekly materials",
      "Week 10"
    ]
  },
  {
    "objectID": "weeks/week-10.html#participate",
    "href": "weeks/week-10.html#participate",
    "title": "Week 10",
    "section": "Participate",
    "text": "Participate\n🖥️ Slides - Tidying Data\n🖥️ Slides - Probability and Statistics",
    "crumbs": [
      "Weekly materials",
      "Week 10"
    ]
  },
  {
    "objectID": "weeks/week-10.html#exercise",
    "href": "weeks/week-10.html#exercise",
    "title": "Week 10",
    "section": "Exercise",
    "text": "Exercise\n📋 Lab-17 tidyr\nr fontawesome::fa(\"table\") trump.csv\n📋 Lab-18 Probability\n\n\nBack to course schedule ⏎",
    "crumbs": [
      "Weekly materials",
      "Week 10"
    ]
  },
  {
    "objectID": "weeks/week-3.html",
    "href": "weeks/week-3.html",
    "title": "Week 3",
    "section": "",
    "text": "Important",
    "crumbs": [
      "Weekly materials",
      "Week 3"
    ]
  },
  {
    "objectID": "weeks/week-3.html#participate",
    "href": "weeks/week-3.html#participate",
    "title": "Week 3",
    "section": "Participate",
    "text": "Participate\n🖥️ Slides - Quarto\n🖥️ Slides - R/Python Syntax",
    "crumbs": [
      "Weekly materials",
      "Week 3"
    ]
  },
  {
    "objectID": "weeks/week-3.html#exercise",
    "href": "weeks/week-3.html#exercise",
    "title": "Week 3",
    "section": "Exercise",
    "text": "Exercise\n📋 Lab-02 Quarto File\n📋 Lab-03 Markdown\n📋 Lab-04 Code Chunk\n📋 Lab-05 R Data Summary\n📋 Lab-06 Python Data Structure\n📋 Lab-07 Plotting",
    "crumbs": [
      "Weekly materials",
      "Week 3"
    ]
  },
  {
    "objectID": "weeks/week-3.html#reading-and-resources",
    "href": "weeks/week-3.html#reading-and-resources",
    "title": "Week 3",
    "section": "Reading and Resources",
    "text": "Reading and Resources\n📖 The R Graph Gallery\n📖 matplotlib\n\nMarkdown\n📖 Markdown Tutorial\n📖 Mastering Markdown GitHub Guides\n📖 Markdown Guide\n\n\nQuarto\n📖 Quarto Website\n📖 Get Started with Quarto\n📖 R for Data Science - Quarto\n\n\nBack to course schedule ⏎",
    "crumbs": [
      "Weekly materials",
      "Week 3"
    ]
  },
  {
    "objectID": "weeks/week-4.html",
    "href": "weeks/week-4.html",
    "title": "Week 4",
    "section": "",
    "text": "Important",
    "crumbs": [
      "Weekly materials",
      "Week 4"
    ]
  },
  {
    "objectID": "weeks/week-4.html#participate",
    "href": "weeks/week-4.html#participate",
    "title": "Week 4",
    "section": "Participate",
    "text": "Participate\n🖥️ Slides - R/Python Syntax",
    "crumbs": [
      "Weekly materials",
      "Week 4"
    ]
  },
  {
    "objectID": "weeks/week-4.html#reading-and-resources",
    "href": "weeks/week-4.html#reading-and-resources",
    "title": "Week 4",
    "section": "Reading and Resources",
    "text": "Reading and Resources\n📖 The R Graph Gallery\n📖 matplotlib",
    "crumbs": [
      "Weekly materials",
      "Week 4"
    ]
  },
  {
    "objectID": "weeks/week-4.html#perform",
    "href": "weeks/week-4.html#perform",
    "title": "Week 4",
    "section": "Perform",
    "text": "Perform\n📋 Lab-05 R Data Summary\n📋 Lab-06 Python Data Structure\n📋 Lab-07 Plotting\n\n\nBack to course schedule ⏎",
    "crumbs": [
      "Weekly materials",
      "Week 4"
    ]
  },
  {
    "objectID": "weeks/week-7.html",
    "href": "weeks/week-7.html",
    "title": "Week 7",
    "section": "",
    "text": "Important",
    "crumbs": [
      "Weekly materials",
      "Week 7"
    ]
  },
  {
    "objectID": "weeks/week-7.html#participate",
    "href": "weeks/week-7.html#participate",
    "title": "Week 7",
    "section": "Participate",
    "text": "Participate\n🖥️ Slides -Visualizing Data\n🖥️ Slides - Interactive Visualization\nr fontawesome::fa(\"table\") Data - loans\nr fontawesome::fa(\"table\") Data - Murders",
    "crumbs": [
      "Weekly materials",
      "Week 7"
    ]
  },
  {
    "objectID": "weeks/week-7.html#reading-and-resources",
    "href": "weeks/week-7.html#reading-and-resources",
    "title": "Week 7",
    "section": "Reading and Resources",
    "text": "Reading and Resources\n📖 More add-on r emo::ji(\"package\"): ggplot2 extensions\n📖 The R Graph Gallery\n📖 R Graphics Cookbook\n📖 R CHARTS\n📖 R for Data Science - Data Transformation",
    "crumbs": [
      "Weekly materials",
      "Week 7"
    ]
  },
  {
    "objectID": "weeks/week-7.html#exercise",
    "href": "weeks/week-7.html#exercise",
    "title": "Week 7",
    "section": "Exercise",
    "text": "Exercise\n📋 Lab-12 Faceting\n📋 Lab-13 Visualization\n📋 Lab-14 Interactive Visualization (Present)\n\n\nBack to course schedule ⏎",
    "crumbs": [
      "Weekly materials",
      "Week 7"
    ]
  },
  {
    "objectID": "present-work.html",
    "href": "present-work.html",
    "title": "Midterm Visualization Project",
    "section": "",
    "text": "The Whales: Brady Nelson, Brody Roessler, Christian Filardo, Dorien Vazquez, Filip Kisielewski\n\nHow do game sales correlate to console popularity by global region\n\nAnalytics Avengers (4): Sophia Bryant, Kumassi Browne, Charles Kendrick Jr, Isabel Bauer\n\nNetflix Analysis\n\nSyntax Squad: Nick Panoske, Kate Gibson, Annika Lautenbach, Simon Glarner, Sophia Ferru\n\nNo Project Title\n\nData Detectives: Jordan Dubeck, Justice Milhoan, Grace Placko, Jane Harvey, Madison Zursin\n\nHappiness of the World Over Time\n\nHala Madrid: Abdullah Al-Refai, Labeeb Awan, Kevin Esquivel, Derian Esquivel, Tyler Smith\n\nVideo Game Sales Data Analysis Report\n\nThe Back Right corner: Luke Syverud, Isaac Kujak, Elizabeth Ruiz, Maxwell Creager-Roberts, Kaia Lui\n\nHow do Movies and Tv Shows differ by Country?\n\nThe Outliers: Spencer Christensen, Peter Kaull, Dean Lang, Joshua Hunter, Marcin Tutaj\n\nExploratory Data Analysis in Auto-Mpg Dataset\n\nBlock Blasters: Lucy McGovern, Emma Kimball, Riley Abrahamson, Brianna Velez, Napoleon Her\n\nWhat Makes a Song Danceable?\n\nIntermediate Wizards: Kyle Forsberg, Luke Bondi, Justin Hoffman, Sam Wolf, Ava Unertl\n\nMost Important Factors to a child’s exam success\n\nTeamName?: Jack Anderson, Nathan Rusch, Nirmay Kathuria, Wilson von Bohlen, Juan De Los Santos\n\nMarquette University Basketball Heatmap",
    "crumbs": [
      "Mini Project",
      "Topics and Works"
    ]
  },
  {
    "objectID": "present-work.html#group-projects-proposal",
    "href": "present-work.html#group-projects-proposal",
    "title": "Midterm Visualization Project",
    "section": "",
    "text": "The Whales: Brady Nelson, Brody Roessler, Christian Filardo, Dorien Vazquez, Filip Kisielewski\n\nHow do game sales correlate to console popularity by global region\n\nAnalytics Avengers (4): Sophia Bryant, Kumassi Browne, Charles Kendrick Jr, Isabel Bauer\n\nNetflix Analysis\n\nSyntax Squad: Nick Panoske, Kate Gibson, Annika Lautenbach, Simon Glarner, Sophia Ferru\n\nNo Project Title\n\nData Detectives: Jordan Dubeck, Justice Milhoan, Grace Placko, Jane Harvey, Madison Zursin\n\nHappiness of the World Over Time\n\nHala Madrid: Abdullah Al-Refai, Labeeb Awan, Kevin Esquivel, Derian Esquivel, Tyler Smith\n\nVideo Game Sales Data Analysis Report\n\nThe Back Right corner: Luke Syverud, Isaac Kujak, Elizabeth Ruiz, Maxwell Creager-Roberts, Kaia Lui\n\nHow do Movies and Tv Shows differ by Country?\n\nThe Outliers: Spencer Christensen, Peter Kaull, Dean Lang, Joshua Hunter, Marcin Tutaj\n\nExploratory Data Analysis in Auto-Mpg Dataset\n\nBlock Blasters: Lucy McGovern, Emma Kimball, Riley Abrahamson, Brianna Velez, Napoleon Her\n\nWhat Makes a Song Danceable?\n\nIntermediate Wizards: Kyle Forsberg, Luke Bondi, Justin Hoffman, Sam Wolf, Ava Unertl\n\nMost Important Factors to a child’s exam success\n\nTeamName?: Jack Anderson, Nathan Rusch, Nirmay Kathuria, Wilson von Bohlen, Juan De Los Santos\n\nMarquette University Basketball Heatmap",
    "crumbs": [
      "Mini Project",
      "Topics and Works"
    ]
  },
  {
    "objectID": "present-work.html#presentation-order",
    "href": "present-work.html#presentation-order",
    "title": "Midterm Visualization Project",
    "section": "Presentation order",
    "text": "Presentation order",
    "crumbs": [
      "Mini Project",
      "Topics and Works"
    ]
  },
  {
    "objectID": "LICENSE.html#creative-commons-attribution-sharealike-4.0-international-public-license",
    "href": "LICENSE.html#creative-commons-attribution-sharealike-4.0-international-public-license",
    "title": "Attribution-ShareAlike 4.0 International",
    "section": "Creative Commons Attribution-ShareAlike 4.0 International Public License",
    "text": "Creative Commons Attribution-ShareAlike 4.0 International Public License\nBy exercising the Licensed Rights (defined below), You accept and agree to be bound by the terms and conditions of this Creative Commons Attribution-ShareAlike 4.0 International Public License (“Public License”). To the extent this Public License may be interpreted as a contract, You are granted the Licensed Rights in consideration of Your acceptance of these terms and conditions, and the Licensor grants You such rights in consideration of benefits the Licensor receives from making the Licensed Material available under these terms and conditions.\n\nSection 1 – Definitions.\n\nAdapted Material means material subject to Copyright and Similar Rights that is derived from or based upon the Licensed Material and in which the Licensed Material is translated, altered, arranged, transformed, or otherwise modified in a manner requiring permission under the Copyright and Similar Rights held by the Licensor. For purposes of this Public License, where the Licensed Material is a musical work, performance, or sound recording, Adapted Material is always produced where the Licensed Material is synched in timed relation with a moving image.\nAdapter’s License means the license You apply to Your Copyright and Similar Rights in Your contributions to Adapted Material in accordance with the terms and conditions of this Public License.\nBY-SA Compatible License means a license listed at creativecommons.org/compatiblelicenses, approved by Creative Commons as essentially the equivalent of this Public License.\nCopyright and Similar Rights means copyright and/or similar rights closely related to copyright including, without limitation, performance, broadcast, sound recording, and Sui Generis Database Rights, without regard to how the rights are labeled or categorized. For purposes of this Public License, the rights specified in Section 2(b)(1)-(2) are not Copyright and Similar Rights.\nEffective Technological Measures means those measures that, in the absence of proper authority, may not be circumvented under laws fulfilling obligations under Article 11 of the WIPO Copyright Treaty adopted on December 20, 1996, and/or similar international agreements.\nExceptions and Limitations means fair use, fair dealing, and/or any other exception or limitation to Copyright and Similar Rights that applies to Your use of the Licensed Material.\nLicense Elements means the license attributes listed in the name of a Creative Commons Public License. The License Elements of this Public License are Attribution and ShareAlike.\nLicensed Material means the artistic or literary work, database, or other material to which the Licensor applied this Public License.\nLicensed Rights means the rights granted to You subject to the terms and conditions of this Public License, which are limited to all Copyright and Similar Rights that apply to Your use of the Licensed Material and that the Licensor has authority to license.\nLicensor means the individual(s) or entity(ies) granting rights under this Public License.\nShare means to provide material to the public by any means or process that requires permission under the Licensed Rights, such as reproduction, public display, public performance, distribution, dissemination, communication, or importation, and to make material available to the public including in ways that members of the public may access the material from a place and at a time individually chosen by them.\nSui Generis Database Rights means rights other than copyright resulting from Directive 96/9/EC of the European Parliament and of the Council of 11 March 1996 on the legal protection of databases, as amended and/or succeeded, as well as other essentially equivalent rights anywhere in the world.\nYou means the individual or entity exercising the Licensed Rights under this Public License. Your has a corresponding meaning.\n\n\n\nSection 2 – Scope.\n\nLicense grant.\n\nSubject to the terms and conditions of this Public License, the Licensor hereby grants You a worldwide, royalty-free, non-sublicensable, non-exclusive, irrevocable license to exercise the Licensed Rights in the Licensed Material to:\nA. reproduce and Share the Licensed Material, in whole or in part; and\nB. produce, reproduce, and Share Adapted Material.\nExceptions and Limitations. For the avoidance of doubt, where Exceptions and Limitations apply to Your use, this Public License does not apply, and You do not need to comply with its terms and conditions.\nTerm. The term of this Public License is specified in Section 6(a).\nMedia and formats; technical modifications allowed. The Licensor authorizes You to exercise the Licensed Rights in all media and formats whether now known or hereafter created, and to make technical modifications necessary to do so. The Licensor waives and/or agrees not to assert any right or authority to forbid You from making technical modifications necessary to exercise the Licensed Rights, including technical modifications necessary to circumvent Effective Technological Measures. For purposes of this Public License, simply making modifications authorized by this Section 2(a)(4) never produces Adapted Material.\nDownstream recipients.\nA. Offer from the Licensor – Licensed Material. Every recipient of the Licensed Material automatically receives an offer from the Licensor to exercise the Licensed Rights under the terms and conditions of this Public License.\nB. Additional offer from the Licensor – Adapted Material. Every recipient of Adapted Material from You automatically receives an offer from the Licensor to exercise the Licensed Rights in the Adapted Material under the conditions of the Adapter’s License You apply.\nC. No downstream restrictions. You may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, the Licensed Material if doing so restricts exercise of the Licensed Rights by any recipient of the Licensed Material.\nNo endorsement. Nothing in this Public License constitutes or may be construed as permission to assert or imply that You are, or that Your use of the Licensed Material is, connected with, or sponsored, endorsed, or granted official status by, the Licensor or others designated to receive attribution as provided in Section 3(a)(1)(A)(i).\n\nOther rights.\n\nMoral rights, such as the right of integrity, are not licensed under this Public License, nor are publicity, privacy, and/or other similar personality rights; however, to the extent possible, the Licensor waives and/or agrees not to assert any such rights held by the Licensor to the limited extent necessary to allow You to exercise the Licensed Rights, but not otherwise.\nPatent and trademark rights are not licensed under this Public License.\nTo the extent possible, the Licensor waives any right to collect royalties from You for the exercise of the Licensed Rights, whether directly or through a collecting society under any voluntary or waivable statutory or compulsory licensing scheme. In all other cases the Licensor expressly reserves any right to collect such royalties.\n\n\n\n\nSection 3 – License Conditions.\nYour exercise of the Licensed Rights is expressly made subject to the following conditions.\n\nAttribution.\n\nIf You Share the Licensed Material (including in modified form), You must:\nA. retain the following if it is supplied by the Licensor with the Licensed Material:\n\nidentification of the creator(s) of the Licensed Material and any others designated to receive attribution, in any reasonable manner requested by the Licensor (including by pseudonym if designated);\na copyright notice;\na notice that refers to this Public License;\na notice that refers to the disclaimer of warranties;\na URI or hyperlink to the Licensed Material to the extent reasonably practicable;\n\nB. indicate if You modified the Licensed Material and retain an indication of any previous modifications; and\nC. indicate the Licensed Material is licensed under this Public License, and include the text of, or the URI or hyperlink to, this Public License.\nYou may satisfy the conditions in Section 3(a)(1) in any reasonable manner based on the medium, means, and context in which You Share the Licensed Material. For example, it may be reasonable to satisfy the conditions by providing a URI or hyperlink to a resource that includes the required information.\nIf requested by the Licensor, You must remove any of the information required by Section 3(a)(1)(A) to the extent reasonably practicable.\n\nShareAlike.\n\nIn addition to the conditions in Section 3(a), if You Share Adapted Material You produce, the following conditions also apply.\n\nThe Adapter’s License You apply must be a Creative Commons license with the same License Elements, this version or later, or a BY-SA Compatible License.\nYou must include the text of, or the URI or hyperlink to, the Adapter’s License You apply. You may satisfy this condition in any reasonable manner based on the medium, means, and context in which You Share Adapted Material.\nYou may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, Adapted Material that restrict exercise of the rights granted under the Adapter’s License You apply.\n\n\n\nSection 4 – Sui Generis Database Rights.\nWhere the Licensed Rights include Sui Generis Database Rights that apply to Your use of the Licensed Material:\n\nfor the avoidance of doubt, Section 2(a)(1) grants You the right to extract, reuse, reproduce, and Share all or a substantial portion of the contents of the database;\nif You include all or a substantial portion of the database contents in a database in which You have Sui Generis Database Rights, then the database in which You have Sui Generis Database Rights (but not its individual contents) is Adapted Material, including for purposes of Section 3(b); and\nYou must comply with the conditions in Section 3(a) if You Share all or a substantial portion of the contents of the database.\n\nFor the avoidance of doubt, this Section 4 supplements and does not replace Your obligations under this Public License where the Licensed Rights include other Copyright and Similar Rights.\n\n\nSection 5 – Disclaimer of Warranties and Limitation of Liability.\n\nUnless otherwise separately undertaken by the Licensor, to the extent possible, the Licensor offers the Licensed Material as-is and as-available, and makes no representations or warranties of any kind concerning the Licensed Material, whether express, implied, statutory, or other. This includes, without limitation, warranties of title, merchantability, fitness for a particular purpose, non-infringement, absence of latent or other defects, accuracy, or the presence or absence of errors, whether or not known or discoverable. Where disclaimers of warranties are not allowed in full or in part, this disclaimer may not apply to You.\nTo the extent possible, in no event will the Licensor be liable to You on any legal theory (including, without limitation, negligence) or otherwise for any direct, special, indirect, incidental, consequential, punitive, exemplary, or other losses, costs, expenses, or damages arising out of this Public License or use of the Licensed Material, even if the Licensor has been advised of the possibility of such losses, costs, expenses, or damages. Where a limitation of liability is not allowed in full or in part, this limitation may not apply to You.\nThe disclaimer of warranties and limitation of liability provided above shall be interpreted in a manner that, to the extent possible, most closely approximates an absolute disclaimer and waiver of all liability.\n\n\n\nSection 6 – Term and Termination.\n\nThis Public License applies for the term of the Copyright and Similar Rights licensed here. However, if You fail to comply with this Public License, then Your rights under this Public License terminate automatically.\nWhere Your right to use the Licensed Material has terminated under Section 6(a), it reinstates:\n\nautomatically as of the date the violation is cured, provided it is cured within 30 days of Your discovery of the violation; or\nupon express reinstatement by the Licensor.\n\nFor the avoidance of doubt, this Section 6(b) does not affect any right the Licensor may have to seek remedies for Your violations of this Public License.\nFor the avoidance of doubt, the Licensor may also offer the Licensed Material under separate terms or conditions or stop distributing the Licensed Material at any time; however, doing so will not terminate this Public License.\nSections 1, 5, 6, 7, and 8 survive termination of this Public License.\n\n\n\nSection 7 – Other Terms and Conditions.\n\nThe Licensor shall not be bound by any additional or different terms or conditions communicated by You unless expressly agreed.\nAny arrangements, understandings, or agreements regarding the Licensed Material not stated herein are separate from and independent of the terms and conditions of this Public License.\n\n\n\nSection 8 – Interpretation.\n\nFor the avoidance of doubt, this Public License does not, and shall not be interpreted to, reduce, limit, restrict, or impose conditions on any use of the Licensed Material that could lawfully be made without permission under this Public License.\nTo the extent possible, if any provision of this Public License is deemed unenforceable, it shall be automatically reformed to the minimum extent necessary to make it enforceable. If the provision cannot be reformed, it shall be severed from this Public License without affecting the enforceability of the remaining terms and conditions.\nNo term or condition of this Public License will be waived and no failure to comply consented to unless expressly agreed to by the Licensor.\nNothing in this Public License constitutes or may be interpreted as a limitation upon, or waiver of, any privileges and immunities that apply to the Licensor or You, including from the legal processes of any jurisdiction or authority.\n\n\nCreative Commons is not a party to its public licenses. Notwithstanding, Creative Commons may elect to apply one of its public licenses to material it publishes and in those instances will be considered the “Licensor.” The text of the Creative Commons public licenses is dedicated to the public domain under the CC0 Public Domain Dedication. Except for the limited purpose of indicating that material is shared under a Creative Commons public license or as otherwise permitted by the Creative Commons policies published at creativecommons.org/policies, Creative Commons does not authorize the use of the trademark “Creative Commons” or any other trademark or logo of Creative Commons without its prior written consent including, without limitation, in connection with any unauthorized modifications to any of its public licenses or any other arrangements, understandings, or agreements concerning use of licensed material. For the avoidance of doubt, this paragraph does not form part of the public licenses.\nCreative Commons may be contacted at creativecommons.org."
  },
  {
    "objectID": "present-description.html",
    "href": "present-description.html",
    "title": "MATH/COSC 3570 Mini Project Presentation",
    "section": "",
    "text": "This is the latest version of project guideline. It may be revised later.\nThe midterm mini project is about data visualization. Show your fun project! Let’s go!! 😎",
    "crumbs": [
      "Mini Project",
      "Guideline and Policy"
    ]
  },
  {
    "objectID": "present-description.html#team-up",
    "href": "present-description.html#team-up",
    "title": "MATH/COSC 3570 Mini Project Presentation",
    "section": "Team up!",
    "text": "Team up!\n\nYou lose 3 points of your project grade if you don’t meet the requirement or miss the deadline.\nYou will be randomly assigned to a group if you do not belong to any group before the deadline.",
    "crumbs": [
      "Mini Project",
      "Guideline and Policy"
    ]
  },
  {
    "objectID": "present-description.html#proposal",
    "href": "present-description.html#proposal",
    "title": "MATH/COSC 3570 Mini Project Presentation",
    "section": "Proposal",
    "text": "Proposal\n\nEach one of you loses 3 points of your project grade if you don’t meet the requirement or miss the deadline.\nYour proposal (in PDF) should include three parts:\n\nProject title\nMembers duty. For example,\n\nJohn and Ben: clean data; Mike and Emma: prepare slides; Sophia, Mike, and Ben: plotting, etc.\n\nThe description of the data set you use in your project. For example, what is the data set about, how large is the data, the variables you use for your project, etc. The data set should be one of the data listed in Section 3.1.\nThe goal of your project. For example, what are questions you’d like to answer via data visualization? What would you like to learn about and from the data? What variables are you interested?\n\nAlthough it is risky, you can change your project topic after you submit your proposal if you decide to do something else.",
    "crumbs": [
      "Mini Project",
      "Guideline and Policy"
    ]
  },
  {
    "objectID": "present-description.html#materials",
    "href": "present-description.html#materials",
    "title": "MATH/COSC 3570 Mini Project Presentation",
    "section": "Materials",
    "text": "Materials\n\nEach one of you loses 3 points of your project grade if you don’t meet the requirement or miss the deadline.\nYou need to share your entire work, including slides, code, etc so that anyone is able to reproduce your outputs and plots shown in the slides.\nThe code must be shared via a Quarto file.",
    "crumbs": [
      "Mini Project",
      "Guideline and Policy"
    ]
  },
  {
    "objectID": "present-description.html#presentation",
    "href": "present-description.html#presentation",
    "title": "MATH/COSC 3570 Mini Project Presentation",
    "section": "Presentation",
    "text": "Presentation\n\nEach group presentation is about 5 and 6 minute long, followed by about 1 minute Q&A. If your presentation is too short or too long, every one of you loses 3 points of your project grade.",
    "crumbs": [
      "Mini Project",
      "Guideline and Policy"
    ]
  },
  {
    "objectID": "present-description.html#sec-data",
    "href": "present-description.html#sec-data",
    "title": "MATH/COSC 3570 Mini Project Presentation",
    "section": "Data",
    "text": "Data\nThe available data sets for this projects can be downloaded from kaggle, a data science competition platform sharing various data and projects. Please choose one data set for your project from the following:\n\nWorld Happiness Report\n\n\n\nSupermarket Sales Data\nNBA Players stats since 1950\nAirline Passenger Satisfaction\n\n\n\nAuto-mpg dataset\nNetflix Movies and TV Shows\nStudents Performance in Exams\nVideo Game Sales\nSpotify Tracks Dataset\nUS Census Demographic Data\n\n[Note:] Those are real data sets that contains many observations and variables. You just need to pick a few variables for plotting and analysis.\n[Note:] You may use some other data, but the data set cannot be the one used in the course (like ggplot2::mpg). The data set needs to be as sophisticated as the listed data sets above. Dr. Yu and TA will evaluate your data quality.",
    "crumbs": [
      "Mini Project",
      "Guideline and Policy"
    ]
  },
  {
    "objectID": "present-description.html#sec-grading",
    "href": "present-description.html#sec-grading",
    "title": "MATH/COSC 3570 Mini Project Presentation",
    "section": "Evaluation and Grading",
    "text": "Evaluation and Grading\n\nYour project performance is evaluated by Dr. Yu and the TA that is based on the following rubric:\n\n\nRubric\n\n\n\n\n\n\n\n\n\nCriteria\nExcellent\nGood\nFair\nEmerging\n\n\n\n\nData Understanding (15%)\nClearly explains the dataset, its source, and key variables. Provides meaningful insights.\nShows good understanding with clear explanations and some strong insights. A few minor details could be expanded.\nShows a basic grasp of the dataset but needs more clarity or depth in explaining its significance and insights.\nNeeds further understanding of the dataset. More details and insights would strengthen the analysis.\n\n\nVisualization Quality (30%)\nVisualizations are clear, well-chosen, and enhance understanding. Thoughtful design choices make the data engaging and accessible.\nStrong visuals that support the data well. Some minor refinements could improve clarity or impact.\nBasic visuals that convey information but could be more refined or better suited to the dataset.\nNeeds improvement in visualization selection or clarity. More attention to detail will enhance effectiveness.\n\n\nOutput Interpretation and Insights (25%)\nThoughtful and well-supported insights demonstrate strong analytical skills. Patterns and trends are clearly explained with compelling interpretations.\nProvides solid insights with good explanations. Some areas could benefit from deeper analysis.\nInsights are present but may lack depth or clear connections to the data. Some interpretations need more support.\nInsights need further development. Strengthening data interpretation will enhance overall understanding.\n\n\nSlides quality (15%)\nSlides are visually appealing, well-organized, and complement the spoken presentation. Effective use of text, images, and color enhances clarity.\nSlides are clear and well-structured but could be slightly improved in design or organization.\nSlides contain useful content but may be text-heavy, cluttered, or lack visual appeal.\nSlides need better organization and design to support the presentation effectively.\n\n\nPresentation Clarity and Interaction (15%)\nThe presentation is well-organized, engaging, and confident. The team communicates ideas effectively and transitions smoothly.\nA well-structured and clear presentation. Minor adjustments could improve flow or engagement.\nThe presentation is understandable but could be more organized or engaging. Some transitions may be unclear.\nMore practice and organization will help improve clarity and engagement.\n\n\n\n\nYour project grade will be\n\n\nProject grade = performance grade - points lost due to violation of policy\n\nwith adjustement based on your performance of duty.",
    "crumbs": [
      "Mini Project",
      "Guideline and Policy"
    ]
  },
  {
    "objectID": "present-description.html#peer-individual-performance-evaluation",
    "href": "present-description.html#peer-individual-performance-evaluation",
    "title": "MATH/COSC 3570 Mini Project Presentation",
    "section": "Peer Individual Performance Evaluation",
    "text": "Peer Individual Performance Evaluation\n\nIn each team, two group members will win the best contribution reward that add extra points to the project grade.\nEach one of you has two votes to nominate one or two of your teammates who you think contribute the most to your group project.\nYou can nominate\n\ntwo teammates, each receiving one vote.\none teammate who receives two votes.\n\nYou cannot nominate yourself.\nIf you don’t vote, or you just use one vote, you can’t be the best contributor even if you receive the most or 2nd highest votes. The member with the 2nd or 3rd highest votes wins the best contribution reward.\nIf there are more than two group members receive top two number of votes, Dr. Yu and the TA will decide the final top two nominees. For example, if John receives the most votes, and Emma and Amy both receive the 2nd highest votes, Dr. Yu and the TA choose either Emma or Amy for the reward.",
    "crumbs": [
      "Mini Project",
      "Guideline and Policy"
    ]
  },
  {
    "objectID": "weeks/week-6.html",
    "href": "weeks/week-6.html",
    "title": "Week 6",
    "section": "",
    "text": "Important",
    "crumbs": [
      "Weekly materials",
      "Week 6"
    ]
  },
  {
    "objectID": "weeks/week-6.html#participate",
    "href": "weeks/week-6.html#participate",
    "title": "Week 6",
    "section": "Participate",
    "text": "Participate\n🖥️ Slides - ggplot2\nr fontawesome::fa(\"table\") openintro::loans_full_schema",
    "crumbs": [
      "Weekly materials",
      "Week 6"
    ]
  },
  {
    "objectID": "weeks/week-6.html#reading-and-resources",
    "href": "weeks/week-6.html#reading-and-resources",
    "title": "Week 6",
    "section": "Reading and Resources",
    "text": "Reading and Resources\n📖 More add-on r emo::ji(\"package\"): ggplot2 extensions\n📖 The R Graph Gallery\n📖 R Graphics Cookbook\n📖 R CHARTS",
    "crumbs": [
      "Weekly materials",
      "Week 6"
    ]
  },
  {
    "objectID": "weeks/week-6.html#exercise",
    "href": "weeks/week-6.html#exercise",
    "title": "Week 6",
    "section": "Exercise",
    "text": "Exercise\n📋 Lab-11 ggplot2\nr fontawesome::fa(\"table\") penguins.csv\n\n\nBack to course schedule ⏎",
    "crumbs": [
      "Weekly materials",
      "Week 6"
    ]
  },
  {
    "objectID": "weeks/week-5.html",
    "href": "weeks/week-5.html",
    "title": "Week 5",
    "section": "",
    "text": "Important",
    "crumbs": [
      "Weekly materials",
      "Week 5"
    ]
  },
  {
    "objectID": "weeks/week-5.html#participate",
    "href": "weeks/week-5.html#participate",
    "title": "Week 5",
    "section": "Participate",
    "text": "Participate\n🖥️ Slides - R/Python for Data Science",
    "crumbs": [
      "Weekly materials",
      "Week 5"
    ]
  },
  {
    "objectID": "weeks/week-5.html#reading-and-resources",
    "href": "weeks/week-5.html#reading-and-resources",
    "title": "Week 5",
    "section": "Reading and Resources",
    "text": "Reading and Resources\n📖 tibbles\n📖 pipes\n📖 NumPy\n📖 pandas",
    "crumbs": [
      "Weekly materials",
      "Week 5"
    ]
  },
  {
    "objectID": "weeks/week-5.html#exercise",
    "href": "weeks/week-5.html#exercise",
    "title": "Week 5",
    "section": "Exercise",
    "text": "Exercise\n📋 Lab-08 tibbles and pipe\n📋 Lab-09 NumPy and pandas\n\n\nBack to course schedule ⏎",
    "crumbs": [
      "Weekly materials",
      "Week 5"
    ]
  },
  {
    "objectID": "weeks/week-1.html",
    "href": "weeks/week-1.html",
    "title": "Week 1",
    "section": "",
    "text": "📖 Read the syllabus\n📖 Get your laptop and computing environment ready!",
    "crumbs": [
      "Weekly materials",
      "Week 1"
    ]
  },
  {
    "objectID": "weeks/week-1.html#prepare",
    "href": "weeks/week-1.html#prepare",
    "title": "Week 1",
    "section": "",
    "text": "📖 Read the syllabus\n📖 Get your laptop and computing environment ready!",
    "crumbs": [
      "Weekly materials",
      "Week 1"
    ]
  },
  {
    "objectID": "weeks/week-1.html#reading-and-resources",
    "href": "weeks/week-1.html#reading-and-resources",
    "title": "Week 1",
    "section": "Reading and Resources",
    "text": "Reading and Resources\n📖 R for Data Science - Introduction\n📖 R for Data Science - Whole game\n📖 RStudio IDE Cheatsheet\n📖 Posit Cloud Documentation",
    "crumbs": [
      "Weekly materials",
      "Week 1"
    ]
  },
  {
    "objectID": "weeks/week-1.html#participate",
    "href": "weeks/week-1.html#participate",
    "title": "Week 1",
    "section": "Participate",
    "text": "Participate\n🖥️ Slides - Welcome to MATH/COSC 3570\n🖥️ Slides - Overview of Data Science\n🖥️ Slides - Posit Cloud\n🖥️ Slides - Git/GitHub\n\n\n\n\n\nggplot2::mpg",
    "crumbs": [
      "Weekly materials",
      "Week 1"
    ]
  },
  {
    "objectID": "weeks/week-1.html#perform",
    "href": "weeks/week-1.html#perform",
    "title": "Week 1",
    "section": "Perform",
    "text": "Perform\n📋 Lab-00 Posit Cloud\n📋 Lab-01 Running R Script\n\n\nBack to course schedule ⏎",
    "crumbs": [
      "Weekly materials",
      "Week 1"
    ]
  },
  {
    "objectID": "weeks/week-2.html",
    "href": "weeks/week-2.html",
    "title": "Week 2",
    "section": "",
    "text": "Important",
    "crumbs": [
      "Weekly materials",
      "Week 2"
    ]
  },
  {
    "objectID": "weeks/week-2.html#participate",
    "href": "weeks/week-2.html#participate",
    "title": "Week 2",
    "section": "Participate",
    "text": "Participate\n🖥️ Slides - Git/GitHub\n🖥️ Slides - Quarto",
    "crumbs": [
      "Weekly materials",
      "Week 2"
    ]
  },
  {
    "objectID": "weeks/week-2.html#perform",
    "href": "weeks/week-2.html#perform",
    "title": "Week 2",
    "section": "Perform",
    "text": "Perform\n📋 Lab-00 Git/GitHub\n📋 Lab-02 Quarto File\n📋 Lab-03 Markdown\n📋 Lab-04 Code Chunk",
    "crumbs": [
      "Weekly materials",
      "Week 2"
    ]
  },
  {
    "objectID": "weeks/week-2.html#reading-and-resources",
    "href": "weeks/week-2.html#reading-and-resources",
    "title": "Week 2",
    "section": "Reading and Resources",
    "text": "Reading and Resources\n\nGit/GitHub\n📖 Create a personal access token (PAT)\n📖 Two-factor authentication\n📖 Git hands-on session within RStudio\n📖 Happy Git and GitHub for the useR\n📖 Happier version control with Git and GitHub\n\n\nMarkdown\n📖 Markdown Tutorial\n📖 Mastering Markdown GitHub Guides\n📖 Markdown Guide\n\n\nQuarto\n📖 Quarto Website\n📖 Get Started with Quarto\n📖 R for Data Science - Quarto\n\n\nBack to course schedule ⏎",
    "crumbs": [
      "Weekly materials",
      "Week 2"
    ]
  },
  {
    "objectID": "weeks/week-11.html",
    "href": "weeks/week-11.html",
    "title": "Week 11",
    "section": "",
    "text": "Important",
    "crumbs": [
      "Weekly materials",
      "Week 11"
    ]
  },
  {
    "objectID": "weeks/week-11.html#participate",
    "href": "weeks/week-11.html#participate",
    "title": "Week 11",
    "section": "Participate",
    "text": "Participate\n🖥️ Slides - Probability and Statistics",
    "crumbs": [
      "Weekly materials",
      "Week 11"
    ]
  },
  {
    "objectID": "weeks/week-11.html#exercise",
    "href": "weeks/week-11.html#exercise",
    "title": "Week 11",
    "section": "Exercise",
    "text": "Exercise\n📋 Lab-19 Confidence Interval\n\n\nBack to course schedule ⏎",
    "crumbs": [
      "Weekly materials",
      "Week 11"
    ]
  },
  {
    "objectID": "weeks/week-12.html",
    "href": "weeks/week-12.html",
    "title": "Week 12",
    "section": "",
    "text": "Important",
    "crumbs": [
      "Weekly materials",
      "Week 12"
    ]
  },
  {
    "objectID": "weeks/week-12.html#participate",
    "href": "weeks/week-12.html#participate",
    "title": "Week 12",
    "section": "Participate",
    "text": "Participate\n🖥️ Slides - Linear Regression\nr fontawesome::fa(\"table\") ggplot2::mpg",
    "crumbs": [
      "Weekly materials",
      "Week 12"
    ]
  },
  {
    "objectID": "weeks/week-12.html#reading",
    "href": "weeks/week-12.html#reading",
    "title": "Week 12",
    "section": "Reading",
    "text": "Reading\n📖",
    "crumbs": [
      "Weekly materials",
      "Week 12"
    ]
  },
  {
    "objectID": "weeks/week-12.html#exercise",
    "href": "weeks/week-12.html#exercise",
    "title": "Week 12",
    "section": "Exercise",
    "text": "Exercise\n📋 Lab-20 Simple Linear Regression\n\n\nBack to course schedule ⏎",
    "crumbs": [
      "Weekly materials",
      "Week 12"
    ]
  },
  {
    "objectID": "weeks/week-9.html",
    "href": "weeks/week-9.html",
    "title": "Week 9",
    "section": "",
    "text": "Important\n\n\n\n\n\n\nHappy spring break! Remember to work on your project!\n\n\nBack to course schedule ⏎",
    "crumbs": [
      "Weekly materials",
      "Week 9"
    ]
  },
  {
    "objectID": "weeks/week-8.html",
    "href": "weeks/week-8.html",
    "title": "Week 8",
    "section": "",
    "text": "Important",
    "crumbs": [
      "Weekly materials",
      "Week 8"
    ]
  },
  {
    "objectID": "weeks/week-8.html#participate",
    "href": "weeks/week-8.html#participate",
    "title": "Week 8",
    "section": "Participate",
    "text": "Participate\n🖥️ Slides - Data Wrangling (one data frame)\n🖥️ Slides - Data Wrangling - two data frames\n Data - Pop_x and elec_vote_y\n\nlibrary(tidyverse)\nlibrary(dslabs)\npop_x &lt;- murders |&gt; \n    slice(1:6) |&gt;\n    select(state, population)\n\nelec_vote_y &lt;- results_us_election_2016 |&gt; \n    filter(state %in% c(\"Alabama\", \"Alaska\", \"Arizona\", \n                        \"California\", \"Connecticut\", \"Delaware\")) |&gt; \n    select(state, electoral_votes) |&gt; \n    rename(elec_vote = electoral_votes)\n\n Data - Customers",
    "crumbs": [
      "Weekly materials",
      "Week 8"
    ]
  },
  {
    "objectID": "weeks/week-8.html#reading-and-resources",
    "href": "weeks/week-8.html#reading-and-resources",
    "title": "Week 8",
    "section": "Reading and Resources",
    "text": "Reading and Resources\n📖 R for Data Science - Joins\n📖 R for Data Science - Data tidying",
    "crumbs": [
      "Weekly materials",
      "Week 8"
    ]
  },
  {
    "objectID": "weeks/week-8.html#exercise",
    "href": "weeks/week-8.html#exercise",
    "title": "Week 8",
    "section": "Exercise",
    "text": "Exercise\n📋 Lab-15 dplyr\n Data - Murders\n📋 Lab-16 Joining tables\n https://www.jaredlander.com/data/DiamondColors.csv\n ggplot2::diamonds\n\n\nBack to course schedule ⏎",
    "crumbs": [
      "Weekly materials",
      "Week 8"
    ]
  },
  {
    "objectID": "weeks/week-14.html",
    "href": "weeks/week-14.html",
    "title": "Week 14",
    "section": "",
    "text": "Important",
    "crumbs": [
      "Weekly materials",
      "Week 14"
    ]
  },
  {
    "objectID": "weeks/week-14.html#participate",
    "href": "weeks/week-14.html#participate",
    "title": "Week 14",
    "section": "Participate",
    "text": "Participate\n🖥️ Slides - K Nearest Neighbors\nr fontawesome::fa(\"table\") Data - body",
    "crumbs": [
      "Weekly materials",
      "Week 14"
    ]
  },
  {
    "objectID": "weeks/week-14.html#reading",
    "href": "weeks/week-14.html#reading",
    "title": "Week 14",
    "section": "Reading",
    "text": "Reading\n📖",
    "crumbs": [
      "Weekly materials",
      "Week 14"
    ]
  },
  {
    "objectID": "weeks/week-14.html#exercise",
    "href": "weeks/week-14.html#exercise",
    "title": "Week 14",
    "section": "Exercise",
    "text": "Exercise\n📋 Lab-22 K Nearest Neighbors\n\n\nBack to course schedule ⏎",
    "crumbs": [
      "Weekly materials",
      "Week 14"
    ]
  },
  {
    "objectID": "hw/hw2.html",
    "href": "hw/hw2.html",
    "title": "Homework 2: Data Visualization and Data Wrangling",
    "section": "",
    "text": "You use R and Python to do the following problems. You write R (Python) code for the problems starting with [R] ([Python]).\n\n\nImport the data set murders.\n\n[R] Use the pipe operator |&gt; and the dplyr functions mutate(), filter(), select(), and arrange() to get the following data output. Call the data set df.\nThe filtering conditions are\n\nregion in “Northeast” or “West”\nrate = total / population * 100000 is less than 1.\n\nThe new variable rank is based on rate. The highest rate is ranked 1st. [Hint:] Use the function rank().\n\n\n## code\n\n# # A tibble: 8 × 4\n#    rate  rank state         total\n#   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;         &lt;dbl&gt;\n# 1 0.320    51 Vermont           2\n# 2 0.380    50 New Hampshire     5\n# 3 0.887    43 Wyoming           5\n# 4 0.515    49 Hawaii            7\n# 5 0.828    44 Maine            11\n# 6 0.766    46 Idaho            12\n# 7 0.796    45 Utah             22\n# 8 0.940    42 Oregon           36\n\n\n[Python] Use Python methods query(), filter(), and sort_values() to do Problem 1.\n\n\nimport numpy as np\nimport pandas as pd\n\n\n\n## code\n\n\n[R] With df, use contains() to select column variables whose name contains the string “at”. Then order the data by rate decreasingly.\n\n\n## code\n\n\n[Python] With df, use argument like= in filter() to pick column variables whose name contains the string “at”. Then order the data by rate decreasingly.\n\n\n\n## code\n\n\n[R] Back to murders. Group the data by region, then use summarize() to compute the average, median, and standard deviation of population. Call the column names avg, med, and stdev.\n\n\n## code\n\n\n[Python] Back to murders. Group the data by region, then use agg() to compute the average, median, and standard deviation of population. Call the column names avg, med, and stdev.\n\n\n\n## code\n\n\n\n\nThe following baseball data are from the Lahman package.\nThe Batting data frame contains the offensive statistics for all players for many years:\n\n\nRows: 113,799\nColumns: 22\n$ playerID &lt;chr&gt; \"aardsda01\", \"aardsda01\", \"aardsda01\", \"aardsda01\", \"aardsda0…\n$ yearID   &lt;int&gt; 2004, 2006, 2007, 2008, 2009, 2010, 2012, 2013, 2015, 1954, 1…\n$ stint    &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ teamID   &lt;fct&gt; SFN, CHN, CHA, BOS, SEA, SEA, NYA, NYN, ATL, ML1, ML1, ML1, M…\n$ lgID     &lt;fct&gt; NL, NL, AL, AL, AL, AL, AL, NL, NL, NL, NL, NL, NL, NL, NL, N…\n$ G        &lt;int&gt; 11, 45, 25, 47, 73, 53, 1, 43, 33, 122, 153, 153, 151, 153, 1…\n$ AB       &lt;int&gt; 0, 2, 0, 1, 0, 0, 0, 0, 1, 468, 602, 609, 615, 601, 629, 590,…\n$ R        &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 58, 105, 106, 118, 109, 116, 102, …\n$ H        &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 131, 189, 200, 198, 196, 223, 172,…\n$ X2B      &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 27, 37, 34, 27, 34, 46, 20, 39, 28…\n$ X3B      &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 9, 14, 6, 4, 7, 11, 10, 6, 4, 2…\n$ HR       &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, 27, 26, 44, 30, 39, 40, 34, 45…\n$ RBI      &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 69, 106, 92, 132, 95, 123, 126, 12…\n$ SB       &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 3, 2, 1, 4, 8, 16, 21, 15, 31, …\n$ CS       &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 4, 1, 1, 0, 7, 9, 7, 5, 4, 4…\n$ BB       &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 28, 49, 37, 57, 59, 51, 60, 56, 66…\n$ SO       &lt;int&gt; 0, 0, 0, 1, 0, 0, 0, 0, 1, 39, 61, 54, 58, 49, 54, 63, 64, 73…\n$ IBB      &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, NA, 5, 6, 15, 16, 17, 13, 20, 14, …\n$ HBP      &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 2, 0, 1, 4, 2, 2, 3, 0, 0, 1…\n$ SH       &lt;int&gt; 0, 1, 0, 0, 0, 0, 0, 0, 0, 6, 7, 5, 0, 0, 0, 0, 1, 0, 0, 0, 0…\n$ SF       &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 7, 3, 3, 9, 12, 9, 6, 5, 2, …\n$ GIDP     &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, 20, 21, 13, 21, 19, 8, 16, 14,…\n\n\n\n[R] Use Batting data to obtain the top 10 player observations that hit the most home runs (in descending order) in 2023. Call the data set top10, make it as a tibble and print it out.\n\n\n## code\n\n\n[Python] Import the data Batting.csv. Use Batting data to obtain the top 10 player observations that hit the most home runs (in descending order) in 2023. Call the data set top10 and print it out.\n\n\n\n## code\n\nBut who are these players? In the top10 data, we see IDs, but names. The player names are in the People data set:\n\n\nRows: 21,010\nColumns: 26\n$ playerID     &lt;chr&gt; \"aardsda01\", \"aaronha01\", \"aaronto01\", \"aasedo01\", \"abada…\n$ birthYear    &lt;int&gt; 1981, 1934, 1939, 1954, 1972, 1985, 1850, 1877, 1869, 186…\n$ birthMonth   &lt;int&gt; 12, 2, 8, 9, 8, 12, 11, 4, 11, 10, 9, 3, 10, 2, 8, 9, 6, …\n$ birthDay     &lt;int&gt; 27, 5, 5, 8, 25, 17, 4, 15, 11, 14, 20, 16, 22, 16, 17, 1…\n$ birthCity    &lt;chr&gt; \"Denver\", \"Mobile\", \"Mobile\", \"Orange\", \"Palm Beach\", \"La…\n$ birthCountry &lt;chr&gt; \"USA\", \"USA\", \"USA\", \"USA\", \"USA\", \"D.R.\", \"USA\", \"USA\", …\n$ birthState   &lt;chr&gt; \"CO\", \"AL\", \"AL\", \"CA\", \"FL\", \"La Romana\", \"PA\", \"PA\", \"V…\n$ deathYear    &lt;int&gt; NA, 2021, 1984, NA, NA, NA, 1905, 1957, 1962, 1926, NA, 1…\n$ deathMonth   &lt;int&gt; NA, 1, 8, NA, NA, NA, 5, 1, 6, 4, NA, 2, 6, NA, NA, NA, N…\n$ deathDay     &lt;int&gt; NA, 22, 16, NA, NA, NA, 17, 6, 11, 27, NA, 13, 11, NA, NA…\n$ deathCountry &lt;chr&gt; NA, \"USA\", \"USA\", NA, NA, NA, \"USA\", \"USA\", \"USA\", \"USA\",…\n$ deathState   &lt;chr&gt; NA, \"GA\", \"GA\", NA, NA, NA, \"NJ\", \"FL\", \"VT\", \"CA\", NA, \"…\n$ deathCity    &lt;chr&gt; NA, \"Atlanta\", \"Atlanta\", NA, NA, NA, \"Pemberton\", \"Fort …\n$ nameFirst    &lt;chr&gt; \"David\", \"Hank\", \"Tommie\", \"Don\", \"Andy\", \"Fernando\", \"Jo…\n$ nameLast     &lt;chr&gt; \"Aardsma\", \"Aaron\", \"Aaron\", \"Aase\", \"Abad\", \"Abad\", \"Aba…\n$ nameGiven    &lt;chr&gt; \"David Allan\", \"Henry Louis\", \"Tommie Lee\", \"Donald Willi…\n$ weight       &lt;int&gt; 215, 180, 190, 190, 184, 235, 192, 170, 175, 169, 220, 19…\n$ height       &lt;int&gt; 75, 72, 75, 75, 73, 74, 72, 71, 71, 68, 74, 71, 70, 78, 7…\n$ bats         &lt;fct&gt; R, R, R, R, L, L, R, R, R, L, R, R, R, R, R, L, R, L, L, …\n$ throws       &lt;fct&gt; R, R, R, R, L, L, R, R, R, L, R, R, R, R, L, L, R, L, R, …\n$ debut        &lt;chr&gt; \"2004-04-06\", \"1954-04-13\", \"1962-04-10\", \"1977-07-26\", \"…\n$ bbrefID      &lt;chr&gt; \"aardsda01\", \"aaronha01\", \"aaronto01\", \"aasedo01\", \"abada…\n$ finalGame    &lt;chr&gt; \"2015-08-23\", \"1976-10-03\", \"1971-09-26\", \"1990-10-03\", \"…\n$ retroID      &lt;chr&gt; \"aardd001\", \"aaroh101\", \"aarot101\", \"aased001\", \"abada001…\n$ deathDate    &lt;date&gt; NA, 2021-01-22, 1984-08-16, NA, NA, NA, 1905-05-17, 1957…\n$ birthDate    &lt;date&gt; 1981-12-27, 1934-02-05, 1939-08-05, 1954-09-08, 1972-08-…\n\n\nWe can see column names nameFirst and nameLast.\n\n[R] Use left_join() to create a table of the top home run hitters. The data table should have variables playerID, nameFirst, nameLast, and HR. Overwrite the object top10 with this new table, and print it out.\n\n\n## code\n\n\n[Python] Import the data People.csv. Use merge() to create a table of the top home run hitters. The data table should have variables playerID, nameFirst, nameLast, and HR. Overwrite the object top10 with this new table, and print it out.\n\n\n\n## code\n\n\n[R] Use the Fielding data frame to add each player’s position to the data top10. You filter Fielding for the year 2023 first, then use right_join(). This time show nameFirst, nameLast, teamID, HR, and POS. Make sure the data are ordered by HR decreasingly.\n\n\n## code\n\n\n[Python] Import the data Fielding.csv. Use it to add each player’s position to the data top10. You query Fielding for the year 2023 first, then use merge(). This time show nameFirst, nameLast, teamID, HR, and POS. Make sure the data are ordered by HR decreasingly.\n\n\n\n## code\n\n\n\n\n\nco2_wide &lt;- data.frame(matrix(co2, ncol = 12, byrow = TRUE)) |&gt; \n    setNames(1:12) |&gt; \n    mutate(year = as.character(1959:1997))\n\n\n[R] Use the pivot_longer() function to make co2_wide tidy. The pivoted columns are 1 to 12. Call the column with the CO2 measurements co2 and call the month column month. Call the resulting object co2_tidy. Print it out.\n\n\n## code\n\n\n[Python] Import co2_wide.csv. Generate the data as co2_tidy.\n\n\n\n## code"
  },
  {
    "objectID": "hw/hw2.html#sec-murders",
    "href": "hw/hw2.html#sec-murders",
    "title": "Homework 2: Data Visualization and Data Wrangling",
    "section": "",
    "text": "Import the data set murders.\n\n[R] Use the pipe operator |&gt; and the dplyr functions mutate(), filter(), select(), and arrange() to get the following data output. Call the data set df.\nThe filtering conditions are\n\nregion in “Northeast” or “West”\nrate = total / population * 100000 is less than 1.\n\nThe new variable rank is based on rate. The highest rate is ranked 1st. [Hint:] Use the function rank().\n\n\n## code\n\n# # A tibble: 8 × 4\n#    rate  rank state         total\n#   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;         &lt;dbl&gt;\n# 1 0.320    51 Vermont           2\n# 2 0.380    50 New Hampshire     5\n# 3 0.887    43 Wyoming           5\n# 4 0.515    49 Hawaii            7\n# 5 0.828    44 Maine            11\n# 6 0.766    46 Idaho            12\n# 7 0.796    45 Utah             22\n# 8 0.940    42 Oregon           36\n\n\n[Python] Use Python methods query(), filter(), and sort_values() to do Problem 1.\n\n\nimport numpy as np\nimport pandas as pd\n\n\n\n## code\n\n\n[R] With df, use contains() to select column variables whose name contains the string “at”. Then order the data by rate decreasingly.\n\n\n## code\n\n\n[Python] With df, use argument like= in filter() to pick column variables whose name contains the string “at”. Then order the data by rate decreasingly.\n\n\n\n## code\n\n\n[R] Back to murders. Group the data by region, then use summarize() to compute the average, median, and standard deviation of population. Call the column names avg, med, and stdev.\n\n\n## code\n\n\n[Python] Back to murders. Group the data by region, then use agg() to compute the average, median, and standard deviation of population. Call the column names avg, med, and stdev.\n\n\n\n## code"
  },
  {
    "objectID": "hw/hw2.html#sec-baseball",
    "href": "hw/hw2.html#sec-baseball",
    "title": "Homework 2: Data Visualization and Data Wrangling",
    "section": "",
    "text": "The following baseball data are from the Lahman package.\nThe Batting data frame contains the offensive statistics for all players for many years:\n\n\nRows: 113,799\nColumns: 22\n$ playerID &lt;chr&gt; \"aardsda01\", \"aardsda01\", \"aardsda01\", \"aardsda01\", \"aardsda0…\n$ yearID   &lt;int&gt; 2004, 2006, 2007, 2008, 2009, 2010, 2012, 2013, 2015, 1954, 1…\n$ stint    &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ teamID   &lt;fct&gt; SFN, CHN, CHA, BOS, SEA, SEA, NYA, NYN, ATL, ML1, ML1, ML1, M…\n$ lgID     &lt;fct&gt; NL, NL, AL, AL, AL, AL, AL, NL, NL, NL, NL, NL, NL, NL, NL, N…\n$ G        &lt;int&gt; 11, 45, 25, 47, 73, 53, 1, 43, 33, 122, 153, 153, 151, 153, 1…\n$ AB       &lt;int&gt; 0, 2, 0, 1, 0, 0, 0, 0, 1, 468, 602, 609, 615, 601, 629, 590,…\n$ R        &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 58, 105, 106, 118, 109, 116, 102, …\n$ H        &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 131, 189, 200, 198, 196, 223, 172,…\n$ X2B      &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 27, 37, 34, 27, 34, 46, 20, 39, 28…\n$ X3B      &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 9, 14, 6, 4, 7, 11, 10, 6, 4, 2…\n$ HR       &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, 27, 26, 44, 30, 39, 40, 34, 45…\n$ RBI      &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 69, 106, 92, 132, 95, 123, 126, 12…\n$ SB       &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 3, 2, 1, 4, 8, 16, 21, 15, 31, …\n$ CS       &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 4, 1, 1, 0, 7, 9, 7, 5, 4, 4…\n$ BB       &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 28, 49, 37, 57, 59, 51, 60, 56, 66…\n$ SO       &lt;int&gt; 0, 0, 0, 1, 0, 0, 0, 0, 1, 39, 61, 54, 58, 49, 54, 63, 64, 73…\n$ IBB      &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, NA, 5, 6, 15, 16, 17, 13, 20, 14, …\n$ HBP      &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 2, 0, 1, 4, 2, 2, 3, 0, 0, 1…\n$ SH       &lt;int&gt; 0, 1, 0, 0, 0, 0, 0, 0, 0, 6, 7, 5, 0, 0, 0, 0, 1, 0, 0, 0, 0…\n$ SF       &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 7, 3, 3, 9, 12, 9, 6, 5, 2, …\n$ GIDP     &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, 20, 21, 13, 21, 19, 8, 16, 14,…\n\n\n\n[R] Use Batting data to obtain the top 10 player observations that hit the most home runs (in descending order) in 2023. Call the data set top10, make it as a tibble and print it out.\n\n\n## code\n\n\n[Python] Import the data Batting.csv. Use Batting data to obtain the top 10 player observations that hit the most home runs (in descending order) in 2023. Call the data set top10 and print it out.\n\n\n\n## code\n\nBut who are these players? In the top10 data, we see IDs, but names. The player names are in the People data set:\n\n\nRows: 21,010\nColumns: 26\n$ playerID     &lt;chr&gt; \"aardsda01\", \"aaronha01\", \"aaronto01\", \"aasedo01\", \"abada…\n$ birthYear    &lt;int&gt; 1981, 1934, 1939, 1954, 1972, 1985, 1850, 1877, 1869, 186…\n$ birthMonth   &lt;int&gt; 12, 2, 8, 9, 8, 12, 11, 4, 11, 10, 9, 3, 10, 2, 8, 9, 6, …\n$ birthDay     &lt;int&gt; 27, 5, 5, 8, 25, 17, 4, 15, 11, 14, 20, 16, 22, 16, 17, 1…\n$ birthCity    &lt;chr&gt; \"Denver\", \"Mobile\", \"Mobile\", \"Orange\", \"Palm Beach\", \"La…\n$ birthCountry &lt;chr&gt; \"USA\", \"USA\", \"USA\", \"USA\", \"USA\", \"D.R.\", \"USA\", \"USA\", …\n$ birthState   &lt;chr&gt; \"CO\", \"AL\", \"AL\", \"CA\", \"FL\", \"La Romana\", \"PA\", \"PA\", \"V…\n$ deathYear    &lt;int&gt; NA, 2021, 1984, NA, NA, NA, 1905, 1957, 1962, 1926, NA, 1…\n$ deathMonth   &lt;int&gt; NA, 1, 8, NA, NA, NA, 5, 1, 6, 4, NA, 2, 6, NA, NA, NA, N…\n$ deathDay     &lt;int&gt; NA, 22, 16, NA, NA, NA, 17, 6, 11, 27, NA, 13, 11, NA, NA…\n$ deathCountry &lt;chr&gt; NA, \"USA\", \"USA\", NA, NA, NA, \"USA\", \"USA\", \"USA\", \"USA\",…\n$ deathState   &lt;chr&gt; NA, \"GA\", \"GA\", NA, NA, NA, \"NJ\", \"FL\", \"VT\", \"CA\", NA, \"…\n$ deathCity    &lt;chr&gt; NA, \"Atlanta\", \"Atlanta\", NA, NA, NA, \"Pemberton\", \"Fort …\n$ nameFirst    &lt;chr&gt; \"David\", \"Hank\", \"Tommie\", \"Don\", \"Andy\", \"Fernando\", \"Jo…\n$ nameLast     &lt;chr&gt; \"Aardsma\", \"Aaron\", \"Aaron\", \"Aase\", \"Abad\", \"Abad\", \"Aba…\n$ nameGiven    &lt;chr&gt; \"David Allan\", \"Henry Louis\", \"Tommie Lee\", \"Donald Willi…\n$ weight       &lt;int&gt; 215, 180, 190, 190, 184, 235, 192, 170, 175, 169, 220, 19…\n$ height       &lt;int&gt; 75, 72, 75, 75, 73, 74, 72, 71, 71, 68, 74, 71, 70, 78, 7…\n$ bats         &lt;fct&gt; R, R, R, R, L, L, R, R, R, L, R, R, R, R, R, L, R, L, L, …\n$ throws       &lt;fct&gt; R, R, R, R, L, L, R, R, R, L, R, R, R, R, L, L, R, L, R, …\n$ debut        &lt;chr&gt; \"2004-04-06\", \"1954-04-13\", \"1962-04-10\", \"1977-07-26\", \"…\n$ bbrefID      &lt;chr&gt; \"aardsda01\", \"aaronha01\", \"aaronto01\", \"aasedo01\", \"abada…\n$ finalGame    &lt;chr&gt; \"2015-08-23\", \"1976-10-03\", \"1971-09-26\", \"1990-10-03\", \"…\n$ retroID      &lt;chr&gt; \"aardd001\", \"aaroh101\", \"aarot101\", \"aased001\", \"abada001…\n$ deathDate    &lt;date&gt; NA, 2021-01-22, 1984-08-16, NA, NA, NA, 1905-05-17, 1957…\n$ birthDate    &lt;date&gt; 1981-12-27, 1934-02-05, 1939-08-05, 1954-09-08, 1972-08-…\n\n\nWe can see column names nameFirst and nameLast.\n\n[R] Use left_join() to create a table of the top home run hitters. The data table should have variables playerID, nameFirst, nameLast, and HR. Overwrite the object top10 with this new table, and print it out.\n\n\n## code\n\n\n[Python] Import the data People.csv. Use merge() to create a table of the top home run hitters. The data table should have variables playerID, nameFirst, nameLast, and HR. Overwrite the object top10 with this new table, and print it out.\n\n\n\n## code\n\n\n[R] Use the Fielding data frame to add each player’s position to the data top10. You filter Fielding for the year 2023 first, then use right_join(). This time show nameFirst, nameLast, teamID, HR, and POS. Make sure the data are ordered by HR decreasingly.\n\n\n## code\n\n\n[Python] Import the data Fielding.csv. Use it to add each player’s position to the data top10. You query Fielding for the year 2023 first, then use merge(). This time show nameFirst, nameLast, teamID, HR, and POS. Make sure the data are ordered by HR decreasingly.\n\n\n\n## code"
  },
  {
    "objectID": "hw/hw2.html#pivoting",
    "href": "hw/hw2.html#pivoting",
    "title": "Homework 2: Data Visualization and Data Wrangling",
    "section": "",
    "text": "co2_wide &lt;- data.frame(matrix(co2, ncol = 12, byrow = TRUE)) |&gt; \n    setNames(1:12) |&gt; \n    mutate(year = as.character(1959:1997))\n\n\n[R] Use the pivot_longer() function to make co2_wide tidy. The pivoted columns are 1 to 12. Call the column with the CO2 measurements co2 and call the month column month. Call the resulting object co2_tidy. Print it out.\n\n\n## code\n\n\n[Python] Import co2_wide.csv. Generate the data as co2_tidy.\n\n\n\n## code"
  },
  {
    "objectID": "hw/hw2.html#murders",
    "href": "hw/hw2.html#murders",
    "title": "Homework 2: Data Visualization and Data Wrangling",
    "section": "2.1 murders",
    "text": "2.1 murders\nUse murders to make plots.\n\nCreate a scatter plot of total murders (x-axis) versus population sizes (y-axis) using the pipe operator |&gt; that the murders data set is on the left to |&gt;.\n\n\n## code\n\n\nGenerate the plot below using label and color aesthetics in aes() and a geometry layer geom_label(). Save the ggplot object as p. Here, we add abbreviation as the label, and make the labels’ color be determined by the state’s region.\n\n\n## code\n\n\n\n\n\n\n\n\n\n\n\nUse the object p and\n\n\nChange both axes to be in the \\(\\log_{10}\\) scale using scale_x_log10() and scale_y_log10()\nAdd a title “Gun murder data”\nUse the wall street journal theme in ggthemes.\n\n\n## code"
  },
  {
    "objectID": "hw/hw2.html#mpg",
    "href": "hw/hw2.html#mpg",
    "title": "Homework 2: Data Visualization and Data Wrangling",
    "section": "2.2 mpg",
    "text": "2.2 mpg\nUse mpg to make plots.\n\nWhat’s gone wrong with this code? Why are the points not blue? Change it so that the points are colored in blue.\n\n\nmpg |&gt; ggplot(mapping = aes(x = displ, y = hwy, colour = \"blue\")) +\n    geom_point()\n\n\n\n\n\n\n\n\n\nGenerate the bar chart below.\n\n\n## code\n\n\n\n\n\n\n\n\n\n\n\nComplete the code to generate the boxplot below. Note that x = class and y = hwy, so the coordinates need to be flipped.\n\n\n## code\n\n\n\n\n\n\n\n\n\n\n\nGenerate the histogram below with density scale. Map y to the internal variable ..density.. (after_stat(density)) to show density values. Put the legend inside the plot at c(0.9, 0.15). (check ?theme help page)\n\n\n## code\n\n\n\n\n\n\n\n\n\n\n\nGenerate the scatter plot below.\n\n\n## code"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MATH/COSC 3570 Introduction to Data Science (Spring 2025)",
    "section": "",
    "text": "Midterm project Proposal due Friday, 3/7, 11:59 PM.\nTA help desk hours at Cudahy Hall 301 Monday: 1 – 2 PM, Tuesday: 12 – 1 PM, Thursday: 12 – 2 PM\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeek\nDate\nTopic\nTo Do\nSlides\nLab Exercise\nHomework\nProject\n\n\n\n\n1\nTue, Jan 14\nGreetings + Overview of Data Science\n📖\n🖥️syllabus 🖥️overview\n\n\n\n\n\n\nThu, Jan 16\nPosit Cloud\n\n🖥️posit\n📋 posit 📋01\n\n\n\n\n2\nTue, Jan 21\nNo CLASS: Cold Weather\n📖\n\n\n\n\n\n\n\nThu, Jan 23\nGit/GitHub Introduction\n\n🖥️git\n📋github\n\n\n\n\n3\nTue, Jan 28\nQuarto: YAML and Markdown\n📖\n🖥️quarto\n📋02 📋03 📋04\n\n\n\n\n\nThu, Jan 30\nQuarto: Code Chunk\n\n\n\n\n\n\n\n4\nTue, Feb 4\nR Syntax\n📖\n🖥️syntax\n📋05\n\n\n\n\n\nThu, Feb 6\nPython Syntax\n\n\n📋06 📋 07(opt)\n✍️ HW1\n\n\n\n5\nTue, Feb 11\nR Tidyverse\n📖\n🖥️package\n📋08\n\n\n\n\n\nThu, Feb 13\nPython NumPy/Pandas\n\n\n📋09\n\n\n\n\n6\nTue, Feb 18\nData Importing\n📖\n🖥️import\n📋10\n\n\n\n\n\nThu, Feb 20\nData Visualization-ggplot2\n\n🖥️ggplot\n📋11 📋12\n\n\n\n\n7\nTue, Feb 25\nData Visualization-categorical and numerical data\n📖\n🖥️visualization\n📋13\n\n\n\n\n\nThu, Feb 27\nInteractive Data Visualization\n\n🖥️interactive-viz\n📋14 (opt)\nHW 1 Due\n✅ Team up Due\n\n\n8\nTue, Mar 4\nData Wrangling - one data frame\n📖\n🖥️dplyr-1\n📋15\n\n\n\n\n\nThu, Mar 6\nData Wrangling - two data frames\n\n🖥️ dplyr-2\n📋16\n\n✅ Proposal Due\n\n\n9\nTue, Mar 11\nNO CLASS: Spring break\n📖\n\n📋 Lab Solution\n\n\n\n\n\nThu, Mar 13\nNO CLASS: Spring break\n\n\n\n\n\n\n\n10\nTue, Mar 18\nData Wrangling - tidyr\n📖\n🖥️ tidyr\n📋17\n✍️ HW2\n✅ Materials Due\n\n\n\nThu, Mar 20\nMini Project Presentation\n\n\n\n\n\n\n\n11\nTue, Mar 25\nProbabilistic and Statistical Simulation\n📖\n🖥️\n📋\n\n\n\n\n\nThu, Mar 27\nProbabilistic and Statistical Simulation\n\n\n\n\n\n\n\n12\nTue, Apr 1\nLinear Regression\n📖\n🖥️\n\n\n\n\n\n\nThu, Apr 3\nLinear Regression\n\n\n📋\nHW 2 Due\n\n\n\n13\nTue, Apr 8\nLogistic Regression\n📖\n🖥️\n\n\n\n\n\n\nThu, Apr 10\nLogistic Regression\n\n\n📋\n✍️\n\n\n\n14\nTue, Apr 15\nK-Nearest Neighbors\n📖\n🖥️\n\n\n\n\n\n\nThu, Apr 17\nNO CLASS: Easter break\n\n\n📋\n\n\n\n\n15\nTue, Apr 22\nPrincipal Component Analysis\n📖\n🖥️\n\n\n\n\n\n\nThu, Apr 24\nPrincipal Component Analysis\n\n\n📋\n\n\n\n\n16\nTue, Apr 29\nK-Means Clustering\n📖\n🖥️\n\n\n\n\n\n\nThu, May 1\nFinal Project Presentation I\n\n🖥️\n📋\nHW 3 Due\n\n\n\n17\nMon, May 5\nFinal Project Presentation II\n\n\n\n\n\n\n\n\n\nThis schedule will be updated as the semester progresses, with all changes documented here. Dr. Yu reserve the right to make changes to the schedule.",
    "crumbs": [
      "Course information",
      "Schedule"
    ]
  },
  {
    "objectID": "slides/13-dplyr-2.html#joining-data-frames",
    "href": "slides/13-dplyr-2.html#joining-data-frames",
    "title": "Data Wrangling - two data frames 🛠",
    "section": "Joining data frames",
    "text": "Joining data frames\n\nHave multiple data frames\nWant to bring them together\n\nSQL-like functions\n\nleft_join(x, y)\nright_join(x, y)\nfull_join(x, y)\ninner_join(x, y)\nsemi_join(x, y)\nanti_join(x, y)\n\n\n\n\nOK, back to dplyr. Here the idea is that we have two or more data frames, and we want to bring them together as one single combined data set.\nHow? we are gonna use dplyr functions with name something_join(x, y).\nThese functions borrow the idea of SQL for relational database management. They are similar to the join functions of SQL.\nAnd so we can do something that SQL usually does in R, and it’s probably easier because we don’t need to use R and SQL back and forth, and integrate data manipulation and analysis together.\nIn particular, we are gonna go through the following 6 join functions.\nHere x and y are data frames. OK."
  },
  {
    "objectID": "slides/13-dplyr-2.html#setup",
    "href": "slides/13-dplyr-2.html#setup",
    "title": "Data Wrangling - two data frames 🛠",
    "section": "Setup",
    "text": "Setup\nData sets x and y share the same variable id.\n\n\n\nx &lt;- tibble(\n    id = c(\"01\", \"02\", \"03\"),\n    var_x = c(\"x1\", \"x2\", \"x3\")\n    )\n\n\nx\n\n# A tibble: 3 × 2\n  id    var_x\n  &lt;chr&gt; &lt;chr&gt;\n1 01    x1   \n2 02    x2   \n3 03    x3   \n\n\n\n\ny &lt;- tibble(\n    id = c(\"01\", \"02\", \"04\"),\n    var_y = c(\"y1\", \"y2\", \"y4\")\n    )\n\n\ny\n\n# A tibble: 3 × 2\n  id    var_y\n  &lt;chr&gt; &lt;chr&gt;\n1 01    y1   \n2 02    y2   \n3 04    y4   \n\n\n\n\n\nI am going to use these two data frames as an illustration of join functions.\ndata frame x has variable id and var_x\ndata frame y has variable again id and but another variable var_y.\nData frame x and y have the common variable id, so it’s quite reasonable to merge the two data sets together by the common variable id. But x has id 1, 2, 3 and y has id 1, 2, 4. And so there are many different ways to combine the two.\nYou can think id is marquette ID, and var_x stores GPA and var_y stores say students’ height. And we are gonna combine the two data sets into one student personal information data set."
  },
  {
    "objectID": "slides/13-dplyr-2.html#left_joinx-y-all-rows-from-x",
    "href": "slides/13-dplyr-2.html#left_joinx-y-all-rows-from-x",
    "title": "Data Wrangling - two data frames 🛠",
    "section": "\nleft_join(x, y): all rows from x",
    "text": "left_join(x, y): all rows from x\n\n\n\n\n\n\n\n\n\n\n\n\n## by = keys\nleft_join(x, y, by = \"id\")\n\n# A tibble: 3 × 3\n  id    var_x var_y\n  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n1 01    x1    y1   \n2 02    x2    y2   \n3 03    x3    &lt;NA&gt; \n\n\n\n\nNA is added to the id not appearing in y.\n\n\n\n\n\n\n\n\n\n\n\n\nOK first left_join. Look at this gif.\nThe idea is that left_join(x, y) keeps all the rows or observations from x, and keep all the variables in x and y, including id, var_x and var_y.\nThe variables used to connect two data tables are called keys, and we use by argument to tell dplyr which variable is the key\nBy default, the function uses all variables that appear in both tables as keys. So here, the default key is also “id” because “id” is the only variable that appears in both data sets.\nThe resulting data frame is shown here. The left join function basically keeps the entire data set x, and attaches the data set y to x with “id” in x.\nBecause y doesn’t have id 3, its value of var_y is a missing value NA.\nWe can use the venn diagram to visualize the idea of joining tables. And basically, the main data set is A or x. We keep everything of A, and we add stuff of B or y for observations that are in A or x only."
  },
  {
    "objectID": "slides/13-dplyr-2.html#left_join-example",
    "href": "slides/13-dplyr-2.html#left_join-example",
    "title": "Data Wrangling - two data frames 🛠",
    "section": "\nleft_join() Example",
    "text": "left_join() Example\n\n\nLeft join\nCode for generating the data sets\n\n\n\n\n\n\npop_x\n\n       state population\n1    Alabama    4779736\n2     Alaska     710231\n3    Arizona    6392017\n4   Arkansas    2915918\n5 California   37253956\n6   Colorado    5029196\n\n\n\nelec_vote_y\n\n        state elec_vote\n1  California        55\n2     Arizona        11\n3     Alabama         9\n4 Connecticut         7\n5      Alaska         3\n6    Delaware         3\n\n\n\n\npop_x |&gt; \n    left_join(elec_vote_y) #&lt;&lt;\n\n       state population elec_vote\n1    Alabama    4779736         9\n2     Alaska     710231         3\n3    Arizona    6392017        11\n4   Arkansas    2915918        NA\n5 California   37253956        55\n6   Colorado    5029196        NA\n\n\n\n\nConnecticut and Delaware in elec_vote_y will not be shown in the left-joined data because they are not in pop_x.\n\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(dslabs)\npop_x &lt;- murders |&gt; \n    slice(1:6) |&gt;\n    select(state, population)\n\nelec_vote_y &lt;- results_us_election_2016 |&gt; \n    filter(state %in% c(\"Alabama\", \"Alaska\", \"Arizona\", \n                        \"California\", \"Connecticut\", \"Delaware\")) |&gt; \n    select(state, electoral_votes) |&gt; \n    rename(elec_vote = electoral_votes)\n\n\n\n\n\nLet’s see an example. Here we have two data sets, pop_x and elec_vote_y.\nThe left_join() function uses the common variable “state” to combine the two data sets.\nAnd the result of left joining will be that we keep the entire data set pop_x, and attach the variable elec_vote to the data.\nIf there is no such state or observation in y, its corresponding value of elec_vote is NA."
  },
  {
    "objectID": "slides/13-dplyr-2.html#right_joinx-y-all-rows-from-y",
    "href": "slides/13-dplyr-2.html#right_joinx-y-all-rows-from-y",
    "title": "Data Wrangling - two data frames 🛠",
    "section": "\nright_join(x, y): all rows from y",
    "text": "right_join(x, y): all rows from y\n\n\n\n\n\n\n\n\n\n\n\n\nright_join(x, y)\n\nJoining with `by = join_by(id)`\n\n\n# A tibble: 3 × 3\n  id    var_x var_y\n  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n1 01    x1    y1   \n2 02    x2    y2   \n3 04    &lt;NA&gt;  y4   \n\n\n\n\nNA is in the column coming from x.\n\n\n\n\n\n\n\n\n\n\n\n\nOK. If you get the idea of left_join, you =should be able to guess what right_join() function is doing.\nBasically right_join(x, y) keeps all the rows or observations from y, and second data set, and again keep all the variablesin both x and y, including id, var_x and var_y.\nFor any observation that is not in x, its corresponding value of var_x becomes a missing value NA.\nSo here because x does not have id 4, its value of var_x is NA.\nIn the venn diagram, the main data set is B or y. We keep everything of B, and we add stuff of A or x for observations that are in B or y only."
  },
  {
    "objectID": "slides/13-dplyr-2.html#right_join-example",
    "href": "slides/13-dplyr-2.html#right_join-example",
    "title": "Data Wrangling - two data frames 🛠",
    "section": "\nright_join() Example",
    "text": "right_join() Example\n\n\n\npop_x\n\n       state population\n1    Alabama    4779736\n2     Alaska     710231\n3    Arizona    6392017\n4   Arkansas    2915918\n5 California   37253956\n6   Colorado    5029196\n\n\n\nelec_vote_y\n\n        state elec_vote\n1  California        55\n2     Arizona        11\n3     Alabama         9\n4 Connecticut         7\n5      Alaska         3\n6    Delaware         3\n\n\n\n\npop_x |&gt; \n    right_join(elec_vote_y) #&lt;&lt;\n\n        state population elec_vote\n1     Alabama    4779736         9\n2      Alaska     710231         3\n3     Arizona    6392017        11\n4  California   37253956        55\n5 Connecticut         NA         7\n6    Delaware         NA         3\n\n\n\n\nArkansas and Colorado in pop_x will not be shown in the right-joined data because they are not in elec_vote_y.\n\n\n\n\nBack to the example, if we are doing right-join, we keep the entire data set elec_vote_y, and attach the variable population of pop_x to the data.\nIf there is no such state or observation in x, its corresponding value of population is NA.\nSince x does not have Connecticut and Delaware, their population is NA.\n\nArkansas and Colorado in pop_x will not be shown in the right-joined data because they are not in elec_vote_y."
  },
  {
    "objectID": "slides/13-dplyr-2.html#full_joinx-y-all-rows-from-both-x-and-y",
    "href": "slides/13-dplyr-2.html#full_joinx-y-all-rows-from-both-x-and-y",
    "title": "Data Wrangling - two data frames 🛠",
    "section": "\nfull_join(x, y): all rows from both x and y",
    "text": "full_join(x, y): all rows from both x and y\n\n\n\n\n\n\n\n\n\n\n\n\nfull_join(x, y)\n\nJoining with `by = join_by(id)`\n\n\n# A tibble: 4 × 3\n  id    var_x var_y\n  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n1 01    x1    y1   \n2 02    x2    y2   \n3 03    x3    &lt;NA&gt; \n4 04    &lt;NA&gt;  y4   \n\n\n\nKeep all the rows and fill the missing parts with NAs.\n\n\n\n\n\n\n\n\n\n\n\n\nThe next is full_join(). full_join() preserves all the rows or observations either in x or in y or in both x and y.\nIn x, we have 1, 2, 3, and in y, we have 1, 2, 4. So the resulting full-joined data frame will have observations 1, 2, 3, 4, and fill the missing parts with NAs.\nx does not have id 4, so its var_x is NA. y does not have id 3, so its var_y is NA"
  },
  {
    "objectID": "slides/13-dplyr-2.html#full_join-example",
    "href": "slides/13-dplyr-2.html#full_join-example",
    "title": "Data Wrangling - two data frames 🛠",
    "section": "\nfull_join() Example",
    "text": "full_join() Example\n\n\n\npop_x\n\n       state population\n1    Alabama    4779736\n2     Alaska     710231\n3    Arizona    6392017\n4   Arkansas    2915918\n5 California   37253956\n6   Colorado    5029196\n\nelec_vote_y\n\n        state elec_vote\n1  California        55\n2     Arizona        11\n3     Alabama         9\n4 Connecticut         7\n5      Alaska         3\n6    Delaware         3\n\n\n\n\npop_x |&gt; \n    full_join(elec_vote_y) #&lt;&lt;\n\n        state population elec_vote\n1     Alabama    4779736         9\n2      Alaska     710231         3\n3     Arizona    6392017        11\n4    Arkansas    2915918        NA\n5  California   37253956        55\n6    Colorado    5029196        NA\n7 Connecticut         NA         7\n8    Delaware         NA         3\n\n\n\n\nfull_join() takes the union of observations of x and y, so it produces the data set with the most rows.\n\n\n\n\nIn this example, the full-joined data set will contain observations either in x or in y or in both x and y.\nBecause Arkansas and Colorado are not in elec_vote_y, their elec_vote value is NA\nBecause Connecticut and Delaware are not in pop_x, their population value is NA\nfull_join() takes the union of x and y, so it produces the data set with the most rows."
  },
  {
    "objectID": "slides/13-dplyr-2.html#inner_joinx-y-only-rows-w-keys-in-both-x-and-y",
    "href": "slides/13-dplyr-2.html#inner_joinx-y-only-rows-w-keys-in-both-x-and-y",
    "title": "Data Wrangling - two data frames 🛠",
    "section": "\ninner_join(x, y): only rows w/ keys in both x and y",
    "text": "inner_join(x, y): only rows w/ keys in both x and y\n\n\n\n\n\n\n\n\n\n\n\n\ninner_join(x, y)\n\nJoining with `by = join_by(id)`\n\n\n# A tibble: 2 × 3\n  id    var_x var_y\n  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n1 01    x1    y1   \n2 02    x2    y2   \n\n\n\nKeep only the rows that have information in both tables.\n\n\n\n\n\n\n\n\n\n\n\n\nOK inner_join(). inner_join() preserves only rows with keys or id here in both x and y.\nAnd we know id 1 and id 2 are in both x and y, so these two observations are preserved.\nid 3 is in x, but not in y, id 4 is in y, but not in x, so both are not included in the data.\nBecause we are taking intersection of the rows of x and y, we will get the fewest rows when inner_join() is used."
  },
  {
    "objectID": "slides/13-dplyr-2.html#inner_join-example",
    "href": "slides/13-dplyr-2.html#inner_join-example",
    "title": "Data Wrangling - two data frames 🛠",
    "section": "\ninner_join() Example",
    "text": "inner_join() Example\n\n\n\npop_x\n\n       state population\n1    Alabama    4779736\n2     Alaska     710231\n3    Arizona    6392017\n4   Arkansas    2915918\n5 California   37253956\n6   Colorado    5029196\n\n\n\nelec_vote_y\n\n        state elec_vote\n1  California        55\n2     Arizona        11\n3     Alabama         9\n4 Connecticut         7\n5      Alaska         3\n6    Delaware         3\n\n\n\n\npop_x |&gt; \n    inner_join(elec_vote_y) #&lt;&lt;\n\n       state population elec_vote\n1    Alabama    4779736         9\n2     Alaska     710231         3\n3    Arizona    6392017        11\n4 California   37253956        55\n\n\n\n\n\nIn this example, there are 4 states in both x and y, Alabama, Alaska, Arizona, and California.\nThe inner-joined data set only keep the 4 states data."
  },
  {
    "objectID": "slides/13-dplyr-2.html#section-2",
    "href": "slides/13-dplyr-2.html#section-2",
    "title": "Data Wrangling - two data frames 🛠",
    "section": "",
    "text": "16-Joining tables \n\nIn lab.qmd ## Lab 16 section\n\nImport the data at https://www.jaredlander.com/data/DiamondColors.csv. Call it diamond_color.\n\n\ndiamond_color &lt;- readr::read_csv(\"the url\")\n\n\nUse left_join() to combine the data set diamonds in ggplot2 and diamond_color by the key variable color.\n\n\nSelect the variables carat, color, Description, Details.\n\n\n## Variable \"color\" in diamonds but \"Color\" in diamond_color\n\njoined_df &lt;- diamonds |&gt;  \n    _______(_______, by = c('color' = 'Color')) |&gt;  ## join\n    _______(_________________________________________)  ## select\n\n\nCreate a bar chart of the variable color."
  },
  {
    "objectID": "slides/13-dplyr-2.html#section-3",
    "href": "slides/13-dplyr-2.html#section-3",
    "title": "Data Wrangling - two data frames 🛠",
    "section": "",
    "text": "# A tibble: 53,940 × 4\n  carat color Description    Details                  \n  &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;          &lt;chr&gt;                    \n1  0.23 E     Colorless      Minute traces of color   \n2  0.21 E     Colorless      Minute traces of color   \n3  0.23 E     Colorless      Minute traces of color   \n4  0.29 I     Near Colorless Slightly detectable color\n5  0.31 J     Near Colorless Slightly detectable color\n6  0.24 J     Near Colorless Slightly detectable color\n# ℹ 53,934 more rows"
  },
  {
    "objectID": "slides/13-dplyr-2.html#pd.merge",
    "href": "slides/13-dplyr-2.html#pd.merge",
    "title": "Data Wrangling - two data frames 🛠",
    "section": "pd.merge()",
    "text": "pd.merge()\n\n\nLeft join\nCode for generating the data sets\n\n\n\n\n\n\nimport numpy as np\nimport pandas as pd\n\n\npop_x\n\n        state  population\n0     Alabama     4779736\n1      Alaska      710231\n2     Arizona     6392017\n3    Arkansas     2915918\n4  California    37253956\n5    Colorado     5029196\n\nelec_vote_y\n\n          state  electoral_votes\n21      Alabama                9\n43       Alaska                3\n13      Arizona               11\n0    California               55\n26  Connecticut                7\n44     Delaware                3\n\n\n\n\n## dplyr::left_join()\npop_x.merge(right=elec_vote_y, how='left', on='state')\n\n        state  population  electoral_votes\n0     Alabama     4779736              9.0\n1      Alaska      710231              3.0\n2     Arizona     6392017             11.0\n3    Arkansas     2915918              NaN\n4  California    37253956             55.0\n5    Colorado     5029196              NaN\n\n\n\n\n\n\n\nmurders = pd.read_csv('./data/murders.csv')\npop_x = murders[0:6][['state','population']]\n\nelection = pd.read_csv('./data/results_us_election_2016.csv')\nraws1 = [\"Alabama\", \"Alaska\", \"Arizona\", \"California\", \"Connecticut\", \"Delaware\"]\ncols1 = [\"state\", \"electoral_votes\"]\ndf = election[cols1]\npop = []\nfor i in raws1:\n    mask = df[\"state\"] == i\n    pos = np.flatnonzero(mask)\n    pop.append(pos)\n\npop = np.array(pop)\npop = np.resize(pop, 6)\nelec_vote_y = df.iloc[pop]"
  },
  {
    "objectID": "slides/13-dplyr-2.html#section-5",
    "href": "slides/13-dplyr-2.html#section-5",
    "title": "Data Wrangling - two data frames 🛠",
    "section": "",
    "text": "## dplyr::right_join()\npop_x.merge(elec_vote_y, how = 'right')\n\n         state  population  electoral_votes\n0      Alabama   4779736.0                9\n1       Alaska    710231.0                3\n2      Arizona   6392017.0               11\n3   California  37253956.0               55\n4  Connecticut         NaN                7\n5     Delaware         NaN                3\n\n\n\n\n\n\n## dplyr::full_join()\npop_x.merge(elec_vote_y, how = 'outer')\n\n         state  population  electoral_votes\n0      Alabama   4779736.0              9.0\n1       Alaska    710231.0              3.0\n2      Arizona   6392017.0             11.0\n3     Arkansas   2915918.0              NaN\n4   California  37253956.0             55.0\n5     Colorado   5029196.0              NaN\n6  Connecticut         NaN              7.0\n7     Delaware         NaN              3.0\n\n\n\n\n\n\n\n## dplyr::inner_join()\npop_x.merge(elec_vote_y, how = 'inner')\n\n        state  population  electoral_votes\n0     Alabama     4779736                9\n1      Alaska      710231                3\n2     Arizona     6392017               11\n3  California    37253956               55\n\n\n\n\n\n\n\nmath3570-s25.github.io/website"
  },
  {
    "objectID": "slides/10-viz.html#categorical-vs.-numerical-variables",
    "href": "slides/10-viz.html#categorical-vs.-numerical-variables",
    "title": "Visualizing Data 📈",
    "section": "Categorical vs. Numerical Variables",
    "text": "Categorical vs. Numerical Variables\n\nA categorical (qualitative) variable provides non-numerical information which can be placed in one (and only one) category from two or more categories.\n\n\n\nGender (Male 👨, Female 👩, Other 🏳️‍🌈) \nClass (Freshman, Sophomore, Junior, Senior, Graduate) \nCountry (USA 🇺🇸, Canada 🇨🇦, UK 🇬🇧, Germany 🇩🇪, Japan 🇯🇵, Korea 🇰🇷) \n\n\n\n\nA numerical (quantitative) variable is recorded in a numerical value representing counts or measurements.\n\n\n\n GPA \n The number of relationships you’ve had \n Height"
  },
  {
    "objectID": "slides/10-viz.html#data-lending-club",
    "href": "slides/10-viz.html#data-lending-club",
    "title": "Visualizing Data 📈",
    "section": "Data: Lending Club",
    "text": "Data: Lending Club\n\nLending Club is a platform that allows individuals to lend to other individuals.\nNot all loans are created equal – ease of getting a loan depends on ability to pay back the loan.\nData includes loans made, these are not loan applications.\n\n\n\nOK. The data set we will be working with comes from the lending club.\nThousands of loans made through the Lending Club, which is a platform that allows individuals to lend to other individuals.\nIf you are finance or econ major, or you know about loans, you know that Not all loans are created equal – ease of getting a loan depends on (apparent) ability to pay back the loan.\nData include loans made, these are not loan applications.\nIt’s important to keep this in mind when we are looking at the relationships between the variables that we are going to see, since the pattern may be different for those relationships for loans that never got approved."
  },
  {
    "objectID": "slides/10-viz.html#take-a-peek-at-data",
    "href": "slides/10-viz.html#take-a-peek-at-data",
    "title": "Visualizing Data 📈",
    "section": "Take a Peek at Data",
    "text": "Take a Peek at Data\n\nlibrary(openintro) ## for loading the data set\ndplyr::glimpse(loans_full_schema)\n\nRows: 10,000\nColumns: 55\n$ emp_title                        &lt;chr&gt; \"global config engineer \", \"warehouse…\n$ emp_length                       &lt;dbl&gt; 3, 10, 3, 1, 10, NA, 10, 10, 10, 3, 1…\n$ state                            &lt;fct&gt; NJ, HI, WI, PA, CA, KY, MI, AZ, NV, I…\n$ homeownership                    &lt;fct&gt; MORTGAGE, RENT, RENT, RENT, RENT, OWN…\n$ annual_income                    &lt;dbl&gt; 90000, 40000, 40000, 30000, 35000, 34…\n$ verified_income                  &lt;fct&gt; Verified, Not Verified, Source Verifi…\n$ debt_to_income                   &lt;dbl&gt; 18.01, 5.04, 21.15, 10.16, 57.96, 6.4…\n$ annual_income_joint              &lt;dbl&gt; NA, NA, NA, NA, 57000, NA, 155000, NA…\n$ verification_income_joint        &lt;fct&gt; , , , , Verified, , Not Verified, , ,…\n$ debt_to_income_joint             &lt;dbl&gt; NA, NA, NA, NA, 37.7, NA, 13.1, NA, N…\n$ delinq_2y                        &lt;int&gt; 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0…\n$ months_since_last_delinq         &lt;int&gt; 38, NA, 28, NA, NA, 3, NA, 19, 18, NA…\n$ earliest_credit_line             &lt;dbl&gt; 2001, 1996, 2006, 2007, 2008, 1990, 2…\n$ inquiries_last_12m               &lt;int&gt; 6, 1, 4, 0, 7, 6, 1, 1, 3, 0, 4, 4, 8…\n$ total_credit_lines               &lt;int&gt; 28, 30, 31, 4, 22, 32, 12, 30, 35, 9,…\n$ open_credit_lines                &lt;int&gt; 10, 14, 10, 4, 16, 12, 10, 15, 21, 6,…\n$ total_credit_limit               &lt;int&gt; 70795, 28800, 24193, 25400, 69839, 42…\n$ total_credit_utilized            &lt;int&gt; 38767, 4321, 16000, 4997, 52722, 3898…\n$ num_collections_last_12m         &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ num_historical_failed_to_pay     &lt;int&gt; 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0…\n$ months_since_90d_late            &lt;int&gt; 38, NA, 28, NA, NA, 60, NA, 71, 18, N…\n$ current_accounts_delinq          &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ total_collection_amount_ever     &lt;int&gt; 1250, 0, 432, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ current_installment_accounts     &lt;int&gt; 2, 0, 1, 1, 1, 0, 2, 2, 6, 1, 2, 1, 2…\n$ accounts_opened_24m              &lt;int&gt; 5, 11, 13, 1, 6, 2, 1, 4, 10, 5, 6, 7…\n$ months_since_last_credit_inquiry &lt;int&gt; 5, 8, 7, 15, 4, 5, 9, 7, 4, 17, 3, 4,…\n$ num_satisfactory_accounts        &lt;int&gt; 10, 14, 10, 4, 16, 12, 10, 15, 21, 6,…\n$ num_accounts_120d_past_due       &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, NA, 0, 0, 0, 0, …\n$ num_accounts_30d_past_due        &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ num_active_debit_accounts        &lt;int&gt; 2, 3, 3, 2, 10, 1, 3, 5, 11, 3, 2, 2,…\n$ total_debit_limit                &lt;int&gt; 11100, 16500, 4300, 19400, 32700, 272…\n$ num_total_cc_accounts            &lt;int&gt; 14, 24, 14, 3, 20, 27, 8, 16, 19, 7, …\n$ num_open_cc_accounts             &lt;int&gt; 8, 14, 8, 3, 15, 12, 7, 12, 14, 5, 8,…\n$ num_cc_carrying_balance          &lt;int&gt; 6, 4, 6, 2, 13, 5, 6, 10, 14, 3, 5, 3…\n$ num_mort_accounts                &lt;int&gt; 1, 0, 0, 0, 0, 3, 2, 7, 2, 0, 2, 3, 3…\n$ account_never_delinq_percent     &lt;dbl&gt; 92.9, 100.0, 93.5, 100.0, 100.0, 78.1…\n$ tax_liens                        &lt;int&gt; 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ public_record_bankrupt           &lt;int&gt; 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0…\n$ loan_purpose                     &lt;fct&gt; moving, debt_consolidation, other, de…\n$ application_type                 &lt;fct&gt; individual, individual, individual, i…\n$ loan_amount                      &lt;int&gt; 28000, 5000, 2000, 21600, 23000, 5000…\n$ term                             &lt;dbl&gt; 60, 36, 36, 36, 36, 36, 60, 60, 36, 3…\n$ interest_rate                    &lt;dbl&gt; 14.07, 12.61, 17.09, 6.72, 14.07, 6.7…\n$ installment                      &lt;dbl&gt; 652.5, 167.5, 71.4, 664.2, 786.9, 153…\n$ grade                            &lt;ord&gt; C, C, D, A, C, A, C, B, C, A, C, B, C…\n$ sub_grade                        &lt;fct&gt; C3, C1, D1, A3, C3, A3, C2, B5, C2, A…\n$ issue_month                      &lt;fct&gt; Mar-2018, Feb-2018, Feb-2018, Jan-201…\n$ loan_status                      &lt;fct&gt; Current, Current, Current, Current, C…\n$ initial_listing_status           &lt;fct&gt; whole, whole, fractional, whole, whol…\n$ disbursement_method              &lt;fct&gt; Cash, Cash, Cash, Cash, Cash, Cash, C…\n$ balance                          &lt;dbl&gt; 27016, 4651, 1825, 18853, 21430, 4257…\n$ paid_total                       &lt;dbl&gt; 1999, 499, 282, 3313, 2325, 873, 2731…\n$ paid_principal                   &lt;dbl&gt; 984, 349, 175, 2747, 1570, 743, 1440,…\n$ paid_interest                    &lt;dbl&gt; 1015.2, 150.5, 106.4, 566.1, 754.8, 1…\n$ paid_late_fees                   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n\n\n\nThe data set is stored in the openintro package.\nIn addition to head, structure function, we can also use glimpse() function to see the general picture of the data.\nWe can see that we have 10000 rows, so there are 10000 observations, or loans made in the data set.\nAnd there are 55 columns.\nAnd the name of the data set is loans_full_schema."
  },
  {
    "objectID": "slides/10-viz.html#selected-variables",
    "href": "slides/10-viz.html#selected-variables",
    "title": "Visualizing Data 📈",
    "section": "Selected Variables",
    "text": "Selected Variables\n\nloans &lt;- loans_full_schema |&gt;\n    dplyr::select(loan_amount,\n                  interest_rate,\n                  grade,\n                  homeownership,\n                  debt_to_income)\nglimpse(loans)\n\nRows: 10,000\nColumns: 5\n$ loan_amount    &lt;int&gt; 28000, 5000, 2000, 21600, 23000, 5000, 24000, 20000, 20…\n$ interest_rate  &lt;dbl&gt; 14.07, 12.61, 17.09, 6.72, 14.07, 6.72, 13.59, 11.99, 1…\n$ grade          &lt;ord&gt; C, C, D, A, C, A, C, B, C, A, C, B, C, B, D, D, D, F, E…\n$ homeownership  &lt;fct&gt; MORTGAGE, RENT, RENT, RENT, RENT, OWN, MORTGAGE, MORTGA…\n$ debt_to_income &lt;dbl&gt; 18.01, 5.04, 21.15, 10.16, 57.96, 6.46, 23.66, 16.19, 3…\n\n\n\nThere are 55 variables in the data, but our visualization purpose, we are only going to focus on 8 of these columns.\nloan_amount, …, debt_to_income ratio\nI piped the data into the select function, which allows me to select variables I want by name, and called the selected data loans.\nSo the data has all 10000 observations and 8 selected variables."
  },
  {
    "objectID": "slides/10-viz.html#variable-description",
    "href": "slides/10-viz.html#variable-description",
    "title": "Visualizing Data 📈",
    "section": "Variable Description",
    "text": "Variable Description\n\n\n\n\n\n\n\nvariable\ndescription\n\n\n\nloan_amount\nAmount of the loan received, in US dollars\n\n\ninterest_rate\nInterest rate on the loan, in an annual percentage\n\n\ngrade\nLoan grade, which takes a values A through G and represents the quality of the loan\n\n\nhomeownership\nIndicates whether the person owns, owns but has a mortgage, or rents\n\n\ndebt_to_income\nDebt-to-income ratio"
  },
  {
    "objectID": "slides/10-viz.html#variable-types",
    "href": "slides/10-viz.html#variable-types",
    "title": "Visualizing Data 📈",
    "section": "Variable Types",
    "text": "Variable Types\n\n\n\nvariable\ntype\n\n\n\nloan_amount\nnumerical, continuous\n\n\ninterest_rate\nnumerical, continuous\n\n\ngrade\ncategorical, ordinal\n\n\nhomeownership\ncategorical, nominal\n\n\ndebt_to_income\nnumerical, continuous"
  },
  {
    "objectID": "slides/10-viz.html#bar-chart",
    "href": "slides/10-viz.html#bar-chart",
    "title": "Visualizing Data 📈",
    "section": "Bar Chart",
    "text": "Bar Chart\n\nA bar chart shows the frequency table of a categorical variable.\n\n\n## geom_bar(stat = \"count\")\nloans |&gt; ggplot(aes(x = homeownership)) +\n    geom_bar()  #&lt;&lt;\n\n\n\nOne way representing categorical data is using bar plot.\nHere we don’t use geom_point anymore. Instead, we use the geom_bar function.\nHere we would like to see the frequency distribution of variable homeownership, so I map x to the homeownership variable.\nWhen the geom_bar() is called. ggplot2 actually counts the number of each category for us. In other words, ggplots automatically creates the frequency table of homeownership for us, telling us how many observations belong to mortgage, how many belong to own and how many belong to rent.\nSo the question is, Where does count come from? How does ggplot2 do the calculation?\nNote that on the y-axis, it displays count, but count is NOT a variable in loans!\nWhere does count come from?"
  },
  {
    "objectID": "slides/10-viz.html#stacked-bar-chart",
    "href": "slides/10-viz.html#stacked-bar-chart",
    "title": "Visualizing Data 📈",
    "section": "Stacked Bar Chart",
    "text": "Stacked Bar Chart\n\n\n\n(tbl &lt;- table(loans$homeownership))\n\n\n              ANY MORTGAGE      OWN     RENT \n       0        0     4789     1353     3858 \n\n(freq_tbl &lt;- as.data.frame(tbl[3:5]))\n\n      Var1 Freq\n1 MORTGAGE 4789\n2      OWN 1353\n3     RENT 3858\n\n## column names\nnames(freq_tbl) &lt;- c(\"type\",\"count\")\nfreq_tbl\n\n      type count\n1 MORTGAGE  4789\n2      OWN  1353\n3     RENT  3858\n\n\n\n\n\n\n\n\nbar &lt;- freq_tbl |&gt;\n    ggplot(aes(x = \"\",\n               y = count,\n               fill = type)) +\n    geom_bar(stat = \"identity\")\nbar\n\n\n\n\n\n\n\n\n\n\n\nCheck the proportion or percentage of each category, we may want to create a stacked bar chart.\nTo create such plot, we need to prepare a frequency table.\nx = “” because we don’t map any variable in the frequency table data.\nfill = type because we are gonna fill the bar with colors by the type of homeownership.\nstat = “identity” because here we don’t need to calculate the counts of each category, “identity” means using the values provided in the data.\ngeom_bar() uses stat_count() by default: it counts the number of cases at each x position. geom_col() uses stat_identity(): it leaves the data as is.\n\nbar + theme_minimal() + labs(x = ““) ggplot(freq_tbl, aes(x =”“, y = count, color = type)) + geom_bar(stat =”identity”)"
  },
  {
    "objectID": "slides/10-viz.html#pie-chart",
    "href": "slides/10-viz.html#pie-chart",
    "title": "Visualizing Data 📈",
    "section": "Pie Chart",
    "text": "Pie Chart\n\n\n\npie &lt;- bar +\n    coord_polar(theta = \"y\")\npie\n\n\n\n\n\n\n\n\n\n\npie + theme_void()\n\n\n\n\n\n\n\n\n\n\ntheta = variable to map angle to (x or y) Offset of starting point from 12 o’clock in radians. pie + geom_text(aes(label = count), position = position_stack(vjust = 0.5))"
  },
  {
    "objectID": "slides/10-viz.html#segmented-bar-plot-stacked",
    "href": "slides/10-viz.html#segmented-bar-plot-stacked",
    "title": "Visualizing Data 📈",
    "section": "Segmented Bar Plot: Stacked",
    "text": "Segmented Bar Plot: Stacked\n\nloans |&gt; ggplot(aes(x = homeownership,\n                    fill = grade)) + #&lt;&lt;\n    geom_bar()\n\n\n\nWe can use Segmented Bar Plot, which is helpful when you want to represent two variables.\nSo here we fill these bars based on the grade of the loan, which we know ranges from A to G.\nSo each one of theses segments tells us how many of that grade of loan was observed within a particular homeownership."
  },
  {
    "objectID": "slides/10-viz.html#segmented-bar-plot-compare-proportions",
    "href": "slides/10-viz.html#segmented-bar-plot-compare-proportions",
    "title": "Visualizing Data 📈",
    "section": "Segmented Bar Plot: Compare Proportions",
    "text": "Segmented Bar Plot: Compare Proportions\n\n\nposition = \"fill\" makes each set of stacked bars the same height.\n\n\nloans |&gt; ggplot(aes(x = homeownership, fill = grade)) +\n    geom_bar(position = \"fill\") #&lt;&lt;\n\n\n\nWe may want to add another argument in the geom_bar layer, which is position = “fill”.\n\nposition = \"fill\" works like stacking, but makes each set of stacked bars the same height.\nAnd now the y-axis is not count anymore. Now the y limit is from 0 to 1, and each grade segment represents the relative frequency of a particular homeownership.\nWhich bar plot is a more useful representation for visualizing the relationship between homeownership and grade?"
  },
  {
    "objectID": "slides/10-viz.html#segmented-bar-plot-compare-individual-values",
    "href": "slides/10-viz.html#segmented-bar-plot-compare-individual-values",
    "title": "Visualizing Data 📈",
    "section": "Segmented Bar Plot: Compare Individual Values",
    "text": "Segmented Bar Plot: Compare Individual Values\n\n\nposition = \"dodge\" places overlapping objects directly beside one another.\n\n\nloans |&gt; ggplot(aes(x = homeownership, fill = grade)) +\n  geom_bar(position = \"dodge\") #&lt;&lt;\n\n\n\nIf you wanna compare Individual Values, here the individual category of the grade of loan in each ownership type, position = \"dodge\" may be a goo option.\nThe option places the grade of loans directly beside one another.\nThis way, it’s easier to see the counts of grade of loan within each ownership."
  },
  {
    "objectID": "slides/10-viz.html#customizing-bar-plots",
    "href": "slides/10-viz.html#customizing-bar-plots",
    "title": "Visualizing Data 📈",
    "section": "Customizing Bar Plots",
    "text": "Customizing Bar Plots\n\n\n\n\nloans |&gt;\n  ggplot(\n    aes(x = homeownership,\n        fill = homeownership)\n  ) +\n  geom_bar(\n    color = \"blue\",\n    width = 0.2,\n    alpha = 0.5\n  ) +\n  labs(\n    x = \"Homeownership\",\n    title = \"Homeownership Counts\"\n  ) +\n  geom_text(\n    aes(label = after_stat(count)),\n        stat = 'count',\n        hjust = 3,\n        color = \"red\",\n        size = 5\n  ) +\n  theme_minimal() +\n  coord_flip() ## y = homeownership\n\n\n\n\nggplot2::geom_bar()\nggplot2::geom_text()\n\n\n\n\n\n\n\n\n\n\n\n\n\nstat is short for statistical transformation.\n\nstat = 'count' uses the stat_count() method to get the count of each homeownership.\nOne reason why ggplot2 is powerful is you can customize your plot with great flexibility.\nWhen you use aesthetic option fill, each bar will be colored according to the variable we assign.\nBecause here x and fill map to the same variable, we have each bar has its own one color.\nWe can specify some settings in geom_bar. color is the color of the edge of the bar, and we can also control the width and transparency of bars.\nWe know labs already.\nIf you wanna add text other then labels to your plot, you can use geom_text() function.\nIf you wanna add the counts on each bar, you map label to the variable ..count..\nWhen you see the the variable or data has ..variable_name.., it means that it is an interval variable created by ggplot2.\nIn order to use this ..count.. internal variable, we have to set the stat transformation = “count.\nAnd we can adjust the text horizontally through [hjust], and we can also specify its color and size as we usually do.\nFinally I use theme_minimal() and I flip the coordinate so that the bars become horizontal. It is the same as y = homeownership"
  },
  {
    "objectID": "slides/10-viz.html#histogram",
    "href": "slides/10-viz.html#histogram",
    "title": "Visualizing Data 📈",
    "section": "Histogram",
    "text": "Histogram\n\nloans |&gt; ggplot(aes(x = loan_amount)) +\n    geom_histogram() #&lt;&lt;\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\nOne of the most commonly used ways of visualizing numerical data is with histograms.\nIn ggplot2, we use geom_histogram to create a histogram.\nWhen you use this function, ggplot2 send you a message saying that it uses 30 bins, or the number of classes created from the data, each representing one coloumn in the histogram.\nAnd you can pick better value with binwidth, or the class width."
  },
  {
    "objectID": "slides/10-viz.html#section-2",
    "href": "slides/10-viz.html#section-2",
    "title": "Visualizing Data 📈",
    "section": "",
    "text": "binwidth = 1000\nbinwidth = 5000\nbinwidth = 20000\n\n\n\n\nggplot(loans, aes(x = loan_amount)) +\n    geom_histogram(binwidth = 1000)\n\n\n\n\n\n\n\n\n\n\nggplot(loans, aes(x = loan_amount)) +\n    geom_histogram(binwidth = 5000)\n\n\n\n\n\n\n\n\n\n\nggplot(loans, aes(x = loan_amount)) +\n    geom_histogram(binwidth = 20000)\n\n\n\n\n\n\n\n\n\n\n\nIn this plot I use a binwidth of a thousand dollars, so each one of the bars represents a range of thousand dollars, and the heights of these bars tell me how many loans fall into that range.\nIn the second plot, the binwidth is 500 thousand dollars. So here we can have better sense of the shape of the distribution, comparing to the previous one.\nThe last plot use the binwidth 20000 dollars. And now we lose anything interesting about the shape of the distribution.\nSo picking a binwidth or the number of bins is an art and science. But try 10 to 20 bins may be a good start."
  },
  {
    "objectID": "slides/10-viz.html#customizing-histograms",
    "href": "slides/10-viz.html#customizing-histograms",
    "title": "Visualizing Data 📈",
    "section": "Customizing Histograms",
    "text": "Customizing Histograms\n\n\n\nloans |&gt;\n  ggplot(\n    aes(x = loan_amount)\n  ) +\n  geom_histogram(\n    binwidth = 5000,\n    fill = \"#003366\",\n    colour = \"#FFCC00\",\n    alpha = 0.8,\n    linetype = \"dashed\"\n  ) +\n  labs(\n    x = \"Loan amount ($)\",\n    y = \"Frequency\",\n    title = \"Lending Club loans\"\n  ) +\n  theme_light()\n\n\n\nggplot2::geom_histogram()\n\n\n\n\n\n\n\n\n\n\n\n\nWe can also customize histograms.\nWhat I did here is that I change the color of these bars with fill argument\nAnd the color argument is for the edge of the bars.\nlinetype tells ggplot that the linetype of the edge of the bars is dashed line.\nAnd again, we can add labels using labs function."
  },
  {
    "objectID": "slides/10-viz.html#fill-with-a-categorical-variable-stack",
    "href": "slides/10-viz.html#fill-with-a-categorical-variable-stack",
    "title": "Visualizing Data 📈",
    "section": "Fill with a Categorical Variable: Stack",
    "text": "Fill with a Categorical Variable: Stack\n\n\n\nloans |&gt;\n  ggplot(\n    aes(x = loan_amount,\n        fill = homeownership) #&lt;&lt;\n  ) +\n  geom_histogram(\n    binwidth = 5000\n  ) +\n  labs(\n    x = \"Loan amount ($)\",\n    y = \"Frequency\"\n  ) +\n  theme_linedraw()\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can also fill a histogram with a categorical variable, so it allows us to explore the relationship between the numerical and categorical variables.\nThis is done by adding aesthetic fill. Here basically filling the bars based on home ownership.\nSo we can actually see what’s happening behind each level"
  },
  {
    "objectID": "slides/10-viz.html#fill-with-a-categorical-variable-identity-bad",
    "href": "slides/10-viz.html#fill-with-a-categorical-variable-identity-bad",
    "title": "Visualizing Data 📈",
    "section": "Fill with a Categorical Variable: Identity (BAD)",
    "text": "Fill with a Categorical Variable: Identity (BAD)\n\n\n\nloans |&gt;\n  ggplot(\n    aes(x = loan_amount,\n        fill = homeownership)\n  ) +\n  geom_histogram(\n    binwidth = 5000,\n    position = \"identity\" #&lt;&lt;\n  ) +\n  labs(\n    x = \"Loan amount ($)\",\n    y = \"Frequency\",\n    title = \"Lending Club loans\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhy such plot is bad?\n\n\nSo here, if we don’t specify alpha, there is no transparency at all.\nAnd we can see that the histogram of loan amount for house owners is totally masked by the histogram for renters, because there are much more renters than house owners, and the frequency of each bin in the histogram for the renters is higher than the frequency for the owners.\nSo use visualization carefully. Sometimes the plot does not provide more information, and sometimes it is misleading."
  },
  {
    "objectID": "slides/10-viz.html#fill-with-a-categorical-variable-identity",
    "href": "slides/10-viz.html#fill-with-a-categorical-variable-identity",
    "title": "Visualizing Data 📈",
    "section": "Fill with a Categorical Variable: Identity",
    "text": "Fill with a Categorical Variable: Identity\n\n\n\nloans |&gt;\n  ggplot(\n    aes(x = loan_amount,\n        fill = homeownership)\n  ) +\n  geom_histogram(\n    binwidth = 5000,\n    alpha = 0.5,  #&lt;&lt;\n    position = \"identity\"\n  ) +\n  labs(\n    x = \"Loan amount ($)\",\n    y = \"Frequency\",\n    title = \"Lending Club loans\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can also compare the histograms of loan amount of different homeownership by simply superimposing on one to another.\nWe use position = “identity” to do that.\nIn this case, we basically put three histograms together in one plot, sharing the same x-axis and y-axis\nIf you wanna use this type of plot, remember to make it transparent, so that each histogram can be seen even they are superimposed."
  },
  {
    "objectID": "slides/10-viz.html#facet-with-a-categorical-variable",
    "href": "slides/10-viz.html#facet-with-a-categorical-variable",
    "title": "Visualizing Data 📈",
    "section": "Facet with a Categorical Variable",
    "text": "Facet with a Categorical Variable\n\n\n\nloans |&gt;\n  ggplot(\n    aes(x = loan_amount,\n        fill = homeownership)\n  ) +\n  geom_histogram(\n    binwidth = 5000\n  ) +\n  labs(\n    x = \"Loan amount ($)\",\n    y = \"Frequency\",\n    title = \"Lending Club loans\"\n  ) +\n  facet_wrap(\n    ~ homeownership, #&lt;&lt;\n    nrow = 3  #&lt;&lt;\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nIf you don’t want to put all three histograms in one single plot, remember you can use faceting trick.\nfirst again I fill in with colors based on homeownership\nThen instead of changing alpha level, and put them on top of each other, I can facet the plot.\nSince I am using a single categorical variable to facet, I am going to use facet_wrap() function by homeownership variable and I want the data to be represented in 3 rows, so that the three histograms share the same x-axis and are compared easily. - Basically, there are not many house owners in the data set. And basically all three distributions are right-skewed."
  },
  {
    "objectID": "slides/10-viz.html#section-3",
    "href": "slides/10-viz.html#section-3",
    "title": "Visualizing Data 📈",
    "section": "",
    "text": "13-Visualization \n\nIn lab.qmd ## Lab 13 section,\n\nImport the data penguins.csv.\nGenerate the following"
  },
  {
    "objectID": "slides/10-viz.html#section-4",
    "href": "slides/10-viz.html#section-4",
    "title": "Visualizing Data 📈",
    "section": "",
    "text": "# library(tidyverse)\npenguins &lt;- read_csv(__________________)\n________ |&gt; ggplot(_______________________) +  ## mapping layer\n    ___________________ +  ## geometry layer\n    _____________________________  ## label layer\n\n\n\n________ |&gt; ggplot(______________________________) +  ## mapping layer\n    _______________ +  ## geometry layer\n    _______________ +  ## label layer\n    ______________________________  +   ## facet layer\n    ______________________________      ## theme layer (set legend.position = \"none\")"
  },
  {
    "objectID": "slides/10-viz.html#density-plot",
    "href": "slides/10-viz.html#density-plot",
    "title": "Visualizing Data 📈",
    "section": "Density Plot",
    "text": "Density Plot\n\n\n\n\n\ngeom_density() uses kernel density estimation to smooth the histogram or our data. (MATH 4750 Statistical Computing)\n\n\nggplot(loans, aes(x = loan_amount)) +\n    geom_density()  #&lt;&lt;\n\n\n\nLet’s continue. Another way we can visualize numerical data is using a density plot.\nA density plot is basically a smoothed version of a histogram.\nRemember that a continuous random variable has a continuous probability distribution that is a density curve as a plot. Right?\nSo a normal r.v. has a normal density curve that this.\nBut given a data set of continuous variable, we can only draw a histogram that is sort of an approximation to its density curve. The histogram will only be very much like its true density plot when the data size is huge or approaching to infinity.\nA density plot here smooths the histogram, telling us that given the data set we have, what the true density curve might look like.\nIn ggplot, we have geometry geom_density() to create a density plot.\nAnd ggplot uses the so-called kernel density estimation to smooth the histogram. The kernel is not a the linux kernel in computer science. The kernel here is a probability distribution.\nIf you are interested, it will be taught in 4750 Computational Statistics which is a new course starting this fall.\nYou can see in the graph that the density curve smooths the histogram, but it;s still not very smooth, right. It’s a little bit jagged.\nThe ggplot choose a level of smoothness for us. And we can adjust the smoothness by ourselves."
  },
  {
    "objectID": "slides/10-viz.html#density-plots-and-adjusting-bandwidth",
    "href": "slides/10-viz.html#density-plots-and-adjusting-bandwidth",
    "title": "Visualizing Data 📈",
    "section": "Density Plots and Adjusting Bandwidth",
    "text": "Density Plots and Adjusting Bandwidth\n\n\nadjust = 0.5\nadjust = 1\nadjust = 2\n\n\n\n\nggplot(loans, aes(x = loan_amount)) +\n    geom_density(adjust = 0.5)\n\n\n\n\n\n\n\n\n\n\nggplot(loans, aes(x = loan_amount)) +\n    geom_density(adjust = 1) # default bandwidth\n\n\n\n\n\n\n\n\n\n\nggplot(loans, aes(x = loan_amount)) +\n    geom_density(adjust = 2)\n\n\n\n\n\n\n\n\n\n\n\nWe can adjust the smoothness of a density plot by the argument adjust in geom_density() function.\nbasically, the larger the value is, the smoother the curve will be.\nand the default is adjust = 1.\nKeep in mind that if you use a very smooth density plot, some local peaks or features may be washed out or smoothed away. If these local things contain some information, you may lose the information by just looking at the smooth density plot.\nSo a better idea is to try different level of smoothness, and check different plots, such as histogram, bar plots, and scatter plots as well."
  },
  {
    "objectID": "slides/10-viz.html#customizing-density-plots",
    "href": "slides/10-viz.html#customizing-density-plots",
    "title": "Visualizing Data 📈",
    "section": "Customizing Density Plots",
    "text": "Customizing Density Plots\n\n\n\nloans |&gt;\n  ggplot(\n    aes(x = loan_amount)\n  ) +\n  geom_density(\n    adjust = 2,\n    fill = \"#FFCC00\",\n    color = \"#003366\",\n    alpha = 0.5,\n    linetype = \"dashed\"\n  ) +\n  labs(\n    x = \"Loan amount ($)\",\n    y = \"Density\",\n    title = \"Lending Club loans\"\n  )\n\n\n\nggplot2::geom_density()\n\n\n\n\n\n\n\n\n\n\n\n\nWe can also customize density plots as others.\nIn addition to adjust, we can also use fill, color, alpha, line type as we have used in histogram."
  },
  {
    "objectID": "slides/10-viz.html#density-curve-on-a-histogram",
    "href": "slides/10-viz.html#density-curve-on-a-histogram",
    "title": "Visualizing Data 📈",
    "section": "Density Curve on a Histogram",
    "text": "Density Curve on a Histogram\n\n\n\nloans |&gt;\n  ggplot(\n    aes(x = loan_amount)\n  ) +\n  ## scale down to\n  ## match the density\n  geom_histogram(\n    binwidth = 5000,\n    aes(y = ..density..) #&lt;&lt;\n  ) +\n  geom_density(\n    alpha = 0.1,\n    fill = \"#FF6666\"\n  ) +\n  labs(\n    x = \"Loan amount ($)\",\n    y = \"Density\",\n    title = \"Lending Club loans\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nSometimes we like to put the density on top of the histogram to have a better understanding how smooth the density curve is, comparing to the histogram.\nWell it’s very easy to do that.\nWe just need to add the geom_density layer to the existent geom_histogram layer.\nAnd don’t forget to use density scale in geom_histogram so that the height of histogram and density plot can share the same y-axis each other."
  },
  {
    "objectID": "slides/10-viz.html#adding-a-categorical-variable-to-density-plots",
    "href": "slides/10-viz.html#adding-a-categorical-variable-to-density-plots",
    "title": "Visualizing Data 📈",
    "section": "Adding a Categorical Variable to Density Plots",
    "text": "Adding a Categorical Variable to Density Plots\n\n\n\nloans |&gt;\n  ggplot(\n    aes(x = loan_amount,\n        fill = homeownership)\n  ) +\n  geom_density(\n    adjust = 2,\n    alpha = 0.4\n  ) +\n  labs(\n    x = \"Loan amount ($)\",\n    y = \"Density\",\n    title = \"Amounts of loans\",\n    fill = \"Homeownership\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can also add a categorical variable to a density plot. This is similar to what we did with the histograms, where you can see them overlaid on top of each other.\nSo once again, we can fill in the density curves based on the value of homeownership.\nand I am changing alpha, so that we can actually see what’s happening behind the curve. If I didn’t change alpha, we are not able to see the peaks of mortagage and own because they are masked by the density curve of home renters. OK."
  },
  {
    "objectID": "slides/10-viz.html#box-plot-1",
    "href": "slides/10-viz.html#box-plot-1",
    "title": "Visualizing Data 📈",
    "section": "Box Plot",
    "text": "Box Plot\n\nloans |&gt; ggplot(aes(x = interest_rate)) +\n  geom_boxplot() +\n  labs(x = \"interest rate (%)\")\n\n\n\nRemember in base R, we can use boxplot function to create a boxplot.\nIn ggplot, we add the geometry layer, geom_boxplot().\nOne of things that boxplots are good at is uncovering our potential outliers, and here, the distribution of interest rates is right-skewed, and has several outliers.\nMost of the interest rates are between 10 to 15%, but some can be as high as 30% or more."
  },
  {
    "objectID": "slides/10-viz.html#customizing-box-plots",
    "href": "slides/10-viz.html#customizing-box-plots",
    "title": "Visualizing Data 📈",
    "section": "Customizing Box Plots",
    "text": "Customizing Box Plots\n\n\n\nloans |&gt;\n  ggplot(aes(x = interest_rate)) +\n  geom_boxplot(\n    # custom outliers\n    outlier.colour = \"red\",\n    outlier.shape = 8,\n    outlier.size = 3,\n    # Notch?\n    notch = TRUE,\n    notchwidth = 0.1,\n    # custom boxes\n    fill = \"#FFCC00\",\n    colour = \"#003366\",\n    alpha = 0.2\n  ) +\n  labs(\n    x = \"Interest rate (%)\",\n    title = \"Interest rates of loans\"\n  ) +\n  theme(\n    axis.ticks.y = element_blank(),\n    axis.text.y = element_blank()\n  )\n\n\n\nggplot2::geom_boxplot()\n\n\n\n\n\n\n\n\n\n\n\n\nHow do we customize our boxplot?\nFor a boxplot, we can change outlier’s color, shape and size, using outlier.colour, outlier.shape and outlier.size.\nI remembered I show you point shape and its corresponding number when I introduced base R plotting. You can use the same point shape numbering system here.\nYou can also decide if the boxplot has a notch, although I don’t see the importance of this option.\nAnd again you can customize the box using fill, color, and alpha argument.\nAnd one interesting part is that, when we show a boxplot like this, the y-axis does not mean anything right? the width or height of the box does not meaning anything.\nSo we can actually remove the y axis tick marks and labels.\nAnd how? Because the axes labels and ticks are part of plotting theme, we should go to theme and set ticks.y and text.y = element_blank().\nThis is very ggplot2 syntax. It is a little bit harder to read and make sense of, so it does take time to get used to it."
  },
  {
    "objectID": "slides/10-viz.html#adding-a-categorical-variable-to-box-plots",
    "href": "slides/10-viz.html#adding-a-categorical-variable-to-box-plots",
    "title": "Visualizing Data 📈",
    "section": "Adding a Categorical Variable to Box Plots",
    "text": "Adding a Categorical Variable to Box Plots\n\n\n\nloans |&gt;\n  ggplot(\n    aes(x = interest_rate,\n        y = grade) #&lt;&lt;\n  ) +\n  geom_boxplot() +\n  labs(\n    x = \"Interest rate (%)\",\n    y = \"Grade\",\n    title = \"Interest Rates of Loans\",\n    subtitle = \"by grade of loan\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can also add categorical variable to a boxplot, so these are called side-by-side boxplots. They are very commonly used.\nThis is the interest rate distribution by the grade of loan, where A is of the highest quality and G is the lowest quality.\nAnd it looks like the higher the quality of the loan, the lower the interest rate it has.\nWe can also see that there is an outlier in grade D data, where the interest rate is super low, even lower than most of the interest rate of the grade A loans. You as a reasearcher or data analyst have to figure out if it is typo, or it is the true interest rate. If it is a correct number, why such low interest rate happened?\nAnd to create such side-by-side boxplot, we just add y mapping, setting it to grade."
  },
  {
    "objectID": "slides/10-viz.html#adding-two-categorical-variables-to-box-plots",
    "href": "slides/10-viz.html#adding-two-categorical-variables-to-box-plots",
    "title": "Visualizing Data 📈",
    "section": "Adding Two Categorical Variables to Box Plots",
    "text": "Adding Two Categorical Variables to Box Plots\n\n\n\nloans |&gt;\n  ggplot(\n    aes(x = interest_rate,\n        y = grade,\n        fill = homeownership) #&lt;&lt;\n  ) +\n  geom_boxplot() +\n  labs(\n    x = \"Interest rate (%)\",\n    y = \"Grade\",\n    fill = \"Homeowership\",\n    title = \"Interest Rates of Loans\",\n    subtitle = \"by grade and ownership\"\n  ) +\n  theme(\n    legend.position = \"bottom\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\n\nIf we want to add two categorical variables to box plots, that’s easy.\nWe can fill the boxplots with colors based on another variable, here the homeownership.\nANd now each grade of loans is furthered divided into three categories of the homeownership variable.\nAnd we can see that basically, the type of homeownership does not affect interest rate much given the same grade of loans."
  },
  {
    "objectID": "slides/10-viz.html#adding-points-on-box-plots",
    "href": "slides/10-viz.html#adding-points-on-box-plots",
    "title": "Visualizing Data 📈",
    "section": "Adding Points on Box Plots",
    "text": "Adding Points on Box Plots\n\nggplot(loans, aes(x = homeownership, y = interest_rate)) +\n    geom_boxplot() +\n    geom_point(alpha = 0.1, shape = 1) #&lt;&lt; geom_jitter(width = 0.2, alpha = 0.1, shape = 1)\n\n\n\nIf we don’t just want the boxplot, and we also want to show data points along with the boxplot, we can add the another layer geom_point(), as shown here.\nBut this plot is a little misleading. Anybody see why?\nThe boxplot tell us 50% of the data points should be inside the box, right?\nBut according to the boxplot, it is not the case. Why?\nActually, there are lots points overlapped at the same interest rate. So it looks like there is only one data point, but actually there are many data points right there. They just overlapped each other.\nSo how do we actually show all data points?"
  },
  {
    "objectID": "slides/10-viz.html#scatterplot",
    "href": "slides/10-viz.html#scatterplot",
    "title": "Visualizing Data 📈",
    "section": "Scatterplot",
    "text": "Scatterplot\n\nggplot(loans, aes(x = debt_to_income, y = interest_rate)) +\n    geom_point(shape = 23, fill = \"blue\", size = 0.8)  #&lt;&lt;\n\n\n\nWe already talked about scatter plot using geom_point().\nHere we have a scatter plot of interest rate and the debt to income ratio.\nOne potential problem here is that like adding points to boxplot, we have so many data points overlapped together, and their relationship cannot be truly revealed. and so it’s really difficult to make sense of this scatter plot built with geom_point."
  },
  {
    "objectID": "slides/10-viz.html#hex-plot",
    "href": "slides/10-viz.html#hex-plot",
    "title": "Visualizing Data 📈",
    "section": "Hex Plot",
    "text": "Hex Plot\n\nggplot(loans, aes(x = debt_to_income, y = interest_rate)) +\n    geom_hex()  #&lt;&lt; (hexbin pkg)\n\n\n\nSo one solution is using Hex Plot instead by using geom_hex() function.\nThe idea is that we first bin these data with the hex shape, grouping data points together for each hex bin.\nAnd the color of these hexes is what tells us how many data points or how dense my data are.\nSo the lighter the color, the more data points we have there.\nThis is particularly useful when we have lots of data points that have similar or the same values."
  },
  {
    "objectID": "slides/10-viz.html#hex-plot-zoom-in",
    "href": "slides/10-viz.html#hex-plot-zoom-in",
    "title": "Visualizing Data 📈",
    "section": "Hex Plot Zoom-in",
    "text": "Hex Plot Zoom-in\n\nloans |&gt;\n    filter(debt_to_income &lt; 100) |&gt;\n    ggplot(aes(x = debt_to_income, y = interest_rate)) +\n    geom_hex() +\n    viridis::scale_fill_viridis()\n\n\n\nHere just show you that we can further zoom in the plot, focusing on the the data that has debt_to_income ratio less that 100%.\nAnd now we can more clearly see what’s going on.\nBasically, more data points happen around debt_to_income ratio 12 to 15% and interest rate 10%.\nAnd the two variables are a little bit positively correlated that higher debt_to_income ratio corresponds to higher interest rate. But again the correlation is very weak here."
  },
  {
    "objectID": "slides/10-viz.html#line-chart-for-time-series-ggplot2geom_line",
    "href": "slides/10-viz.html#line-chart-for-time-series-ggplot2geom_line",
    "title": "Visualizing Data 📈",
    "section": "Line Chart for Time Series ggplot2::geom_line()\n",
    "text": "Line Chart for Time Series ggplot2::geom_line()\n\n\neconomics_long |&gt; ggplot(aes(x = date, y = value01,\n                             colour = variable, linetype = variable)) +\n    geom_line(linewidth = 1) +\n    theme_bw() +\n    theme(legend.position = \"bottom\")\n\n\n\nIf you have time series data, line plot is your good friend, which shows the trend of some variable.\nFor example here, the unemployment number."
  },
  {
    "objectID": "slides/10-viz.html#qq-plots",
    "href": "slides/10-viz.html#qq-plots",
    "title": "Visualizing Data 📈",
    "section": "QQ-plots",
    "text": "QQ-plots\n\nQuantile-Quantile plots are used to check if data are normally distributed (or follow any distribution).\n\n\nggplot(mpg, aes(sample = hwy)) + geom_qq() + geom_qq_line()\n\n\n\nTo create a qqplot, we add the geometry geom_qq(), and geom_qq_line() if you want to add a straight line that helps you determine whether the data are normally distributed."
  },
  {
    "objectID": "slides/10-viz.html#violin-plots",
    "href": "slides/10-viz.html#violin-plots",
    "title": "Visualizing Data 📈",
    "section": "Violin Plots",
    "text": "Violin Plots\n\nViolin plots are similar to box plots, but show the smooth density of the data.\n\n\nf &lt;- ggplot(loans, aes(x = loan_amount, y = grade))\n\n\n\n\nf + geom_boxplot()\n\n\n\n\n\n\n\n\n\nf + geom_violin()\n\n\n\n\n\n\n\n\n\n\nIn ggplot, we can use geom_violin() to create one. \n\nSee if we just check the boxplot, we will miss the information that the loan amount of the grade G actually has a bimodal distribution, right?"
  },
  {
    "objectID": "slides/10-viz.html#add-on-ggridges-for-ridge-plots",
    "href": "slides/10-viz.html#add-on-ggridges-for-ridge-plots",
    "title": "Visualizing Data 📈",
    "section": "Add-on 📦: ggridges for Ridge Plots",
    "text": "Add-on 📦: ggridges for Ridge Plots\n\nlibrary(ggridges)\nggplot(loans, aes(x = loan_amount, y = grade, fill = grade, color = grade)) +\n    geom_density_ridges(alpha = 0.9)\n\n\n\nTo show better smooth density plots, we can create the so-called ridge plots provided by the add-on package called ggridges.\neverything is basically the same. You just need to install and load the package, and add the geometry called geom_density_ridges()."
  },
  {
    "objectID": "slides/10-viz.html#add-on-ggrepel",
    "href": "slides/10-viz.html#add-on-ggrepel",
    "title": "Visualizing Data 📈",
    "section": "Add-on 📦: ggrepel \n",
    "text": "Add-on 📦: ggrepel \n\n\n\nggrepel provides geoms for ggplot2 to repel overlapping text labels.\n\n\nlibrary(ggrepel)\np &lt;- mtcars |&gt; filter(wt &gt; 2.75 & wt &lt; 3.45) |&gt; rownames_to_column(\"car\") |&gt;\n    ggplot(aes(wt, mpg, label = car)) +\n    geom_point(color = \"red\")\n\n\n\n\np + geom_text() +\n    labs(title = \"geom_text()\")\n\n\n\n\n\n\n\n\n\np + geom_text_repel() +\n    labs(title = \"geom_text_repel()\")\n\n\n\n\n\n\n\n\n\n\nAnother useful ggplot2 extension is ggrepel that provides geoms for ggplot2 to repel overlapping text labels.\nThis makes your labels much more clear.\nFor example, here I want to label each data point by its observation’s name, I can add geom_text(). But the ggplot2 setting basically put the text right on the top of the point, which sometimes the labels are mixed together and makes it hard to read.\nAnd we can use the function geom_text_repel(), and then it will automatically find a good spot for those texts that are close to their data point, but not overlap each other."
  },
  {
    "objectID": "slides/10-viz.html#wordcloud-from-ggwordcloud-package",
    "href": "slides/10-viz.html#wordcloud-from-ggwordcloud-package",
    "title": "Visualizing Data 📈",
    "section": "Wordcloud from ggwordcloud Package \n",
    "text": "Wordcloud from ggwordcloud Package \n\n\n\nPlot\nCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlibrary(ggwordcloud)\nlibrary(showtext)\nwhere &lt;- font_files()[which(str_detect(font_files()$family, \"Arial Unicode MS\")), ]\npar(mar = c(0, 0, 0, 0))\nthankyou_words_small |&gt; ggplot(aes(label = word, size = speakers, color = name)) +\n    geom_text_wordcloud(area_corr = TRUE, rm_outside = TRUE,\n                        family = where[1, ]$family) +\n    scale_size_area(max_size = 40) +\n    theme_minimal() +\n    theme(plot.margin = margin(t = -200,  # Top margin\n                               r = 0,  # Right margin\n                               b = 0,  # Bottom margin\n                               l = 0)) # Left margin\n\n\n\n\nhttps://towardsdatascience.com/create-a-word-cloud-with-r-bde3e7422e8a http://www.sthda.com/english/wiki/text-mining-and-word-cloud-fundamentals-in-r-5-simple-steps-you-should-know http://www.sthda.com/english/wiki/word-cloud-generator-in-r-one-killer-function-to-do-everything-you-need https://semba-blog.netlify.app/10/29/2019/creating-wordcloud-in-r/     https://stackoverflow.com/questions/74415534/why-do-characters-from-foreign-alphabets-not-show-in-my-wordcloud-on-r"
  },
  {
    "objectID": "slides/10-viz.html#radar-chart-from-fmsb-and-ggradar-package",
    "href": "slides/10-viz.html#radar-chart-from-fmsb-and-ggradar-package",
    "title": "Visualizing Data 📈",
    "section": "Radar Chart from fmsb and ggradar Package",
    "text": "Radar Chart from fmsb and ggradar Package\n\n\nPlot\nCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nradar_data &lt;- readr::read_csv(\n    file = \"./data/radar_data.csv\")\n# Color vector\ncolors_border &lt;- c(rgb(0.2,0.5,0.5,0.9),\n                   rgb(0.8,0.2,0.5,0.9),\n                   rgb(0.7,0.5,0.1,0.9))\ncolors_in &lt;- c(rgb(0.2,0.5,0.5,0.4),\n               rgb(0.8,0.2,0.5,0.4),\n               rgb(0.7,0.5,0.1,0.4))\npar(mar = c(0, 0, 0, 0))\nradarchart(radar_data, axistype = 1,\n           #custom polygon\n           pcol = colors_border,\n           pfcol = colors_in,\n           plwd = 4, plty = 1,\n           #custom the grid\n           cglcol = \"grey\", cglty = 1,\n           axislabcol = \"grey\",\n           caxislabels = seq(0, 20, 5),\n           cglwd = 0.8,\n           #custom labels\n           vlcex = 1.2)\n# legend(\"topright\", legend = rownames(radar_data[-c(1, 2), ]), bty = \"n\", pch = 20 ,\n#        col = colors_in, text.col = \"grey\", cex = 1.2, pt.cex = 3)\n\n\n\n\n\nlibrary(ggradar)\n\nggradar_data &lt;- radar_data |&gt;\n    as_tibble(rownames = \"group\") |&gt;\n    mutate_at(vars(-group), rescale) |&gt;\n    tail(3)\npar(mar = c(0, 0, 0, 0))\nggradar(ggradar_data,\n        base.size = 5,\n        grid.label.size = 6,\n        axis.label.size = 5,\n        group.point.size = 3,\n        fill.alpha = 0.2,\n        grid.line.width = 0.4,\n        plot.legend = FALSE,\n        fill = TRUE)\n\n\n\n\n\n\n\nlazy-load database ‘/Library/Frameworks/R.framework/Versions/4.2-arm64/Resources/library/callr/R/callr.rdb’ is corrupt Restart R"
  },
  {
    "objectID": "slides/10-viz.html#network-from-igraph-package",
    "href": "slides/10-viz.html#network-from-igraph-package",
    "title": "Visualizing Data 📈",
    "section": "Network from igraph Package",
    "text": "Network from igraph Package\n\n\nPlot\nCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlibrary(igraph)\nnetwork_data &lt;- read_rds(file = \"./data/network_data.rds\")\n\n# build the graph object\nnetwork &lt;- graph_from_adjacency_matrix(network_data)\n\n# plot it\nplot(network)"
  },
  {
    "objectID": "slides/10-viz.html#more-r-graphics-resources",
    "href": "slides/10-viz.html#more-r-graphics-resources",
    "title": "Visualizing Data 📈",
    "section": "More R Graphics Resources",
    "text": "More R Graphics Resources\n\nMore add-on 📦: ggplot2 extensions\n\nThe R Graph Gallery\nR Graphics Cookbook\nR CHARTS\n\n\n\n\n\n\n\n\n\n\nAs I mentioned before, there are tons of ggplot2 extensions.\nIf you are interested, check those links, and learn more about them. OK.\n\n\n\n\nmath3570-s25.github.io/website"
  },
  {
    "objectID": "slides/02-datascience.html#a-little-history-of-data-science",
    "href": "slides/02-datascience.html#a-little-history-of-data-science",
    "title": "Data Science Overview 📖",
    "section": "A Little History of Data Science",
    "text": "A Little History of Data Science\n\nIn 1985, Dr. Jeff Wu used the term Data Science for the first time as an alternative name for Statistics.  \n\n\n\n\nThe first question is What is DS? Actually this is a really hard question to answer, at least at this moment.\n\nOriginally, DS was proposed to replace statistics. DS is just another name or maybe better name for statistics.\n\n\nBut still at that time, nobody cares. Statisticians are weird guys in math departments who deal with proofs and theorems and sometimes real data, and they are stubborn, not willing to change. But if you wiki the definition of statistics, statistics is a science of data, and you tell me what is the difference of science of data and data science?\n\n\nUsing this definition, DS becomes a broader term than statistics. Anything related to data can be a part of data sicence, while statistics now becomes a narrower subject focusing on inference and data analysis part.\n\nHere shows the google trend of DS. When I was in college or beginning of PHD studies, very few people used DS as a term. And all of sudden, DS become more and more popular, and everybody is talking about it."
  },
  {
    "objectID": "slides/02-datascience.html#section-1",
    "href": "slides/02-datascience.html#section-1",
    "title": "Data Science Overview 📖",
    "section": "",
    "text": "Source: https://www.reddit.com/r/meme/comments/floq3q/reality_behind_data_science/\n\n\n\n\n\n\n\n\n\nSource: https://br.ifunny.co/picture/we-will-work-together-statistics-computer-science-please-teach-now-h4hdtthT9?s=cl"
  },
  {
    "objectID": "slides/02-datascience.html#battle-of-the-data-science-venn-diagrams",
    "href": "slides/02-datascience.html#battle-of-the-data-science-venn-diagrams",
    "title": "Data Science Overview 📖",
    "section": "Battle of the Data Science Venn Diagrams",
    "text": "Battle of the Data Science Venn Diagrams\n\n\n\n2010 Drew Conway\n\n\n\n\n\n\n\n\n\n\n\n2012 Brendan Tierney"
  },
  {
    "objectID": "slides/02-datascience.html#battle-of-the-data-science-venn-diagrams-1",
    "href": "slides/02-datascience.html#battle-of-the-data-science-venn-diagrams-1",
    "title": "Data Science Overview 📖",
    "section": "Battle of the Data Science Venn Diagrams",
    "text": "Battle of the Data Science Venn Diagrams\n\n\n\n2013 Ulrich Matter\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2014 Michael Malak\n\n\n\n\n\n\n\n\n\n\n\n\nStarting 2010, people tried to use venn diagrams to define DS, what should be include, what should be not. It’s a subset of something, or superset of something.\nWe have to do DS on some subject/field.\n(left) ML use CS and STAT but doesn’t care about domain knowledge.\nIf you apply CS to substantive expertise without solid math and stats, you are doing bullshit basically.\n(right) DS is a subset of KDD - Knowledge Discovery in Data"
  },
  {
    "objectID": "slides/02-datascience.html#battle-of-the-data-science-venn-diagrams-2",
    "href": "slides/02-datascience.html#battle-of-the-data-science-venn-diagrams-2",
    "title": "Data Science Overview 📖",
    "section": "Battle of the Data Science Venn Diagrams",
    "text": "Battle of the Data Science Venn Diagrams\n\n\n\n2015 Stephan Kolassa\n\n\n\n\n\n\n\n\n\n\n\n2016 Gregory Piatetsky-Shapiro"
  },
  {
    "objectID": "slides/02-datascience.html#shall-we-continue",
    "href": "slides/02-datascience.html#shall-we-continue",
    "title": "Data Science Overview 📖",
    "section": "Shall We Continue?",
    "text": "Shall We Continue?\n\n\n\n2017 Longbing Cao\n\n\n\n\n\n\n\n\n\n\n\ntotally-not-a-Venn-diagram by Calvin Andrus"
  },
  {
    "objectID": "slides/02-datascience.html#section-3",
    "href": "slides/02-datascience.html#section-3",
    "title": "Data Science Overview 📖",
    "section": "",
    "text": "You probably get the idea. There are so many ways to define data science."
  },
  {
    "objectID": "slides/02-datascience.html#what-is-data-scientist",
    "href": "slides/02-datascience.html#what-is-data-scientist",
    "title": "Data Science Overview 📖",
    "section": "What is Data Scientist",
    "text": "What is Data Scientist\n\n💰 💰 Dr. Grant (Statistics Education Research Journal, 2017): Data science is the field of people who decide to print “Data Scientist” on their business cards to get a salary bump! 💵 💵"
  },
  {
    "objectID": "slides/02-datascience.html#what-is-data-scientist-1",
    "href": "slides/02-datascience.html#what-is-data-scientist-1",
    "title": "Data Science Overview 📖",
    "section": "What is Data Scientist",
    "text": "What is Data Scientist\n\n\n\n\n\n\n\nSource: https://www.instagram.com/data_science_learn/\n\n\n\n\n\n\n\n\nSource: https://www.instagram.com/data_science_dojo/"
  },
  {
    "objectID": "slides/02-datascience.html#what-wiki-defines",
    "href": "slides/02-datascience.html#what-wiki-defines",
    "title": "Data Science Overview 📖",
    "section": "What Wiki Defines",
    "text": "What Wiki Defines"
  },
  {
    "objectID": "slides/02-datascience.html#data-science-in-this-course",
    "href": "slides/02-datascience.html#data-science-in-this-course",
    "title": "Data Science Overview 📖",
    "section": "Data Science in This Course",
    "text": "Data Science in This Course\n\nData science is an discipline that allows us to turn raw data into understanding, insight, and knowledge.\nWe’re going to learn to do this in a tidy way – more on that later!\nThis is a introductory data science course with an emphasis on important tools of R/Python that help us do data science."
  },
  {
    "objectID": "slides/02-datascience.html#data-science-workflow",
    "href": "slides/02-datascience.html#data-science-workflow",
    "title": "Data Science Overview 📖",
    "section": "Data Science Workflow",
    "text": "Data Science Workflow"
  },
  {
    "objectID": "slides/02-datascience.html#section-4",
    "href": "slides/02-datascience.html#section-4",
    "title": "Data Science Overview 📖",
    "section": "",
    "text": "Import: Take data stored somewhere and load it into your workspace.\n\nTidy: Storing data in a consistent rectangular form, i.e., a data matrix.\n\nTransform: Narrowing in on observations of interest, creating new variables, calculating statistics.\n\n\nTo do DS, we need data, so the first step is to import data (——).\nBut usually the raw data are very messy, so we need tidy the data by storing data in a consistent rectangular form (data frame in R), which is easy for modeling and analysis.\nDepending on our research goal, we may just want to focus on some variables , or observations in the data, or we may want to create some variables for example, the data use feet, but we want to use meter instead. This data transformation further cleans the data, so that we can extract any information we need from data more easily and efficiently. In other words, we improve the quality of data."
  },
  {
    "objectID": "slides/02-datascience.html#data-matrix",
    "href": "slides/02-datascience.html#data-matrix",
    "title": "Data Science Overview 📖",
    "section": "Data Matrix",
    "text": "Data Matrix\n\nEach row corresponds to a unique case or observational unit.\nEach column represents a characteristic or variable.\nThis structure allows new cases to be added as rows or new variables as new columns.\n\n\n\nggplot2::mpg |&gt; print(n = 10)\n\n# A tibble: 234 × 11\n   manufacturer model      displ  year   cyl trans drv     cty   hwy fl    class\n   &lt;chr&gt;        &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt;\n 1 audi         a4           1.8  1999     4 auto… f        18    29 p     comp…\n 2 audi         a4           1.8  1999     4 manu… f        21    29 p     comp…\n 3 audi         a4           2    2008     4 manu… f        20    31 p     comp…\n 4 audi         a4           2    2008     4 auto… f        21    30 p     comp…\n 5 audi         a4           2.8  1999     6 auto… f        16    26 p     comp…\n 6 audi         a4           2.8  1999     6 manu… f        18    26 p     comp…\n 7 audi         a4           3.1  2008     6 auto… f        18    27 p     comp…\n 8 audi         a4 quattro   1.8  1999     4 manu… 4        18    26 p     comp…\n 9 audi         a4 quattro   1.8  1999     4 auto… 4        16    25 p     comp…\n10 audi         a4 quattro   2    2008     4 manu… 4        20    28 p     comp…\n# ℹ 224 more rows"
  },
  {
    "objectID": "slides/02-datascience.html#section-5",
    "href": "slides/02-datascience.html#section-5",
    "title": "Data Science Overview 📖",
    "section": "",
    "text": "The process of importing, tidying and transforming data is called data wrangling or data munging."
  },
  {
    "objectID": "slides/02-datascience.html#section-6",
    "href": "slides/02-datascience.html#section-6",
    "title": "Data Science Overview 📖",
    "section": "",
    "text": "Visualisation: A good visualisation shows you things that you did not expect or raise new questions about the data.\n\n\nOnce the data are ready, it’s time to explore our data.\nMy recommendation is that always plot your data before building any model or algorithm or doing analysis because good visualization let you understand more about your data, and may provide some hints about how to build your statistical model, machine learning algorithms or how to do analysis.\nAnd good visualization shows you things that you did not expect or raise new questions about the data. (outliers, missing data)\nSo after visualizing your data, you may have better idea of how to transforming your data so that you can be better prepared for modeling and answer your research questions. (nonlinear relationship &lt;-&gt; linear relationship)"
  },
  {
    "objectID": "slides/02-datascience.html#section-7",
    "href": "slides/02-datascience.html#section-7",
    "title": "Data Science Overview 📖",
    "section": "",
    "text": "mpg |&gt; ggplot(aes(x = displ, y = hwy)) +\n    geom_point(aes(color = class)) + \n    geom_smooth() + \n    theme_bw()"
  },
  {
    "objectID": "slides/02-datascience.html#section-8",
    "href": "slides/02-datascience.html#section-8",
    "title": "Data Science Overview 📖",
    "section": "",
    "text": "Model: Models are complementary tools to visualisation. Once you have made your questions sufficiently precise, you can use a model to answer them.\n\n\nThe next step is to use or build a rigorous statistical or machine learning model to answer our research questions. For example, forecasting stock prices, classifying images.\nAnd transform-visualize-model becomes a loop of understanding or learning from data. We keep transforming, visualizing and modeling our data until our questions are properly answered by our data and model."
  },
  {
    "objectID": "slides/02-datascience.html#section-9",
    "href": "slides/02-datascience.html#section-9",
    "title": "Data Science Overview 📖",
    "section": "",
    "text": "library(tidymodels)\nlinear_reg() |&gt;  \n    set_engine(\"lm\") |&gt; \n    fit(hwy ~ displ, data = mpg)\n\nparsnip model object\n\n\nCall:\nstats::lm(formula = hwy ~ displ, data = data)\n\nCoefficients:\n(Intercept)        displ  \n      35.70        -3.53"
  },
  {
    "objectID": "slides/02-datascience.html#section-10",
    "href": "slides/02-datascience.html#section-10",
    "title": "Data Science Overview 📖",
    "section": "",
    "text": "Communication: It doesn’t matter how well your models and visualization have led you to understand the data unless you can also communicate your results to others.\n\n\nFinally we have to share our analysis results with others.\nAt this stage, visualization plays an important role as well.\nFigures/tables speak louder than words.\nWe can have different types of deployment. In addition to papers or reports, we can create a website, a software package, a mobile app, dashboard and so on."
  },
  {
    "objectID": "slides/02-datascience.html#section-11",
    "href": "slides/02-datascience.html#section-11",
    "title": "Data Science Overview 📖",
    "section": "",
    "text": "Programming: Surrounding all these tools is programming.\n\n\nOf course, every aspect of DS is done by programming. DS cannot be done by pieces of paper and pens. It has to be done using computers."
  },
  {
    "objectID": "slides/02-datascience.html#r-for-data-science",
    "href": "slides/02-datascience.html#r-for-data-science",
    "title": "Data Science Overview 📖",
    "section": "R for Data Science",
    "text": "R for Data Science\n\n\n\n\n\nSource: https://teachdatascience.com/tidyverse/\n\n\n\n\n\n\n\nIf you are ready, let’s dive in and learn all these tools. Well not all, but some of these tools.\nBy the way, you see these hex stickers? It kind of becomes a trend that when we create an R package, or software, we also create a hex logo associated with it, so it works as product or brand logo. It may be easier for you to promote your package if you have a cute or beautiful hex logo."
  },
  {
    "objectID": "slides/02-datascience.html#python-for-data-science",
    "href": "slides/02-datascience.html#python-for-data-science",
    "title": "Data Science Overview 📖",
    "section": "Python for Data Science",
    "text": "Python for Data Science\n\n\n\n\n\nSource: https://www.e2enetworks.com/blog/9-python-libraries-for-data-science-and-artificial-intelligence\n\n\n\n\n\n\n\n\nmath3570-s25.github.io/website"
  },
  {
    "objectID": "slides/01-syllabus.html#my-journey",
    "href": "slides/01-syllabus.html#my-journey",
    "title": "Welcome Aboard 🙌",
    "section": "My Journey",
    "text": "My Journey\n\nAssistant Professor (2020/08 - )\n\n\n\n\n\n\n\n\n\n\nPostdoctoral Fellow\n\n\n\n\n\n\n\n\n\n\nPhD in Statistics\n\n\n\n\n\n\n\n\n\n\nMA in Economics/PhD program in Statistics\n\n\n\n\n\n\n\n\n\nAfter college, working and doing military service for several years, I came to the US for my PhD degree. Originally I would like to study economics, but then I switched my major to statistics.\n\nI got my master degree in economics from Indiana University Bloomington, then I transferred to UC Santa Cruz to finish my PhD studies.\nThen I spent two years doing my postdoctoral research at Rice University in Houston, Texas.\nFinally, in fall 2020, I came to Marquette as an assistant professor.\nMidwest/Indiana-West/California-South/Texas-Midwest/Wisconsin\nBeen to any one of these universities/cities?\nThe most beautiful campus.\nWho are international students? I can totally understand how hard studying and living in another country. Feel free to share your stories or difficulties, and I am more than happy to help you if you have any questions.\nPoor listening and speaking skills. I was shy.\nOK so, this is my background. How about you introducing yourself as well. You can share anything, your major, hobbies, your favorite food, what do you want to do after graduation, anything,\nI have the class list. I’d like to learn your face and remember your name. You know, you all wear a mask. It’s hard to recognize you and connect your name and your face.\nWhen I call your name, you can say something about yourself. No need to be long, couple of seconds are good."
  },
  {
    "objectID": "slides/01-syllabus.html#how-to-reach-me",
    "href": "slides/01-syllabus.html#how-to-reach-me",
    "title": "Welcome Aboard 🙌",
    "section": "How to Reach Me",
    "text": "How to Reach Me\n\nOffice hours TuTh 4:50 - 5:50 PM and Wed 12 - 1 PM in Cudahy Hall 353.\n📧 cheng-han.yu@marquette.edu\n\nAnswer your question within 24 hours.\nExpect a reply on Monday if shoot me a message on weekends.\nStart your subject line with [math3570] or [cosc3570] followed by a clear description of your question.\n\n\n\n\n\nI will NOT reply your e-mail if … Check the email policy in the syllabus!"
  },
  {
    "objectID": "slides/01-syllabus.html#ta-information",
    "href": "slides/01-syllabus.html#ta-information",
    "title": "Welcome Aboard 🙌",
    "section": "TA Information",
    "text": "TA Information\n\n\n\nStatistics PhD student Qishi Zhan\n📨 qishi.zhan@marquette.edu\nHelp desk hours: To be announced.\nWelcome to set up a meeting with your TA via Teams.\nLet me know if you need any other help! 😄"
  },
  {
    "objectID": "slides/01-syllabus.html#what-is-this-course",
    "href": "slides/01-syllabus.html#what-is-this-course",
    "title": "Welcome Aboard 🙌",
    "section": "What is This Course?",
    "text": "What is This Course?\n\n\nEvery aspect of doing a practical data science project, from importing data to deploying what we learn from data.\n\n\n❓ What are prerequisites?\n👉 COSC 1010 (Intro Programming) and MATH 4720 (Intro Stats) or MATH 2780 (Intro Regression)\n\n\n\n❓ Is this like another intro stats course?\n👉 No. Statistics and data science are closely related.\n\n\nNowadays\n👉 Data science is a broader subject than statistics.\n\n\n👉 Statistics focuses more on analyzing and learning from data, a part of the entire workflow of data science.\n\n\n\n❓ Is this like another intro CS or programming course?\n👉 Absolutely not. We learn how to code for doing data science, not for understanding computer systems and structures.\n\nOf course we will not cover every detail form A to Z of DS in one semester becuase DS is such a huge subject, just like computer science. It’s impossible to learn CS in one semester by just taking intro to CS, right? So we’ll just learn the basic and essential concepts and tools used is DS."
  },
  {
    "objectID": "slides/01-syllabus.html#what-is-not-covered-in-this-course",
    "href": "slides/01-syllabus.html#what-is-not-covered-in-this-course",
    "title": "Welcome Aboard 🙌",
    "section": "What is NOT Covered in This Course",
    "text": "What is NOT Covered in This Course\n\n\nAdvanced data analytics and computing  \n\nMATH 4750 Statistical Computing\nMATH 4760 Time Series Analysis\nMATH 4780 Regression Analysis\nMATH 4790 Bayesian Statistics\nCOSC 4600 Fundamentals of Artificial Intelligence\nCOSC 4610 Data Mining\nCOEN 4860 Introduction to Neural Networks\n\n\n\n\n\n\nBig data: We start with small, in-memory data sets. You don’t know how to tackle big data unless you have experience with small data.\n\n\n\n\n\nDatabase: Learn SQL in\n\nCOSC 4800 Principles of Database Systems\nINSY 4052 Database Management Systems.\n\n\n\n\nWe won’t talk about topics like cloud computing, parallel computing, distributed computing.\n\nBig data techniques: As a beginner, we focus on small, in-memory datasets. You can’t tackle big data unless you have experience with small data."
  },
  {
    "objectID": "slides/01-syllabus.html#what-computing-languages",
    "href": "slides/01-syllabus.html#what-computing-languages",
    "title": "Welcome Aboard 🙌",
    "section": "What Computing Languages?",
    "text": "What Computing Languages?\n\n\n~ 60%\n\n\n\n\n\n\n\n\n\n~ 40%\n\n\n\n\n\n\n\n\n\n\n\nYou’ve learned Python in COSC 1010. Being R-Python bilingual is getting more important!\n\n\n👉 Wouldn’t it be great to add both languages to your resume! 😎 \n\n\n❌ Don’t want to learn R and/or Python? Take 3570 next semester~!\n❌ Drop deadline: 01/21 (Tue), 11:59 PM."
  },
  {
    "objectID": "slides/01-syllabus.html#where-to-code-posit-cloud",
    "href": "slides/01-syllabus.html#where-to-code-posit-cloud",
    "title": "Welcome Aboard 🙌",
    "section": "Where to Code? Posit Cloud\n",
    "text": "Where to Code? Posit Cloud\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHave nice computing power and interactive collaboration with me and your teammates!\nStudent plan: $5/month (Cheaper than buying a textbook!)"
  },
  {
    "objectID": "slides/01-syllabus.html#course-materials",
    "href": "slides/01-syllabus.html#course-materials",
    "title": "Welcome Aboard 🙌",
    "section": "Course Materials",
    "text": "Course Materials\n\nCourse Website - https://math3570-s25.github.io/website/"
  },
  {
    "objectID": "slides/01-syllabus.html#section-1",
    "href": "slides/01-syllabus.html#section-1",
    "title": "Welcome Aboard 🙌",
    "section": "",
    "text": "Python for Data Analysis, 3E\n\n\n\n\n\n\n\n\n\nR for Data Science 2nd edition\n\n\n\n\n\n\n\n\n\nTidy Modeling with R"
  },
  {
    "objectID": "slides/01-syllabus.html#learning-management-system-d2l",
    "href": "slides/01-syllabus.html#learning-management-system-d2l",
    "title": "Welcome Aboard 🙌",
    "section": "Learning Management System (D2L)",
    "text": "Learning Management System (D2L)\n\n\n\n\n\n\n\n\nAssessments &gt; Grades"
  },
  {
    "objectID": "slides/01-syllabus.html#grading-policy",
    "href": "slides/01-syllabus.html#grading-policy",
    "title": "Welcome Aboard 🙌",
    "section": "Grading Policy ✨",
    "text": "Grading Policy ✨\n\n30% In-class lab exercises and participation.\n30% Homework\n15% Midterm mini project\n25% Final project competition\nExtra credit opportunities\n\n\n❌ You have to participate in the final presentation in order to pass the course.\n❌ You will NOT be allowed to do any extra credit projects/homework/exam to compensate for a poor grade."
  },
  {
    "objectID": "slides/01-syllabus.html#grade-percentage-conversion",
    "href": "slides/01-syllabus.html#grade-percentage-conversion",
    "title": "Welcome Aboard 🙌",
    "section": "Grade-Percentage Conversion",
    "text": "Grade-Percentage Conversion\n\n\n\\([x, y)\\) means greater than or equal to \\(x\\) and less than \\(y\\). For example, 94.0 is in [94, 100] and the grade is A and 93.8 is in [90, 94) and the grade is A-.\n\n\n\n\n\n\nGrade\nPercentage\n\n\n\nA\n[94, 100]\n\n\nA-\n[90, 94)\n\n\nB+\n[87, 90)\n\n\nB\n[84, 87)\n\n\nB-\n[80, 84)\n\n\nC+\n[77, 80)\n\n\nC\n[74, 77)\n\n\nC-\n[70, 74)\n\n\nD+\n[65, 70)\n\n\nD\n[60, 65)\n\n\nF\n[0, 60)"
  },
  {
    "objectID": "slides/01-syllabus.html#lab-exercises-30",
    "href": "slides/01-syllabus.html#lab-exercises-30",
    "title": "Welcome Aboard 🙌",
    "section": "Lab Exercises (30%)",
    "text": "Lab Exercises (30%)\n\nGraded as Complete/Incomplete and used as evidence of attendance and participation.\nAllowed to have one incomplete lab exercise without any penalty.\nBeyond that, 2% grade percentage will be taken off for each missing/incomplete exercise.\nYou will create a RStudio project in Posit Cloud saving all of your lab exercises. (We’ll go through know-how together)"
  },
  {
    "objectID": "slides/01-syllabus.html#homework-30",
    "href": "slides/01-syllabus.html#homework-30",
    "title": "Welcome Aboard 🙌",
    "section": "Homework (30%)",
    "text": "Homework (30%)\n\nThe homework assignments are individual. Submit your own work.\n❌ You may not share answers/code with your classmates.\n\n\n\nHomework will be assigned through GitHub:\n\nclone/pull the homework repo into Posit Cloud\nwork on the Quarto file in the repo (We’ll go through know-how together)\n\n\n\n\n\n\nYou will have at least one week to complete your assignment.\n❌ No make-up homework for any reason unless you have excused absence. 🙏"
  },
  {
    "objectID": "slides/01-syllabus.html#mini-project-15",
    "href": "slides/01-syllabus.html#mini-project-15",
    "title": "Welcome Aboard 🙌",
    "section": "Mini Project (15%)",
    "text": "Mini Project (15%)\n\nYou will be team up to do the midterm mini project.\nMore details about the mini project presentation will be released later."
  },
  {
    "objectID": "slides/01-syllabus.html#project-25",
    "href": "slides/01-syllabus.html#project-25",
    "title": "Welcome Aboard 🙌",
    "section": "Project (25%)",
    "text": "Project (25%)\n\nYou will be team up to do the final project.\n\nYour project can be in either of the following categories:\n\nData analysis using statistical models or machine learning algorithms\nIntroduce a R or Python package not learned in class, including live demo\nIntroduce a data science tool (visualization, computing, etc) not learned in class, including live demo\nIntroduce a programming language not learned in class for doing data science, including live demo, Julia, SQL, MATLAB, SAS for example.\nWeb development: Shiny website or dashboard, including live demo\n\n\nThe final project presentation is on Thursday, 5/1, 2 PM and Monday, 5/5, 10:30 AM - 12:30 PM.\nMore information will be released later."
  },
  {
    "objectID": "slides/01-syllabus.html#generative-ai-and-sharingreusing-code-policy",
    "href": "slides/01-syllabus.html#generative-ai-and-sharingreusing-code-policy",
    "title": "Welcome Aboard 🙌",
    "section": "Generative AI and Sharing/Reusing Code Policy",
    "text": "Generative AI and Sharing/Reusing Code Policy\n\n\nGenerative AI\n\nYou may use generative AI tools such as ChatGPT or DALL-E to generate a first draft of text for your work, provided that this use is documented and cited.\n\n[Example] Data science is an interdisciplinary field that … 1\n\n\n\n\n\n\n\n\n\n\n\n\nSharing/Reusing Code\n\nUnless explicitly stated otherwise, you may make use of any online resources, but you must explicitly cite where you obtained any code you directly use or use as inspiration in your solutions.\n\n[Example]\n\nThe code is modified from the GitHub repo https://github.com/chenghanyustats/slam\nThe code is generated from ChatGPT response to “Please generate Python code for solving the math problem I attach,” Jan 14, 2025.\n\n\nYou are responsible for the content of all work submitted for this course.\nYou can use any code shared online or in books. But please give the authors full credits. Cite their work and let me know whose code you are using to do your homework and project.\nI encourage you to write your own code. This way you learn the most.\n❌ Any recycled code that is discovered and is not explicitly cited will be treated as plagiarism, regardless of source. 😱\n\n\nChatGPT, response to “Tell me what data science is,” Jan 14, 2025, https://chat.openai.com."
  },
  {
    "objectID": "slides/01-syllabus.html#academic-integrity",
    "href": "slides/01-syllabus.html#academic-integrity",
    "title": "Welcome Aboard 🙌",
    "section": "Academic Integrity",
    "text": "Academic Integrity\nThis course expects all students to follow University and College statements on academic integrity.\n\n\nHonor Pledge and Honor Code: I recognize the importance of personal integrity in all aspects of life and work. I commit myself to truthfulness, honor, and responsibility, by which I earn the respect of others. I support the development of good character, and commit myself to uphold the highest standards of academic integrity as an important aspect of personal integrity. My commitment obliges me to conduct myself according to the Marquette University Honor Code."
  },
  {
    "objectID": "slides/01-syllabus.html#q-a",
    "href": "slides/01-syllabus.html#q-a",
    "title": "Welcome Aboard 🙌",
    "section": "Q & A",
    "text": "Q & A\n\n\n\n\n❓ K: I hope to learn more about programming. R: I’m looking forward to learning more about what data science consists of rather than just learning a programming language.\n👉 To make sure everyone is on the same page, first couple of weeks is about learning R and Python syntax. After spring break, we focus on modeling and machine learning methods.\n\n\n❓ What do you think will be the most interesting part of the course?\n👉 I love data visualization and web development.\n\n\n\n\n\n❓ D: Do I need good coding skills to be able to succeed? G: How much of this class is about coding?\n👉 We’ll learn basic syntax for doing data science step by step.\n\n\n\n❓ What kind of time estimate do you believe most students should spend on reading + assignments for the course?\n👉 Everyone is different. The more the better."
  },
  {
    "objectID": "slides/01-syllabus.html#q-a-1",
    "href": "slides/01-syllabus.html#q-a-1",
    "title": "Welcome Aboard 🙌",
    "section": "Q & A",
    "text": "Q & A\n❓ What kind of projects will we be doing for this course?\n👉 Any project related to data works. You propose one to me. We discuss it, then decide.\n\n\n❓ Will this class help me better understand how to code proficiently?\n👉 As you learn to speak a foreign language, you need to code a lot, frequently and constantly in order to be proficient in any programming language. No shortcut.\n\n\n\n❓ Do you know of any internships or research positions offered through Marquette University that incorporate the skills learned in this Data Science course?\n👉 Quite many. Northwestern Mutual, Direct Supply, for example. I’ll share intern info with you if I get any.\n\n\n\n❓ More questions\nBring your laptop next time!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmath3570-s25.github.io/website"
  },
  {
    "objectID": "slides/07-package.html#tidyverse",
    "href": "slides/07-package.html#tidyverse",
    "title": "R/Python Data Frames for Data Science \n",
    "section": "tidyverse 📦",
    "text": "tidyverse 📦\n\n\n\nThe tidyverse is a 📦 for data science.\nAll packages share common design philosophy, grammar, and data structures.\nThe core tidyverse packages include\n\n\nggplot2 - data visualisation\n\ndplyr - data manipulation\n\ntidyr - data tidying\n\nreadr - data importing\n\npurrr - functional programming\n\ntibble - improved data frame\n\nstringr - working with strings\n\nforcats - working with factors\n\nlubridate - working with date/times\n\n\n\n\n\n\n\n\n\nSource: https://github.com/spcanelon/tour-of-the-tidyverse"
  },
  {
    "objectID": "slides/07-package.html#workflow-of-data-science-with-r-packages",
    "href": "slides/07-package.html#workflow-of-data-science-with-r-packages",
    "title": "R/Python Data Frames for Data Science \n",
    "section": "Workflow of Data Science with R packages",
    "text": "Workflow of Data Science with R packages\n\n\n\n\n\nSource: https://oliviergimenez.github.io/intro_tidyverse/#7"
  },
  {
    "objectID": "slides/07-package.html#install-and-load-tidyverse",
    "href": "slides/07-package.html#install-and-load-tidyverse",
    "title": "R/Python Data Frames for Data Science \n",
    "section": "Install and Load tidyverse 📦",
    "text": "Install and Load tidyverse 📦\n\ntidyverse is loading all the core packages for us!\n\n\nlibrary(tidyverse)\n── Attaching core tidyverse packages ──────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ──────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package to force all conflicts to become errors\n\n\nPackages in the tidyverse change frequently. To check if updates are available:\n\n\ntidyverse_update()\nThe following packages are out of date:\n● dbplyr  (2.0.0 -&gt; 2.1.0)\n● forcats (0.5.0 -&gt; 0.5.1)\n● pillar  (1.4.7 -&gt; 1.5.0)\nStart a clean R session then run:\ninstall.packages(c(\"dbplyr\", \"forcats\", \"pillar\"))"
  },
  {
    "objectID": "slides/07-package.html#tidy-data-data-matrix",
    "href": "slides/07-package.html#tidy-data-data-matrix",
    "title": "R/Python Data Frames for Data Science \n",
    "section": "Tidy Data (Data Matrix)",
    "text": "Tidy Data (Data Matrix)\n\n“Happy families are all alike; every unhappy family is unhappy in its own way.” – Leo Tolstoy\n\n\n\nEach variable must have its own column.\nEach observation must have its own row.\nEach value must have its own cell. (match the corresponding row observation and column variable)"
  },
  {
    "objectID": "slides/07-package.html#tidy-data-data-matrix-1",
    "href": "slides/07-package.html#tidy-data-data-matrix-1",
    "title": "R/Python Data Frames for Data Science \n",
    "section": "Tidy Data (Data Matrix)",
    "text": "Tidy Data (Data Matrix)\n\n“Tidy datasets are all alike, but every messy dataset is messy in its own way.” – Hadley Wickham\n\n\n\nEach variable must have its own column.\nEach observation must have its own row.\nEach value must have its own cell. (match the corresponding row observation and column variable)\n\n\nRemember in this course we are working on the so-called tidy data.\nOne of the goals of tidyverse is to make our data tidy.\nSo before we actually get into tidyverse, Let’s define tidy data first.\n“Tidy datasets are all alike, but every messy dataset is messy in its own way.”\nTidy data require that\n\nEach variable must have its own column. (name-value match)\nEach observation must have its own row. The observation could be human being or any object observed in the data set. A row corresponds to an observation.\nEach value must have its own cell."
  },
  {
    "objectID": "slides/07-package.html#why-tidy-data",
    "href": "slides/07-package.html#why-tidy-data",
    "title": "R/Python Data Frames for Data Science \n",
    "section": "Why Tidy Data?",
    "text": "Why Tidy Data?\n\nEach variable must have its own column.\nEach observation must have its own row.\nEach value must have its own cell.\n\n\n\nAdvantages of tidy data:\n\nIf you store all data in a tidy way, you only need to learn the tools that work with them.\nPlacing variables in columns allows R/Python’s vectorised nature to shine. That makes transforming tidy data feel natural.\n\n\n\n\n\n\n\nPractical instructions:\n\nPut each dataset in a data frame.\n\n\nPut each variable in a column.\n\n\n\n\nThese three rules are interrelated; it’s impossible to only satisfy two of the three.\nRemember, “Tidy datasets are all alike, but every messy dataset is messy in its own way.”\n\nRemember, R prefer vectorized programming style. If each variable corresponds to a column vector, it is easy to transform variables using vectorised functions.\nWe will learn how to make our data tidy using tidyr, dplyr and other packages in Data Wrangling weeks."
  },
  {
    "objectID": "slides/07-package.html#data-frames-store-tidy-data",
    "href": "slides/07-package.html#data-frames-store-tidy-data",
    "title": "R/Python Data Frames for Data Science \n",
    "section": "Data Frames Store Tidy Data",
    "text": "Data Frames Store Tidy Data\n\nCollecting information about the distributions of colors and defects in a bag of M&Ms.\n\n\n\n\nNon-tidy Data\n\n\nIf you import data in this format into R/Python, you will be in a mess.\n\n\n\n\n\n\n\n\n\n\n\n\nTidy Data\n\n\nEach row is for one M&M. Each variable is in each column. One value is in a cell.\nDon’t code “Red” in one place and “RED” in another. Be consistent!\n\n\n\n\n\n\n\n\n\n\n\n\n\nYou are gonna find it difficult to deal with this data when you do later visualization and data analysis.\nDon’t code “Red” with capital R in one place and “RED” with all capital letters in another. R treats those as two values.\nconsistent in labeling values for categorical variables."
  },
  {
    "objectID": "slides/07-package.html#tibbles",
    "href": "slides/07-package.html#tibbles",
    "title": "R/Python Data Frames for Data Science \n",
    "section": "Tibbles",
    "text": "Tibbles\n\nTibbles are modern version of R data frames.\nCreate a new tibble using tibble().\nIt is like base::data.frame(), but with a couple differences.\n\n\n\n\ndf &lt;- data.frame(x = 1:5, \n                 y = letters[1:5], \n                 z = 5:1)\ndf\n\n  x y z\n1 1 a 5\n2 2 b 4\n3 3 c 3\n4 4 d 2\n5 5 e 1\n\n\n\nclass(df)\n\n[1] \"data.frame\"\n\n\n\n\n\ntib &lt;- tibble(x = 1:5, \n              y = letters[1:5], \n              z = 5:1)\ntib\n\n# A tibble: 5 × 3\n      x y         z\n  &lt;int&gt; &lt;chr&gt; &lt;int&gt;\n1     1 a         5\n2     2 b         4\n3     3 c         3\n4     4 d         2\n5     5 e         1\n\n\n\nclass(tib)\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\n\n\n\n\nNow we are going discuss the differences between tibble and data frame."
  },
  {
    "objectID": "slides/07-package.html#printing-of-data.frame-class",
    "href": "slides/07-package.html#printing-of-data.frame-class",
    "title": "R/Python Data Frames for Data Science \n",
    "section": "Printing of data.frame Class",
    "text": "Printing of data.frame Class\n\n\nHow the printing method of data.frame can be improved? (Check iris in your R console)\n\n\nclass(iris)\n\n[1] \"data.frame\"\n\n\n\niris\n\n    Sepal.Length Sepal.Width Petal.Length Petal.Width    Species\n1            5.1         3.5          1.4         0.2     setosa\n2            4.9         3.0          1.4         0.2     setosa\n3            4.7         3.2          1.3         0.2     setosa\n4            4.6         3.1          1.5         0.2     setosa\n5            5.0         3.6          1.4         0.2     setosa\n6            5.4         3.9          1.7         0.4     setosa\n7            4.6         3.4          1.4         0.3     setosa\n8            5.0         3.4          1.5         0.2     setosa\n9            4.4         2.9          1.4         0.2     setosa\n10           4.9         3.1          1.5         0.1     setosa\n11           5.4         3.7          1.5         0.2     setosa\n12           4.8         3.4          1.6         0.2     setosa\n13           4.8         3.0          1.4         0.1     setosa\n14           4.3         3.0          1.1         0.1     setosa\n15           5.8         4.0          1.2         0.2     setosa\n16           5.7         4.4          1.5         0.4     setosa\n17           5.4         3.9          1.3         0.4     setosa\n18           5.1         3.5          1.4         0.3     setosa\n19           5.7         3.8          1.7         0.3     setosa\n20           5.1         3.8          1.5         0.3     setosa\n21           5.4         3.4          1.7         0.2     setosa\n22           5.1         3.7          1.5         0.4     setosa\n23           4.6         3.6          1.0         0.2     setosa\n24           5.1         3.3          1.7         0.5     setosa\n25           4.8         3.4          1.9         0.2     setosa\n26           5.0         3.0          1.6         0.2     setosa\n27           5.0         3.4          1.6         0.4     setosa\n28           5.2         3.5          1.5         0.2     setosa\n29           5.2         3.4          1.4         0.2     setosa\n30           4.7         3.2          1.6         0.2     setosa\n31           4.8         3.1          1.6         0.2     setosa\n32           5.4         3.4          1.5         0.4     setosa\n33           5.2         4.1          1.5         0.1     setosa\n34           5.5         4.2          1.4         0.2     setosa\n35           4.9         3.1          1.5         0.2     setosa\n36           5.0         3.2          1.2         0.2     setosa\n37           5.5         3.5          1.3         0.2     setosa\n38           4.9         3.6          1.4         0.1     setosa\n39           4.4         3.0          1.3         0.2     setosa\n40           5.1         3.4          1.5         0.2     setosa\n41           5.0         3.5          1.3         0.3     setosa\n42           4.5         2.3          1.3         0.3     setosa\n43           4.4         3.2          1.3         0.2     setosa\n44           5.0         3.5          1.6         0.6     setosa\n45           5.1         3.8          1.9         0.4     setosa\n46           4.8         3.0          1.4         0.3     setosa\n47           5.1         3.8          1.6         0.2     setosa\n48           4.6         3.2          1.4         0.2     setosa\n49           5.3         3.7          1.5         0.2     setosa\n50           5.0         3.3          1.4         0.2     setosa\n51           7.0         3.2          4.7         1.4 versicolor\n52           6.4         3.2          4.5         1.5 versicolor\n53           6.9         3.1          4.9         1.5 versicolor\n54           5.5         2.3          4.0         1.3 versicolor\n55           6.5         2.8          4.6         1.5 versicolor\n56           5.7         2.8          4.5         1.3 versicolor\n57           6.3         3.3          4.7         1.6 versicolor\n58           4.9         2.4          3.3         1.0 versicolor\n59           6.6         2.9          4.6         1.3 versicolor\n60           5.2         2.7          3.9         1.4 versicolor\n61           5.0         2.0          3.5         1.0 versicolor\n62           5.9         3.0          4.2         1.5 versicolor\n63           6.0         2.2          4.0         1.0 versicolor\n64           6.1         2.9          4.7         1.4 versicolor\n65           5.6         2.9          3.6         1.3 versicolor\n66           6.7         3.1          4.4         1.4 versicolor\n67           5.6         3.0          4.5         1.5 versicolor\n68           5.8         2.7          4.1         1.0 versicolor\n69           6.2         2.2          4.5         1.5 versicolor\n70           5.6         2.5          3.9         1.1 versicolor\n71           5.9         3.2          4.8         1.8 versicolor\n72           6.1         2.8          4.0         1.3 versicolor\n73           6.3         2.5          4.9         1.5 versicolor\n74           6.1         2.8          4.7         1.2 versicolor\n75           6.4         2.9          4.3         1.3 versicolor\n76           6.6         3.0          4.4         1.4 versicolor\n77           6.8         2.8          4.8         1.4 versicolor\n78           6.7         3.0          5.0         1.7 versicolor\n79           6.0         2.9          4.5         1.5 versicolor\n80           5.7         2.6          3.5         1.0 versicolor\n81           5.5         2.4          3.8         1.1 versicolor\n82           5.5         2.4          3.7         1.0 versicolor\n83           5.8         2.7          3.9         1.2 versicolor\n84           6.0         2.7          5.1         1.6 versicolor\n85           5.4         3.0          4.5         1.5 versicolor\n86           6.0         3.4          4.5         1.6 versicolor\n87           6.7         3.1          4.7         1.5 versicolor\n88           6.3         2.3          4.4         1.3 versicolor\n89           5.6         3.0          4.1         1.3 versicolor\n90           5.5         2.5          4.0         1.3 versicolor\n91           5.5         2.6          4.4         1.2 versicolor\n92           6.1         3.0          4.6         1.4 versicolor\n93           5.8         2.6          4.0         1.2 versicolor\n94           5.0         2.3          3.3         1.0 versicolor\n95           5.6         2.7          4.2         1.3 versicolor\n96           5.7         3.0          4.2         1.2 versicolor\n97           5.7         2.9          4.2         1.3 versicolor\n98           6.2         2.9          4.3         1.3 versicolor\n99           5.1         2.5          3.0         1.1 versicolor\n100          5.7         2.8          4.1         1.3 versicolor\n101          6.3         3.3          6.0         2.5  virginica\n102          5.8         2.7          5.1         1.9  virginica\n103          7.1         3.0          5.9         2.1  virginica\n104          6.3         2.9          5.6         1.8  virginica\n105          6.5         3.0          5.8         2.2  virginica\n106          7.6         3.0          6.6         2.1  virginica\n107          4.9         2.5          4.5         1.7  virginica\n108          7.3         2.9          6.3         1.8  virginica\n109          6.7         2.5          5.8         1.8  virginica\n110          7.2         3.6          6.1         2.5  virginica\n111          6.5         3.2          5.1         2.0  virginica\n112          6.4         2.7          5.3         1.9  virginica\n113          6.8         3.0          5.5         2.1  virginica\n114          5.7         2.5          5.0         2.0  virginica\n115          5.8         2.8          5.1         2.4  virginica\n116          6.4         3.2          5.3         2.3  virginica\n117          6.5         3.0          5.5         1.8  virginica\n118          7.7         3.8          6.7         2.2  virginica\n119          7.7         2.6          6.9         2.3  virginica\n120          6.0         2.2          5.0         1.5  virginica\n121          6.9         3.2          5.7         2.3  virginica\n122          5.6         2.8          4.9         2.0  virginica\n123          7.7         2.8          6.7         2.0  virginica\n124          6.3         2.7          4.9         1.8  virginica\n125          6.7         3.3          5.7         2.1  virginica\n126          7.2         3.2          6.0         1.8  virginica\n127          6.2         2.8          4.8         1.8  virginica\n128          6.1         3.0          4.9         1.8  virginica\n129          6.4         2.8          5.6         2.1  virginica\n130          7.2         3.0          5.8         1.6  virginica\n131          7.4         2.8          6.1         1.9  virginica\n132          7.9         3.8          6.4         2.0  virginica\n133          6.4         2.8          5.6         2.2  virginica\n134          6.3         2.8          5.1         1.5  virginica\n135          6.1         2.6          5.6         1.4  virginica\n136          7.7         3.0          6.1         2.3  virginica\n137          6.3         3.4          5.6         2.4  virginica\n138          6.4         3.1          5.5         1.8  virginica\n139          6.0         3.0          4.8         1.8  virginica\n140          6.9         3.1          5.4         2.1  virginica\n141          6.7         3.1          5.6         2.4  virginica\n142          6.9         3.1          5.1         2.3  virginica\n143          5.8         2.7          5.1         1.9  virginica\n144          6.8         3.2          5.9         2.3  virginica\n145          6.7         3.3          5.7         2.5  virginica\n146          6.7         3.0          5.2         2.3  virginica\n147          6.3         2.5          5.0         1.9  virginica\n148          6.5         3.0          5.2         2.0  virginica\n149          6.2         3.4          5.4         2.3  virginica\n150          5.9         3.0          5.1         1.8  virginica\n\n\n\nprint entire data set out.\ndoes not show much information."
  },
  {
    "objectID": "slides/07-package.html#tibbles-display-better",
    "href": "slides/07-package.html#tibbles-display-better",
    "title": "R/Python Data Frames for Data Science \n",
    "section": "Tibbles Display Better",
    "text": "Tibbles Display Better\n\n\nas_tibble() turns a data frame or matrix into a tibble.\n\n\n(iris_tbl &lt;- as_tibble(iris))  ## check iris_tbl in your R console\n\n# A tibble: 150 × 5\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n         &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;fct&gt;  \n1          5.1         3.5          1.4         0.2 setosa \n2          4.9         3            1.4         0.2 setosa \n3          4.7         3.2          1.3         0.2 setosa \n4          4.6         3.1          1.5         0.2 setosa \n5          5           3.6          1.4         0.2 setosa \n6          5.4         3.9          1.7         0.4 setosa \n# ℹ 144 more rows\n\n\n\nOnly shows the first couple of rows.\nPrints data size and column type.\n\n\nOnly shows the first 10 rows and all the columns that fit on one screen. This makes it easier to work with large data.\nPrints data size and column type.\nControl the default appearance, like options(tibble.print_max = n, tibble.print_min = m): if there are more than \\(n\\) rows, print only the first \\(m\\) rows.\n\nhttps://stackoverflow.com/questions/36848785/how-do-i-reset-all-options-arguments-to-their-default-values"
  },
  {
    "objectID": "slides/07-package.html#subsets-of-basedata.frame-may-not-be-data-frames",
    "href": "slides/07-package.html#subsets-of-basedata.frame-may-not-be-data-frames",
    "title": "R/Python Data Frames for Data Science \n",
    "section": "Subsets of base::data.frame May Not be Data Frames",
    "text": "Subsets of base::data.frame May Not be Data Frames\n\nSometimes [] returns a data frame and sometimes it just returns a vector.\n\n\n\n\ndf &lt;- data.frame(x = 1:3, \n                 y = 3:1, \n                 z = LETTERS[1:3])\ndf[, 1:2]\n\n  x y\n1 1 3\n2 2 2\n3 3 1\n\nclass(df[, 1:2])\n\n[1] \"data.frame\"\n\n\n\ndf[, 1]\n\n[1] 1 2 3\n\nclass(df[, 1])\n\n[1] \"integer\"\n\n\n\n\n\nTreat the df as a list. How do we grab the 1st column and preserve its data frame type?\n\n\n\ndf[1]\n\n  x\n1 1\n2 2\n3 3\n\n\n\n\n\n\nRemember we can use [] to subset a data frame. Right?\ndf[, 1, drop=FALSE]"
  },
  {
    "objectID": "slides/07-package.html#subsets-of-tibbles-are-tibbles",
    "href": "slides/07-package.html#subsets-of-tibbles-are-tibbles",
    "title": "R/Python Data Frames for Data Science \n",
    "section": "Subsets of Tibbles Are Tibbles",
    "text": "Subsets of Tibbles Are Tibbles\n\n\n\n[] always returns another tibble.\n\n\ndf_tbl &lt;- tibble(x = 1:2, y = 2:1)\ndf_tbl[, 1]\n\n# A tibble: 2 × 1\n      x\n  &lt;int&gt;\n1     1\n2     2\n\ndf_tbl[1]\n\n# A tibble: 2 × 1\n      x\n  &lt;int&gt;\n1     1\n2     2\n\n\n\nclass(df_tbl[, 1])\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\nclass(df_tbl[1])\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\n\n\n\n$ and [[]] return a vector.\n\n\ndf_tbl$x\n\n[1] 1 2\n\nclass(df_tbl$x) \n\n[1] \"integer\"\n\n\n\n\ndf_tbl[[1]]\n\n[1] 1 2\n\nclass(df_tbl[[1]])  \n\n[1] \"integer\"\n\n\n\n\n\n\nTibbles are quite strict about subsetting"
  },
  {
    "objectID": "slides/07-package.html#tibbles-never-do-partial-matching",
    "href": "slides/07-package.html#tibbles-never-do-partial-matching",
    "title": "R/Python Data Frames for Data Science \n",
    "section": "Tibbles Never Do Partial Matching",
    "text": "Tibbles Never Do Partial Matching\n\n\n\nData frames do partial matching\nTreat name “a” as “abc”!\n\n\n(df &lt;- data.frame(abc = 1))\n\n  abc\n1   1\n\ndf$a\n\n[1] 1\n\n\n\n\n\nTibbles never do partial matching\nName “a” cannot be recognized!\n\n\n(tib &lt;- tibble(abc = 1))\n\n# A tibble: 1 × 1\n    abc\n  &lt;dbl&gt;\n1     1\n\ntib$a\n\nWarning: Unknown or uninitialised column: `a`.\n\n\nNULL"
  },
  {
    "objectID": "slides/07-package.html#tibbles-can-have-complex-entries",
    "href": "slides/07-package.html#tibbles-can-have-complex-entries",
    "title": "R/Python Data Frames for Data Science \n",
    "section": "Tibbles Can Have Complex Entries",
    "text": "Tibbles Can Have Complex Entries\n\n\n\nData frame: Columns can’t be defined using other created variables.\n\n\ndata.frame(x = 1:5, \n           y = 1:5, \n           z = x + 3)\n# object 'x' not found\n\n\n\nTibble: Allow to refer to created variables.\n\n\ntibble(x = 1:5, \n       y = 1:5, \n       z = x + 3)\n\n# A tibble: 5 × 3\n      x     y     z\n  &lt;int&gt; &lt;int&gt; &lt;dbl&gt;\n1     1     1     4\n2     2     2     5\n3     3     3     6\n4     4     4     7\n5     5     5     8\n\n\n\n\n\nColumns need to be atomic vectors of numbers, strings, or logical values\nCan have more complex objects, such as lists or functions."
  },
  {
    "objectID": "slides/07-package.html#pipes",
    "href": "slides/07-package.html#pipes",
    "title": "R/Python Data Frames for Data Science \n",
    "section": "Pipes",
    "text": "Pipes\n\nThe pipe %&gt;% comes from the magrittr package of tidyverse.\n\n\n\nR (4.1+) has native base pipe operator |&gt;. Tools &gt; Global Options &gt; Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nFor simple cases |&gt; and %&gt;% behave identically. The base pipe is recommended because we can use |&gt; anywhere anytime in R, even we don’t use tidyverse.\n\n\n\n\nhttps://r4ds.hadley.nz/data-transform.html#sec-the-pipe"
  },
  {
    "objectID": "slides/07-package.html#what-and-how-to-use-pipe",
    "href": "slides/07-package.html#what-and-how-to-use-pipe",
    "title": "R/Python Data Frames for Data Science \n",
    "section": "What and How to Use Pipe",
    "text": "What and How to Use Pipe\n\nTo add the pipe, use keyboard shortcut Ctrl/Cmd + Shift + M\nThe pipe sends the result of the left side of the pipe to be the first argument of the function on the right side of the pipe.\n\n\n\n16 |&gt; sqrt() |&gt; log2()\n\n[1] 2\n\nlog2(sqrt(16))\n\n[1] 2\n\n## We can define other arguments as if the first argument is already defined\n16 |&gt; sqrt() |&gt; log(base = 2)\n\n[1] 2"
  },
  {
    "objectID": "slides/07-package.html#why-pipe-operator",
    "href": "slides/07-package.html#why-pipe-operator",
    "title": "R/Python Data Frames for Data Science \n",
    "section": "Why Pipe Operator?",
    "text": "Why Pipe Operator?\n\nNested vs. Sequential-piped\nMore natural and easier-to-read structure\n\n\n\n\n\n\nSource: https://www.andrewheiss.com/\n\n\n\n\n\nNested vs. Sequential-piped\nWriting it out using pipes give it a more natural and easier-to-read structure.\nYou can think about the following sequence of actions - wake up, get out of bed, get dressed, and leave house.\nExpressed as a set of nested functions in R would look like\nWriting it out using pipes give it a more natural and easier to read structure (if you think so)\nLike if-else statements, people don’t like too many nested layers. We can easily get lost about what is actually doing.\nUsing pipe operator, we have a clear sequential order, and all the actions or functions will be shown at the beginning of each line, making the code easier to read."
  },
  {
    "objectID": "slides/07-package.html#section-6",
    "href": "slides/07-package.html#section-6",
    "title": "R/Python Data Frames for Data Science \n",
    "section": "",
    "text": "08-Tibbles and Pipes \nIn lab.qmd ## Lab 8 section,\n\nCompare and contrast the following operations on a data.frame and equivalent tibble. What are the differences? Please comment.\n\n\n\n\ndf &lt;- data.frame(abc = 1:2, \n                 xyz = c(\"a\", \"b\"))\n# list method\ndf$x\ndf[[2]]\ndf[\"xyz\"]\ndf[c(\"abc\", \"xyz\")]\n# matrix method\ndf[, 2]\ndf[, \"xyz\"]\ndf[, c(\"abc\", \"xyz\")]\n\n\n\ntib &lt;- tibble(abc = 1:2, \n              xyz = c(\"a\", \"b\"))\n# list method\ntib$x\ntib[[2]]\ntib[\"xyz\"]\ntib[c(\"abc\", \"xyz\")]\n# matrix method\ntib[, 2]\ntib[, \"xyz\"]\ntib[, c(\"abc\", \"xyz\")]\n\n\n\n\nUse |&gt; to first select last 12 rows of iris data set using tail(), then provides summary statistics on its columns using summary().\n\n\n\n\n[1] \"a\" \"b\"\n\n\n[1] \"a\" \"b\"\n\n\n  xyz\n1   a\n2   b\n\n\n  abc xyz\n1   1   a\n2   2   b\n\n\n[1] \"a\" \"b\"\n\n\n[1] \"a\" \"b\"\n\n\n  abc xyz\n1   1   a\n2   2   b\n\n\n\n\nNULL\n\n\n[1] \"a\" \"b\"\n\n\n# A tibble: 2 × 1\n  xyz  \n  &lt;chr&gt;\n1 a    \n2 b    \n\n\n# A tibble: 2 × 2\n    abc xyz  \n  &lt;int&gt; &lt;chr&gt;\n1     1 a    \n2     2 b    \n\n\n# A tibble: 2 × 1\n  xyz  \n  &lt;chr&gt;\n1 a    \n2 b    \n\n\n# A tibble: 2 × 1\n  xyz  \n  &lt;chr&gt;\n1 a    \n2 b    \n\n\n# A tibble: 2 × 2\n    abc xyz  \n  &lt;int&gt; &lt;chr&gt;\n1     1 a    \n2     2 b"
  },
  {
    "objectID": "slides/07-package.html#pandas",
    "href": "slides/07-package.html#pandas",
    "title": "R/Python Data Frames for Data Science \n",
    "section": "Pandas",
    "text": "Pandas\n\nLike tidyverse in R, pandas is a Python library that provides data structures, manipulation and analysis tools for data science.\n\n\nimport numpy as np\nimport pandas as pd"
  },
  {
    "objectID": "slides/07-package.html#pandas-data-frame",
    "href": "slides/07-package.html#pandas-data-frame",
    "title": "R/Python Data Frames for Data Science \n",
    "section": "Pandas Data Frame",
    "text": "Pandas Data Frame\n\nCreate a data frame from a dictionary\n\n\ndata = {\"math\": [99, 65, 87], \"stats\": [92, 48, 88], \"cs\": [50, 88, 94]}\n\ndf = pd.DataFrame(data)\nprint(df) \n\n   math  stats  cs\n0    99     92  50\n1    65     48  88\n2    87     88  94\n\n\n\n\nRow and column names\n\n\ndf.index = [\"s1\", \"s2\", \"s3\"]\ndf.columns = [\"Math\", \"Stat\", \"CS\"]\ndf\n\n    Math  Stat  CS\ns1    99    92  50\ns2    65    48  88\ns3    87    88  94"
  },
  {
    "objectID": "slides/07-package.html#subsetting-columns",
    "href": "slides/07-package.html#subsetting-columns",
    "title": "R/Python Data Frames for Data Science \n",
    "section": "Subsetting Columns",
    "text": "Subsetting Columns\n\n\n\n\n\n\nWarning\n\n\n\n\nIn Python, [] returns Series, [[]] returns DataFrame!\nIn R, [] returns tibble, [[]] returns vector!\n\n\n\n\n\n\n\n\n\n## Series\ndf[\"Math\"]\n\ns1    99\ns2    65\ns3    87\nName: Math, dtype: int64\n\ntype(df[\"Math\"])\n\n&lt;class 'pandas.core.series.Series'&gt;\n\n\n\n\n\n# ## DataFrame\ndf[[\"Math\"]]\n\n    Math\ns1    99\ns2    65\ns3    87\n\ntype(df[[\"Math\"]])\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\n\n\n\ndf[[\"Math\", \"CS\"]]\n\n    Math  CS\ns1    99  50\ns2    65  88\ns3    87  94\n\n\n\n\nisinstance(df[[“Math”]], pd.DataFrame)"
  },
  {
    "objectID": "slides/07-package.html#subsetting-rows-dataframe.iloc",
    "href": "slides/07-package.html#subsetting-rows-dataframe.iloc",
    "title": "R/Python Data Frames for Data Science \n",
    "section": "Subsetting Rows DataFrame.iloc",
    "text": "Subsetting Rows DataFrame.iloc\n\n\ninteger-location based indexing for selection by position\n\n\n\n\ndf \n\n    Math  Stat  CS\ns1    99    92  50\ns2    65    48  88\ns3    87    88  94\n\n\n\n## first row Series\ndf.iloc[0] \n\nMath    99\nStat    92\nCS      50\nName: s1, dtype: int64\n\n\n\n## first row DataFrame\ndf.iloc[[0]]\n\n    Math  Stat  CS\ns1    99    92  50\n\n\n\n\n## first 2 rows\ndf.iloc[[0, 1]]\n\n    Math  Stat  CS\ns1    99    92  50\ns2    65    48  88\n\n\n\n## 1st and 3rd row\ndf.iloc[[True, False, True]]\n\n    Math  Stat  CS\ns1    99    92  50\ns3    87    88  94"
  },
  {
    "objectID": "slides/07-package.html#subsetting-rows-and-columns-dataframe.iloc",
    "href": "slides/07-package.html#subsetting-rows-and-columns-dataframe.iloc",
    "title": "R/Python Data Frames for Data Science \n",
    "section": "Subsetting Rows and Columns DataFrame.iloc\n",
    "text": "Subsetting Rows and Columns DataFrame.iloc\n\n\n\n\ndf \n\n    Math  Stat  CS\ns1    99    92  50\ns2    65    48  88\ns3    87    88  94\n\n\n\n## (1, 3) row and (1, 3) col\ndf.iloc[[0, 2], [0, 2]]\n\n    Math  CS\ns1    99  50\ns3    87  94\n\n\n\n## all rows and 1st col\ndf.iloc[:, [True, False, False]]\n\n    Math\ns1    99\ns2    65\ns3    87\n\n\n\n\ndf.iloc[0:2, 1:3]\n\n    Stat  CS\ns1    92  50\ns2    48  88"
  },
  {
    "objectID": "slides/07-package.html#subsetting-rows-and-columns-dataframe.loc",
    "href": "slides/07-package.html#subsetting-rows-and-columns-dataframe.loc",
    "title": "R/Python Data Frames for Data Science \n",
    "section": "Subsetting Rows and Columns DataFrame.loc\n",
    "text": "Subsetting Rows and Columns DataFrame.loc\n\nAccess a group of rows and columns by label(s)\n\n\n\ndf \n\n    Math  Stat  CS\ns1    99    92  50\ns2    65    48  88\ns3    87    88  94\n\n\n\ndf.loc['s1', \"CS\"]\n\n50\n\n\n\n## all rows and 1st col\ndf.loc['s1':'s3', [True, False, False]]\n\n    Math\ns1    99\ns2    65\ns3    87\n\n\n\n\ndf.loc['s2', ['Math', 'Stat']]\n\nMath    65\nStat    48\nName: s2, dtype: int64"
  },
  {
    "objectID": "slides/07-package.html#obtain-a-single-cell-value-dataframe.iat-dataframe.at",
    "href": "slides/07-package.html#obtain-a-single-cell-value-dataframe.iat-dataframe.at",
    "title": "R/Python Data Frames for Data Science \n",
    "section": "Obtain a Single Cell Value DataFrame.iat/ DataFrame.at\n",
    "text": "Obtain a Single Cell Value DataFrame.iat/ DataFrame.at\n\n\n\n\ndf \n\n    Math  Stat  CS\ns1    99    92  50\ns2    65    48  88\ns3    87    88  94\n\n\n\ndf.iat[1, 2]\n\n88\n\n\n\ndf.iloc[0].iat[1]\n\n92\n\n\n\n\ndf.at['s2', 'Stat']\n\n48\n\n\n\ndf.loc['s1'].at['Stat']\n\n92"
  },
  {
    "objectID": "slides/07-package.html#new-columns-dataframe.insert-and-new-rows-pd.concat",
    "href": "slides/07-package.html#new-columns-dataframe.insert-and-new-rows-pd.concat",
    "title": "R/Python Data Frames for Data Science \n",
    "section": "New Columns DataFrame.insert and New Rows pd.concat\n",
    "text": "New Columns DataFrame.insert and New Rows pd.concat\n\n\n\n\ndf \n\n    Math  Stat  CS\ns1    99    92  50\ns2    65    48  88\ns3    87    88  94\n\n\n\ndf.insert(loc = 2, \n          column = \"Chem\", \n          value = [77, 89, 76])\ndf\n\n    Math  Stat  Chem  CS\ns1    99    92    77  50\ns2    65    48    89  88\ns3    87    88    76  94\n\n\n\n\n\ndf1 = pd.DataFrame({\n    \"Math\": 88, \n    \"Stat\": 99, \n    \"Chem\": 0, \n    \"CS\": 100\n    }, index = ['s4'])\n\n\npd.concat(objs = [df, df1])\n\n    Math  Stat  Chem   CS\ns1    99    92    77   50\ns2    65    48    89   88\ns3    87    88    76   94\ns4    88    99     0  100\n\n\n\n\n\n\npd.concat(objs = [df, df1], \n          ignore_index = True)"
  },
  {
    "objectID": "slides/07-package.html#numpy-for-arraysmatrices",
    "href": "slides/07-package.html#numpy-for-arraysmatrices",
    "title": "R/Python Data Frames for Data Science \n",
    "section": "NumPy for arrays/matrices",
    "text": "NumPy for arrays/matrices\n\nrange(0, 5, 1) # a seq of number from 0 to 4 with increment of 1\n\nrange(0, 5)\n\nlist(range(0, 5, 1))\n\n[0, 1, 2, 3, 4]\n\n\n\n\nThe array object in NumPy is of class ndarray.\nUse np.array() to create a NumPy array.\n\n\nimport numpy as np\narr = np.array(range(0, 5, 1)) ## One-dim array \narr\n\narray([0, 1, 2, 3, 4])\n\ntype(arr)\n\n&lt;class 'numpy.ndarray'&gt;\n\n\n\n\nNumPy is used to work with arrays/matrices"
  },
  {
    "objectID": "slides/07-package.html#d-array-vector-and-2d-array-matrix",
    "href": "slides/07-package.html#d-array-vector-and-2d-array-matrix",
    "title": "R/Python Data Frames for Data Science \n",
    "section": "1D Array (Vector) and 2D Array (Matrix)",
    "text": "1D Array (Vector) and 2D Array (Matrix)\n\n\nnp.arange: Efficient way to create a one-dim array of sequence of numbers\n\n\nnp.arange(2, 5)\n\narray([2, 3, 4])\n\nnp.arange(6, 0, -1)\n\narray([6, 5, 4, 3, 2, 1])\n\n\n\n\n2D array\n\n\nnp.array([[1, 2, 3], [4, 5, 6]])\n\narray([[1, 2, 3],\n       [4, 5, 6]])\n\n\n\nnp.array([[[1, 2, 3], [4, 5, 6]], [[1, 2, 3], [4, 5, 6]]])\n\narray([[[1, 2, 3],\n        [4, 5, 6]],\n\n       [[1, 2, 3],\n        [4, 5, 6]]])"
  },
  {
    "objectID": "slides/07-package.html#np.reshape",
    "href": "slides/07-package.html#np.reshape",
    "title": "R/Python Data Frames for Data Science \n",
    "section": "np.reshape()",
    "text": "np.reshape()\n\narr2 = np.arange(8).reshape(2, 4)\narr2\n\narray([[0, 1, 2, 3],\n       [4, 5, 6, 7]])\n\narr2.shape  \n\n(2, 4)\n\n\n\narr2.ndim\n\n2\n\n\n\narr2.size\n\n8"
  },
  {
    "objectID": "slides/07-package.html#stacking-arrays",
    "href": "slides/07-package.html#stacking-arrays",
    "title": "R/Python Data Frames for Data Science \n",
    "section": "Stacking Arrays",
    "text": "Stacking Arrays\n\na = np.array([1, 2, 3, 4]).reshape(2, 2)\nb = np.array([5, 6, 7, 8]).reshape(2, 2)\n\nnp.vstack((a, b))\n\narray([[1, 2],\n       [3, 4],\n       [5, 6],\n       [7, 8]])\n\n\n\nnp.hstack((a, b))\n\narray([[1, 2, 5, 6],\n       [3, 4, 7, 8]])"
  },
  {
    "objectID": "slides/07-package.html#section-9",
    "href": "slides/07-package.html#section-9",
    "title": "R/Python Data Frames for Data Science \n",
    "section": "",
    "text": "09-NumPy and pandas \nIn lab.qmd ## Lab 9 section, create a Python pandas.DataFrame equivalent to the R tibble\n\ntibble(x = 1:5, y = 5:1, z = LETTERS[1:5])\n\n# A tibble: 5 × 3\n      x     y z    \n  &lt;int&gt; &lt;int&gt; &lt;chr&gt;\n1     1     5 A    \n2     2     4 B    \n3     3     3 C    \n4     4     2 D    \n5     5     1 E    \n\n\n\nimport numpy as np\nimport pandas as pd\ndic = {'__': np.arange(__, __), \n       '__': np.arange(__, __, __),\n       '__': [, , , , ]}\npd._____________(dic)"
  },
  {
    "objectID": "slides/07-package.html#lab-bonus",
    "href": "slides/07-package.html#lab-bonus",
    "title": "R/Python Data Frames for Data Science \n",
    "section": "Lab Bonus!",
    "text": "Lab Bonus!\n\nHappy Ralentine’s Day! ❤️\n\n\nx &lt;- seq(0, 2*pi, by = 0.01)\nxhrt &lt;- 16 * sin(x) ^ 3\nyhrt &lt;- 13 * cos(x) - 5 * cos(2*x) - 2 * cos(3*x) - cos(4*x)\npar(mar = c(0, 0, 0, 0))\nplot(xhrt, yhrt, type = \"l\", axes = FALSE, xlab = \"\", ylab = \"\")\npolygon(xhrt, yhrt, col = \"red\", border = NA)\npoints(c(10,-10, -15, 15), c(-10, -10, 10, 10), pch = 169, font = 5)\ntext(0, 0, \"Happy Valentine's Day!\", font = 2, cex = 2, col = \"pink\")"
  },
  {
    "objectID": "slides/07-package.html#lab-bonus-1",
    "href": "slides/07-package.html#lab-bonus-1",
    "title": "R/Python Data Frames for Data Science \n",
    "section": "Lab Bonus!",
    "text": "Lab Bonus!\n\nHappy Pylentine’s Day! ❤️\n\n\nlines = []\nmsg = \"~Happy Valentine's Day!~\"\nfor y in range(15, -15, -1):\n    line = \"\"\n    for x in range(-30, 30):\n        f = ((x * 0.05) ** 2 + (y * 0.1) ** 2 - 1) ** 3 - (x * 0.05) ** 2 * (y * 0.1) ** 3\n        line += msg[(x - y) % len(msg)] if f &lt;= 0 else \" \"\n    lines.append(line)\n\nprint(\"\\n\".join(lines))"
  },
  {
    "objectID": "slides/07-package.html#resources",
    "href": "slides/07-package.html#resources",
    "title": "R/Python Data Frames for Data Science \n",
    "section": "Resources",
    "text": "Resources\n\ntibble\npipes\nNumPy\npandas\n\n\n\n\n\nmath3570-s25.github.io/website"
  },
  {
    "objectID": "slides/05-quarto.html#sharing-data-science-products-using-quarto",
    "href": "slides/05-quarto.html#sharing-data-science-products-using-quarto",
    "title": "Quarto 📖",
    "section": "Sharing Data Science Products using Quarto",
    "text": "Sharing Data Science Products using Quarto\n\n\nRemember that in DS, our ultimate goal is share our data science outputs and communicate with others.\nToday, we are going to learn Quarto that is an amazing tool for generating various different kinds of data science output."
  },
  {
    "objectID": "slides/05-quarto.html#what-and-why-full-reproducibility",
    "href": "slides/05-quarto.html#what-and-why-full-reproducibility",
    "title": "Quarto 📖",
    "section": "What and Why – Full Reproducibility",
    "text": "What and Why – Full Reproducibility\n\n\n\n\n[What] data science publishing system\nUse a single Quarto file (.qmd) to\n\nweave together narrative text and code\n\nproduce elegantly formatted outputs: word/pdf, webpages, blogs, books, etc.\n\n\n\n[Why] Fully reproducible reports\n\nHave code, results, and text in the same document\nResults are generated from the source code, and your documents are automatically updated if your data or code changed.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWHAT\nRemember in the last stage of DS, we need to communicate our DS results with others.\nqmd is a very useful communication tool that integrates prose/words, code, and analysis results.\nWHY\nResults are generated from the source code, and your documents are automatically updated if your data changed.\nSo if your data or code changed, or you need to redo your analysis or rerun your algorithm, you don’t need to actually redo your analysis and copy all of your numbers, tables and figures generated from your code and paste them manually to your Word or Powerpoint file.\nSince your code, results, and text are all in one qmd file, if your data change, your results will be automatically updated with that change. No more copy and paste.\nThis greatly saves lots of time. Also, it reduces the chance of making mistakes of copying and pasting, and increases reproducibility of your study, meaning that your code can produce exactly the same result shown in your document.\nLiterate Programming"
  },
  {
    "objectID": "slides/05-quarto.html#section-1",
    "href": "slides/05-quarto.html#section-1",
    "title": "Quarto 📖",
    "section": "",
    "text": "I found an error in the data and added two more cases. Find the attached the modified excel. Can you redo the analysis?\n\nExcel to R\nRe-Make the graphs and re-run all the analysis\nCopy and paste every updated output from R to your document This is an non-reproducible way fo doing data science.\n\nBut there is another way, a better way, a reproducible way."
  },
  {
    "objectID": "slides/05-quarto.html#why-quarto-various-types-of-output",
    "href": "slides/05-quarto.html#why-quarto-various-types-of-output",
    "title": "Quarto 📖",
    "section": "Why Quarto – Various Types of Output",
    "text": "Why Quarto – Various Types of Output\n\nSupport dozens of static and dynamic/interactive output formats!\n\n\n\n\n\n\n\n\n\n\n\nOne more reason to use Quarto is qmd can generate various types of output!\nIt can produce a PDF, blog, HTML. It can generate slides, website, dashboard, word document, e-books. You name it!\nSo once you learn this Rmarkdown, you can prepare any type of output you want for different purposes. You can prepare a paper for submitting it to a journal, prepare slides for your presentation, prepare a website/dashboard for data science results.\nIt’s really handy! In fact, the slides I make for this course are all qmd files."
  },
  {
    "objectID": "slides/05-quarto.html#moving-between-formats-straightforward",
    "href": "slides/05-quarto.html#moving-between-formats-straightforward",
    "title": "Quarto 📖",
    "section": "Moving Between Formats Straightforward",
    "text": "Moving Between Formats Straightforward\n\n\nHTML Document\n\n datascience.qmd\n\ntitle: \"Data Science\"\nformat: html\n\n\nPresentation Slides\n\n datascience.qmd\n\ntitle: \"Data Science\"\nformat: revealjs\n\n\n\nWebsite\n\n _quarto.yml\n\nproject:\n  type: website\n\nwebsite: \n  navbar: \n    left:\n      - datascience.qmd\n\n\n\n–&gt; a lesson in document form  –&gt; the same content in presentation form  –&gt; the same content on a page in a website,\nand you can see that all that needed to change going between these formats is a few lines in the yaml. Nothing in the content part of my document. No slide breaks to remove, no citation style to change, no headings to re-level. This ease of transition has freed up time to focus my time on content, and that, folks, is the dream!"
  },
  {
    "objectID": "slides/05-quarto.html#why-quarto1-integrate-multiple-languages",
    "href": "slides/05-quarto.html#why-quarto1-integrate-multiple-languages",
    "title": "Quarto 📖",
    "section": "Why Quarto1 – Integrate Multiple Languages",
    "text": "Why Quarto1 – Integrate Multiple Languages\n\nQuarto is actually a command line interface that can render .qmd files into different output formats using commands in terminal."
  },
  {
    "objectID": "slides/05-quarto.html#quarto-is-built-on-pandoc",
    "href": "slides/05-quarto.html#quarto-is-built-on-pandoc",
    "title": "Quarto 📖",
    "section": "Quarto Is Built on Pandoc\n",
    "text": "Quarto Is Built on Pandoc\n\n\nR uses knitr and Python/Julia uses Jupyter to evaluate our code and turn qmd into md file.\n\n\n\nSo what does Quarto do so amazingly for us?\nWhen we hit Knit, your qmd first uses the knitr package to execute and translate our code, and then creates a new markdown document which includes the code and its output.\nThe markdown file is then processed by a document converter called pandoc which is responsible for creating various document format you like.\nThe entire process looks and sounds complicated, and indeed it’s complicated. But qmd makes it simple. All we need is to click on the Knit button, and qmd does everything for us."
  },
  {
    "objectID": "slides/05-quarto.html#why-quarto-comfort-of-your-own-workspace",
    "href": "slides/05-quarto.html#why-quarto-comfort-of-your-own-workspace",
    "title": "Quarto 📖",
    "section": "Why Quarto – Comfort of Your Own Workspace",
    "text": "Why Quarto – Comfort of Your Own Workspace"
  },
  {
    "objectID": "slides/05-quarto.html#why-quarto-simple-markdown-syntax-for-text",
    "href": "slides/05-quarto.html#why-quarto-simple-markdown-syntax-for-text",
    "title": "Quarto 📖",
    "section": "Why Quarto – Simple Markdown Syntax for Text",
    "text": "Why Quarto – Simple Markdown Syntax for Text\nTo generate a PDF report, you prefer writing this with 24 lines…\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnother reason to use Quarto is that its syntax is simple.\nWe can generate this PDF report including code and figures using this concise qmd file on the right."
  },
  {
    "objectID": "slides/05-quarto.html#why-quarto-simple-markdown-syntax-for-text-1",
    "href": "slides/05-quarto.html#why-quarto-simple-markdown-syntax-for-text-1",
    "title": "Quarto 📖",
    "section": "Why Quarto – Simple Markdown Syntax for Text",
    "text": "Why Quarto – Simple Markdown Syntax for Text\nOr this with 250 lines!?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can also generate the same PDF report using this document processing format.\nWhich one you prefer?\nDoes anyone know what tool is used for generating the PDF? It’s called LaTex.\nYou can see the qmd file is cleaner and much more concise."
  },
  {
    "objectID": "slides/05-quarto.html#markdown",
    "href": "slides/05-quarto.html#markdown",
    "title": "Quarto 📖",
    "section": "Markdown",
    "text": "Markdown\n\n\n\nQuarto is based on markdown, a markup language that is widely used to generate HTML pages.\nMarkdown is a lightweight and easy-to-use syntax for styling the writing on the GitHub platform.\nGo through basic (Pandoc’s) Markdown syntax together, and you can learn more at:\n\nMarkdown Tutorial\nMastering Markdown GitHub Guides\nMarkdown Guide\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn my opinion, comparing to HTML, Markdown format is more friendly and easier to learn."
  },
  {
    "objectID": "slides/05-quarto.html#quarto-file-plain-text-file-with-extension-.qmd",
    "href": "slides/05-quarto.html#quarto-file-plain-text-file-with-extension-.qmd",
    "title": "Quarto 📖",
    "section": "Quarto file = plain text file with extension .qmd\n",
    "text": "Quarto file = plain text file with extension .qmd\n\n---\ntitle: \"ggplot2 demo\"\ndate: \"1/25/2025\"\nformat: html\n---\n\n## Cars\nThere is a relationship between *miles per gallon* and *displacement*.\n\n```{r}\nmpg |&gt; ggplot(aes(x = displ, y = hwy)) + \n  geom_point()\n```\n\n\n\n\n\nYAML Header (“YAML Ain’t Markup Language”)\n---\nkey: value\n---\n\n\nThe first part is the YAML header, which is surrounded by a pair of three dashes.\nYAML is a human readable language that is commonly used in configuration files of programs.\nHere, YAML header defines metadata of the document, for example, title, date, and output format.\n\n\n\n\n\n\n\nMarkdown Text\n\n\nThe second part is text.\nAnd as we’ve discussed, the syntax for text is Markdown. We’ll learn some basic syntax later.\n\n\n\n\n\n\n\nCode Chunk\n\n```{r}\n## code right here\n```\n\n\n\nThe third main part of a qmd document is the so-called code chunk. which is surrounded by a pair of three backticks.\nThe code written in code chunks will be run once you compile your qmd file, and any output generated by your code will be printed out in the final document. All right!\nAny questions"
  },
  {
    "objectID": "slides/05-quarto.html#section-2",
    "href": "slides/05-quarto.html#section-2",
    "title": "Quarto 📖",
    "section": "",
    "text": "02-Quarto File\n\nGo to your GitHub repo lab-yourusername. Clone it to your Posit Cloud as a project in 2025-Spring-Math-3570 workspace.\nOpen the file lab.qmd.\nChange author in YAML.\n\n\nClick on  or Ctrl/Cmd + Shift + K to produce a HTML document.\nHow can we show the current date every time we compile the file? [Hint:] Check your hw00. Compile your document and make sure the date shows up.\n\n\nHow do we fold the code so that the document is shorter? Describe it in ## Lab 2: Quarto\nOnce done, commit with message “02-quarto” and push it to GitHub.\n\n\n\nClick on the inverted triangle right next to render to produce a PDF/Word document.\n\nr Sys.Date()\ndate: “2025-01-28”\ndate: today"
  },
  {
    "objectID": "slides/05-quarto.html#text-formatting",
    "href": "slides/05-quarto.html#text-formatting",
    "title": "Quarto 📖",
    "section": "Text Formatting",
    "text": "Text Formatting\n\n\n\n\n\n\nMarkdown Syntax\nOutput\n\n\n\n*italics* and **bold**\n\nitalics and bold\n\n\n\nsuperscript^2^ / subscript~2~\nsuperscript2 / subscript2\n\n\n\n~~strikethrough~~\nstrikethrough\n\n\n`verbatim code`\nverbatim code\n\n\n&gt; here is the quote\n\nhere is the quote"
  },
  {
    "objectID": "slides/05-quarto.html#headings",
    "href": "slides/05-quarto.html#headings",
    "title": "Quarto 📖",
    "section": "Headings",
    "text": "Headings\n\n\n\n\n\n\nMarkdown Syntax\nOutput\n\n\n\n# Header 1\nHeader 1\n\n\n## Header 2\nHeader 2\n\n\n### Header 3\nHeader 3\n\n\n#### Header 4\nHeader 4\n\n\n##### Header 5\nHeader 5\n\n\n###### Header 6\nHeader 6"
  },
  {
    "objectID": "slides/05-quarto.html#lists",
    "href": "slides/05-quarto.html#lists",
    "title": "Quarto 📖",
    "section": "Lists",
    "text": "Lists\n\n\n\n\n\n\n\nMarkdown Syntax\nOutput\n\n\n\n* unordered list\n    + sub-item 1\n    + sub-item 2\n        - sub-sub-item 1\n\n\nunordered list\n\nsub-item 1\n\nsub-item 2\n\nsub-sub-item 1\n\n\n\n\n\n\n\n*   item 2\n    &lt;new line&gt;\n    Continued (indent 4 spaces)\n\n\nitem 2\nContinued (indent 4 spaces)\n\n\n\n\n1. ordered list\n2. item 2\n    i) sub-item 1\n         A.  sub-sub-item 1\n\nordered list\n\nitem 2\n\n\nsub-item 1\n\nsub-sub-item 1\n\n\n\n\n\n\n\n\n\nAt least two spaces\n\nLists in Quarto require an entire blank line above the list.\n\nwefjwrg - list - abc"
  },
  {
    "objectID": "slides/05-quarto.html#math-and-links",
    "href": "slides/05-quarto.html#math-and-links",
    "title": "Quarto 📖",
    "section": "Math and Links",
    "text": "Math and Links\n\n\nMarkdown syntax\ninline-math: $A = r^{2}$\n\n\nmath-block: \n\n$$A = r^{2}$$\n\n&lt;https://www.google.com &gt; \n [Google link](https://www.google.com)\n\nOutput\ninline-math: \\(A = r^{2}\\) math-block: \\[A = r^{2}\\] https://www.google.comGoogle link"
  },
  {
    "objectID": "slides/05-quarto.html#tables",
    "href": "slides/05-quarto.html#tables",
    "title": "Quarto 📖",
    "section": "Tables",
    "text": "Tables\n\n\n| Right | Left | Default | Center |\n|------:|:-----|---------|:------:|\n|   12  |  12  |    12   |    12  |\n|  123  |  123 |   123   |   123  |\n|    1  |    1 |     1   |     1  |\n\n\n\nRight\nLeft\nDefault\nCenter\n\n\n\n12\n12\n12\n12\n\n\n123\n123\n123\n123\n\n\n1\n1\n1\n1"
  },
  {
    "objectID": "slides/05-quarto.html#source-vs.-visual-mode",
    "href": "slides/05-quarto.html#source-vs.-visual-mode",
    "title": "Quarto 📖",
    "section": "Source vs. Visual Mode",
    "text": "Source vs. Visual Mode\nSource Mode\n\n\n\n\n\n\n\n\nVisual Mode (What You See Is What You Mean (WYSIWYM))"
  },
  {
    "objectID": "slides/05-quarto.html#data-as-table",
    "href": "slides/05-quarto.html#data-as-table",
    "title": "Quarto 📖",
    "section": "Data as Table",
    "text": "Data as Table\nknitr::kable() can turn dataframes into tables.\n\nhead(mtcars) |&gt; \n    knitr::kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmpg\ncyl\ndisp\nhp\ndrat\nwt\nqsec\nvs\nam\ngear\ncarb\n\n\n\nMazda RX4\n21.0\n6\n160\n110\n3.90\n2.62\n16.5\n0\n1\n4\n4\n\n\nMazda RX4 Wag\n21.0\n6\n160\n110\n3.90\n2.88\n17.0\n0\n1\n4\n4\n\n\nDatsun 710\n22.8\n4\n108\n93\n3.85\n2.32\n18.6\n1\n1\n4\n1\n\n\nHornet 4 Drive\n21.4\n6\n258\n110\n3.08\n3.21\n19.4\n1\n0\n3\n1\n\n\nHornet Sportabout\n18.7\n8\n360\n175\n3.15\n3.44\n17.0\n0\n0\n3\n2\n\n\nValiant\n18.1\n6\n225\n105\n2.76\n3.46\n20.2\n1\n0\n3\n1"
  },
  {
    "objectID": "slides/05-quarto.html#section-3",
    "href": "slides/05-quarto.html#section-3",
    "title": "Quarto 📖",
    "section": "",
    "text": "03-Markdown \n\nBack to your lab.qmd. In ## Lab 3: Markdown section, add a self-introduction paragraph containing a header, bold and italic text.\n\nAdd another paragraph that contains\n\nlisted items\na hyperlink\na blockquote\nmath expression\n\n\nOnce done, commit with message “03-markdown” and push it to GitHub."
  },
  {
    "objectID": "slides/05-quarto.html#anatomy-of-a-code-chunk",
    "href": "slides/05-quarto.html#anatomy-of-a-code-chunk",
    "title": "Quarto 📖",
    "section": "Anatomy of a Code Chunk",
    "text": "Anatomy of a Code Chunk\n\n\n\n```{r}\n#| label: car-stuff\n#| eval: false\nmtcars |&gt; \n  distinct(cyl)\n```\n\n\n\n```{python}\n#| label: string\n#| eval: false\nx = 'hello, python world!'\nprint(x.split(' '))\n```\n\n\n\nHas 3x backticks ``` on each end\nTo insert a code chunk,\n\n\n\n\n\n\n\n\n\n\nAlt + Ctrl + I (Win) ; Option + Cmd + I (Mac)\nIndicate engine (r) between curly braces {r}\nPlace options behind the #| (hashpipe): #| option: value\nTools &gt; Modify Keyboard Shortcuts &gt; Filter… &gt; Insert Chunk Python &gt; Option + Cmd + P (or any key binding you like)"
  },
  {
    "objectID": "slides/05-quarto.html#option-echo",
    "href": "slides/05-quarto.html#option-echo",
    "title": "Quarto 📖",
    "section": "Option echo\n",
    "text": "Option echo\n\n\nIf you simply want code highlighting, you can use 3x backticks + the language ```r\n\n\n\n```r\nhead(mtcars)\n```\n\n\nWhich returns the below but is not executed since there aren’t {} around the language:\nhead(mtcars)\n\n\n\n\nIf you instead want to see source code and evaluate it, you could use echo: true where echo: false would instead hide the code but still evaluate it.\n\n```{r}\n#| echo: true\n1 + 1\n```\n\n\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "slides/05-quarto.html#chunk-options",
    "href": "slides/05-quarto.html#chunk-options",
    "title": "Quarto 📖",
    "section": "Chunk Options",
    "text": "Chunk Options\n\nThe following table summarises which types of output each option suppresses:\n\n\n\n\n\n\n\n\n\n\n\n\nOption\nRun code\nShow code\nOutput\nPlots\nMessages\nWarnings\n\n\n\neval: false\nx\n\nx\nx\nx\nx\n\n\ninclude: false\n\nx\nx\nx\nx\nx\n\n\necho: false\n\nx\n\n\n\n\n\n\nresults: \"hide\"\n\n\nx\n\n\n\n\n\nfig-show: \"hide\"\n\n\n\nx\n\n\n\n\nmessage: false\n\n\n\n\nx\n\n\n\nwarning: false\n\n\n\n\n\nx\n\n\n\n\nCheck Code Cells: Knitr for more chunk options.\n\n\nHere shows some code chunk options.\nThe table summarises which types of output each option suppresses.\nSo eval = FALSE means that the code is not run, but the code is still shown in the compiled document. Because the code is not run, there will be no output, no plots, no messages and no warnings.\nWhen include = FALSE, the code will be run, but nothing will be included in the final document.\nWhen echo = FALSE, the code will not be shown in the document, but it will be run, and all results will be shown in the document.\nYou get the idea, right.\nSo results controls output, fig.show controls plots, message and warning control if messages and warnings are shown.\nThere are so many chunk options out there. If you want to learn more, definitely check this knitr website. OK"
  },
  {
    "objectID": "slides/05-quarto.html#global-options-execute",
    "href": "slides/05-quarto.html#global-options-execute",
    "title": "Quarto 📖",
    "section": "Global Options: execute",
    "text": "Global Options: execute\n\nShould be specified within the execute key.\n\n\n---\nexecute: \n  echo: false\n  eval: false\n---\n\nCheck HTML Options &gt; Execution for more execution options!\n\n```{r}\n#| label: setup\n#| include: false\n# don't show code unless we explicitly set echo = TRUE\nknitr::opts_chunk$set(echo = FALSE)\n```\n\n\nknitr::opts_chunk$set() sets default options for all chunks."
  },
  {
    "objectID": "slides/05-quarto.html#images",
    "href": "slides/05-quarto.html#images",
    "title": "Quarto 📖",
    "section": "Images",
    "text": "Images\nBasic markdown syntax:\n![Maru](images/05-quarto/maru1.jpg)\n\nMaru"
  },
  {
    "objectID": "slides/05-quarto.html#figures-w-code",
    "href": "slides/05-quarto.html#figures-w-code",
    "title": "Quarto 📖",
    "section": "Figures w/ code",
    "text": "Figures w/ code\n\n```{r}\n#| out-width: 40%\n#| fig-align: right\n\nknitr::include_graphics(\"images/05-quarto/maru1.jpg\")\n```\n\n\nWidth of the plot in the output document, which can be different from its physical fig-width, i.e., plots can be scaled in the output document. When used without a unit, the unit is assumed to be pixels. However, any of the following unit identifiers can be used: px, cm, mm, in, inch and %, for example, 3in, 8cm, 300px or 50%."
  },
  {
    "objectID": "slides/05-quarto.html#including-plots",
    "href": "slides/05-quarto.html#including-plots",
    "title": "Quarto 📖",
    "section": "Including Plots",
    "text": "Including Plots\n\nMany chunk options for figures and images start with fig-, for example fig-width, fig-height, fig-show, etc.\n\n\n\n\n\n```{r}\n#| eval: false\n#| fig-cap: \"Fig. 1: Car stuff\"\n\nplot(x = cars$speed, y = cars$dist)\n```\n\n\n\n\n\n\nFig. 1: Car stuff"
  },
  {
    "objectID": "slides/05-quarto.html#divs-and-spans",
    "href": "slides/05-quarto.html#divs-and-spans",
    "title": "Quarto 📖",
    "section": "Divs and Spans",
    "text": "Divs and Spans\nThis is text with [special]{style=\"color:red\"} formatting.\nThis is text with special formatting.\n\n\n::: {style=\"color:red\"}\nThis content can be styled with a border\n:::\n\nThis content can be styled with a border\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;!-- ::: {style=\"border-left:10px solid red\"} --&gt;\n&lt;!-- This content can be styled with a border --&gt;\n&lt;!-- ::: --&gt;\nDivs start with a fence containing at least three consecutive colons plus some attributes. The attributes may optionally be followed by another string of consecutive colons. The Div ends with another line containing a string of at least three consecutive colons. The Div should be separated by blank lines from preceding and following blocks."
  },
  {
    "objectID": "slides/05-quarto.html#subfigures-fenced-div-class",
    "href": "slides/05-quarto.html#subfigures-fenced-div-class",
    "title": "Quarto 📖",
    "section": "Subfigures Fenced div Class",
    "text": "Subfigures Fenced div Class\n::: {#fig-maru layout-ncol=2}\n\n![Loaf](images/05-quarto/maru2.jpg){#fig-loaf width=\"250px\"}\n![Lick](images/05-quarto/maru3.jpg){#fig-lick width=\"250px\"}\nTwo states of Maru\n\n:::\n\n\n\n\n\n\n\n\n\n(a) Loaf\n\n\n\n\n\n\n\n\n\n(b) Lick\n\n\n\n\n\n\nFigure 1: Two states of Maru"
  },
  {
    "objectID": "slides/05-quarto.html#inline-code",
    "href": "slides/05-quarto.html#inline-code",
    "title": "Quarto 📖",
    "section": "Inline Code",
    "text": "Inline Code\n\nInside your text you can include code with the syntax `r your-r-code`.\nFor example, `r 4 + 5` would output 9 in your text.\n\n\nhead(cars)\n\n  speed dist\n1     4    2\n2     4   10\n3     7    4\n4     7   22\n5     8   16\n6     9   10\n\nnum_cars &lt;- nrow(cars)\n\n\n\n\nCode in Quarto\nThere are `r num_cars` rows in the cars dataset. Four plus five is `r 4 + 5`\n\nOutput\nThere are 50 rows in the cars dataset. Four plus five is 9\n\n\n\nWe;ve learned that Inside your text you can include code, and inline code is created with backticks.\nIn fact, the inline code can actually execute code, if we put r in the first place.\nFor example, 9 would output 9 in your text."
  },
  {
    "objectID": "slides/05-quarto.html#section-4",
    "href": "slides/05-quarto.html#section-4",
    "title": "Quarto 📖",
    "section": "",
    "text": "04-Code Chunk \n\n\nIn lab.qmd ## Lab 4: Code Chunk, use code chunks to\n\ninclude an image with knitr::include_graphics(\"URL or file path\") https://raw.githubusercontent.com/rstudio/hex-stickers/master/PNG/ggplot2.png\ninclude a plot plot(mtcars$disp, mtcars$mpg)\nShow dataset mtcars as a table using knitr::kable()\n\n\nDo some inline code calculation like `r ncol(mtcars)`, `r log(100, base = 10) + sqrt(4)`.\nAdd option fig-height: 4, fig-width: 6 and fig-align: right to the chunk for your plot. What are the changes?\nHow do we set global chunk options to not show the code in every chunk in the document?\nOnce done, commit with message “04-codechunk” and push your work to GitHub.\n\n\n\nRun the following in the console # {r} # #| eval: false # z &lt;- 2 # z * 3 # Then, add the following chunk in your lab02-rmarkdown.qmd and re-knit it. # {r} # #| eval: false # z * 3 # What happens?\nThe environment of your Quarto document is separate from the Console! Remember this, and expect it to bite you a few times as you’re learning to work with Quarto!\nfig.dim = c(8, 6) means fig.width = 8 and fig.height = 6 in inches\nout.width=“50%”: half of the width of the image container"
  },
  {
    "objectID": "slides/05-quarto.html#quarto-skills-to-the-next-level",
    "href": "slides/05-quarto.html#quarto-skills-to-the-next-level",
    "title": "Quarto 📖",
    "section": "Quarto Skills to the Next Level",
    "text": "Quarto Skills to the Next Level\n\nQuarto Website\nGet Started with Quarto\nR for Data Science Ch-28 Quarto\n\n\n\n\n\nmath3570-s25.github.io/website"
  },
  {
    "objectID": "slides/06-syntax.html#run-code-in-console",
    "href": "slides/06-syntax.html#run-code-in-console",
    "title": "Basic R  and Python \n",
    "section": "Run Code in Console",
    "text": "Run Code in Console\n\n\n\n\nreticulate::repl_python() to Python.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nquit or exit to switch back to R."
  },
  {
    "objectID": "slides/06-syntax.html#arithmetic-and-logical-operators",
    "href": "slides/06-syntax.html#arithmetic-and-logical-operators",
    "title": "Basic R  and Python \n",
    "section": "Arithmetic and Logical Operators",
    "text": "Arithmetic and Logical Operators\n\n\n\n\n\n\n\n\n\n\n\n2 + 3 / (5 * 4) ^ 2\n\n[1] 2.01\n\n5 == 5.00\n\n[1] TRUE\n\n# 5 and 5L are of the same value too\n# 5 is of type double; 5L is integer\n5 == 5L\n\n[1] TRUE\n\ntypeof(5L)\n\n[1] \"integer\"\n\n!TRUE == FALSE\n\n[1] TRUE\n\n\n\n\n\n\n\n\n\n\n\n\n\n2 + 3 / (5 * 4) ** 2\n\n2.0075\n\n5 == 5.00\n\nTrue\n\n5 == int(5)\n\nTrue\n\ntype(int(5))\n\n&lt;class 'int'&gt;\n\nnot True == False\n\nTrue\n\n\n\n\n\nrepl_python()"
  },
  {
    "objectID": "slides/06-syntax.html#arithmetic-and-logical-operators-1",
    "href": "slides/06-syntax.html#arithmetic-and-logical-operators-1",
    "title": "Basic R  and Python \n",
    "section": "Arithmetic and Logical Operators",
    "text": "Arithmetic and Logical Operators\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nType coercion: When doing AND/OR comparisons, all nonzero values are treated as TRUE and 0 as FALSE.\n\n-5 | 0\n\n[1] TRUE\n\n1 & 1\n\n[1] TRUE\n\n2 | 0\n\n[1] TRUE\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nbool() converts nonzero numbers to True and zero to False\n\n-5 | 0\n\n-5\n\n1 & 1\n\n1\n\nbool(2) | bool(0)\n\nTrue"
  },
  {
    "objectID": "slides/06-syntax.html#math-functions",
    "href": "slides/06-syntax.html#math-functions",
    "title": "Basic R  and Python \n",
    "section": "Math Functions",
    "text": "Math Functions\n\n\n\n\n\n\n\n\n\n\nMath functions in R are built-in.\n\nsqrt(144)\n\n[1] 12\n\nexp(1)\n\n[1] 2.72\n\nsin(pi/2)\n\n[1] 1\n\nlog(32, base = 2)\n\n[1] 5\n\nabs(-7)\n\n[1] 7\n\n\n\n# R comment\n\n\n\n\n\n\n\n\n\n\n\nNeed to import math library in Python.\n\nimport math\nmath.sqrt(144)\n\n12.0\n\nmath.exp(1)\n\n2.718281828459045\n\nmath.sin(math.pi/2)\n\n1.0\n\nmath.log(32, 2)\n\n5.0\n\nabs(-7)\n\n7\n\n\n\n# python comment"
  },
  {
    "objectID": "slides/06-syntax.html#variables-and-assignment",
    "href": "slides/06-syntax.html#variables-and-assignment",
    "title": "Basic R  and Python \n",
    "section": "Variables and Assignment",
    "text": "Variables and Assignment\n\n\n\n\n\n\n\n\n\n\nUse &lt;- to do assignment. Why\n\n## we create an object, value 5, \n## and call it x, which is a variable\nx &lt;- 5\nx\n\n[1] 5\n\n(x &lt;- x + 6)\n\n[1] 11\n\nx == 5\n\n[1] FALSE\n\nlog(x)\n\n[1] 2.4\n\n\n\n\n\n\n\n\n\n\n\n\nUse = to do assignment.\n\nx = 5\nx\n\n5\n\nx = x + 6\nx\n\n11\n\nx == 5\n\nFalse\n\nmath.log(x)\n\n2.3978952727983707"
  },
  {
    "objectID": "slides/06-syntax.html#object-types",
    "href": "slides/06-syntax.html#object-types",
    "title": "Basic R  and Python \n",
    "section": "Object Types",
    "text": "Object Types\n\n\n\n\n\n\n\n\n\n\ncharacter, double, integer and logical.\n\ntypeof(5)\n\n[1] \"double\"\n\n\n\ntypeof(5L)\n\n[1] \"integer\"\n\n\n\ntypeof(\"I_love_data_science!\")\n\n[1] \"character\"\n\n\n\ntypeof(1 &gt; 3)\n\n[1] \"logical\"\n\n\n\nis.double(5L)\n\n[1] FALSE\n\n\n\n\n\n\n\n\n\n\n\n\nstr, float, int and bool.\n\ntype(5.0)\n\n&lt;class 'float'&gt;\n\ntype(5)\n\n&lt;class 'int'&gt;\n\ntype(\"I_love_data_science!\")\n\n&lt;class 'str'&gt;\n\ntype(1 &gt; 3)\n\n&lt;class 'bool'&gt;\n\ntype(5) is float\n\nFalse\n\n\n\n\n\npython long (long integers, they can also be represented in octal and hexadecimal)"
  },
  {
    "objectID": "slides/06-syntax.html#section-2",
    "href": "slides/06-syntax.html#section-2",
    "title": "Basic R  and Python \n",
    "section": "",
    "text": "Variable defined previously is a scalar value, or in fact a (atomic) vector of length one."
  },
  {
    "objectID": "slides/06-syntax.html#atomic-vector",
    "href": "slides/06-syntax.html#atomic-vector",
    "title": "Basic R  and Python \n",
    "section": "(Atomic) Vector",
    "text": "(Atomic) Vector\n\nTo create a vector, use c(), short for concatenate or combine.\n\nAll elements of a vector must be of the same type.\n\n\n\n\n(dbl_vec &lt;- c(1, 2.5, 4.5)) \n\n[1] 1.0 2.5 4.5\n\n(int_vec &lt;- c(1L, 6L, 10L))\n\n[1]  1  6 10\n\n## TRUE and FALSE can be written as T and F\n(log_vec &lt;- c(TRUE, FALSE, F))  \n\n[1]  TRUE FALSE FALSE\n\n(chr_vec &lt;- c(\"pretty\", \"girl\"))\n\n[1] \"pretty\" \"girl\"  \n\n\n\n\n## check how many elements in a vector\nlength(dbl_vec) \n\n[1] 3\n\n## check a compact description of \n## any R data structure\nstr(dbl_vec) \n\n num [1:3] 1 2.5 4.5"
  },
  {
    "objectID": "slides/06-syntax.html#sequence-of-numbers",
    "href": "slides/06-syntax.html#sequence-of-numbers",
    "title": "Basic R  and Python \n",
    "section": "Sequence of Numbers",
    "text": "Sequence of Numbers\n\nUse : to create a sequence of integers.\nUse seq() to create a sequence of numbers of type double with more options. \n\n\n\n(vec &lt;- 1:5) \n\n[1] 1 2 3 4 5\n\ntypeof(vec)\n\n[1] \"integer\"\n\n# a sequence of numbers from 1 to 10 with increment 2\n(seq_vec &lt;- seq(from = 1, to = 10, by = 2))\n\n[1] 1 3 5 7 9\n\ntypeof(seq_vec)\n\n[1] \"double\""
  },
  {
    "objectID": "slides/06-syntax.html#operations-on-vectors",
    "href": "slides/06-syntax.html#operations-on-vectors",
    "title": "Basic R  and Python \n",
    "section": "Operations on Vectors",
    "text": "Operations on Vectors\n\nWe can do any operations on vectors as we do on a scalar variable (vector of length 1).\n\n\n\n\n# Create two vectors\nv1 &lt;- c(3, 8)\nv2 &lt;- c(4, 100) \n\n## All operations happen element-wisely\n# Vector addition\nv1 + v2\n\n[1]   7 108\n\n# Vector subtraction\nv1 - v2\n\n[1]  -1 -92\n\n\n\n\n# Vector multiplication\nv1 * v2\n\n[1]  12 800\n\n# Vector division\nv1 / v2\n\n[1] 0.75 0.08\n\nsqrt(v2)\n\n[1]  2 10"
  },
  {
    "objectID": "slides/06-syntax.html#recycling-of-vectors",
    "href": "slides/06-syntax.html#recycling-of-vectors",
    "title": "Basic R  and Python \n",
    "section": "Recycling of Vectors",
    "text": "Recycling of Vectors\n\nIf we apply arithmetic operations to two vectors of unequal length, the elements of the shorter vector will be recycled to complete the operations.  \n\n\n\nv1 &lt;- c(3, 8, 4, 5)\n# The following 2 operations are the same\nv1 * 2\n\n[1]  6 16  8 10\n\nv1 * c(2, 2, 2, 2)\n\n[1]  6 16  8 10\n\nv3 &lt;- c(4, 11)\nv1 + v3  ## v3 becomes c(4, 11, 4, 11) when doing the operation\n\n[1]  7 19  8 16"
  },
  {
    "objectID": "slides/06-syntax.html#subsetting-vectors",
    "href": "slides/06-syntax.html#subsetting-vectors",
    "title": "Basic R  and Python \n",
    "section": "Subsetting Vectors",
    "text": "Subsetting Vectors\n\nTo extract element(s) in a vector, we use a pair of brackets [] with element indexing.\nThe indexing starts with 1.\n\n\n\n\nv1\n\n[1] 3 8 4 5\n\nv2\n\n[1]   4 100\n\n## The 3rd element\nv1[3] \n\n[1] 4\n\n\n\n\nv1[c(1, 3)]\n\n[1] 3 4\n\nv1[1:2]\n\n[1] 3 8\n\n## extract all except a few elements\n## put a negative sign before the vector of \n## indices\nv1[-c(2, 3)] \n\n[1] 3 5"
  },
  {
    "objectID": "slides/06-syntax.html#factor-1",
    "href": "slides/06-syntax.html#factor-1",
    "title": "Basic R  and Python \n",
    "section": "Factor",
    "text": "Factor\n\nA vector of type factor can be ordered in a meaningful way. Create a factor by factor().\n\n\n## Create a factor from a character vector using function factor()\n(fac &lt;- factor(c(\"med\", \"high\", \"low\")))\n\n[1] med  high low \nLevels: high low med\n\n\n\n\nIt is a type of integer, not character. 😲 🙄\n\n\ntypeof(fac)  ## The type is integer.\n\n[1] \"integer\"\n\nstr(fac)  ## The integers show the level each element in vector fac belongs to.\n\n Factor w/ 3 levels \"high\",\"low\",\"med\": 3 1 2\n\n\n\n\n\norder_fac &lt;- factor(c(\"med\", \"high\", \"low\"),\n                    levels = c(\"low\", \"med\", \"high\"))\nstr(order_fac)\n\n Factor w/ 3 levels \"low\",\"med\",\"high\": 2 3 1\n\n\nlevels(fac) ## Each level represents an integer, ordered from the vector alphabetically."
  },
  {
    "objectID": "slides/06-syntax.html#list-generic-vectors",
    "href": "slides/06-syntax.html#list-generic-vectors",
    "title": "Basic R  and Python \n",
    "section": "List (Generic Vectors)",
    "text": "List (Generic Vectors)\n\n\nLists are different from (atomic) vectors: Elements can be of any type, including lists.\nConstruct a list by using list().\n\n\n\n\n## a list of 3 elements of different types\nx_lst &lt;- list(idx = 1:3, \n              \"a\", \n              c(TRUE, FALSE))\n\n\n\n$idx\n[1] 1 2 3\n\n[[2]]\n[1] \"a\"\n\n[[3]]\n[1]  TRUE FALSE\n\n\n\n\nstr(x_lst)\n\nList of 3\n $ idx: int [1:3] 1 2 3\n $    : chr \"a\"\n $    : logi [1:2] TRUE FALSE\n\nnames(x_lst)\n\n[1] \"idx\" \"\"    \"\"   \n\nlength(x_lst)\n\n[1] 3"
  },
  {
    "objectID": "slides/06-syntax.html#subsetting-a-list",
    "href": "slides/06-syntax.html#subsetting-a-list",
    "title": "Basic R  and Python \n",
    "section": "Subsetting a List",
    "text": "Subsetting a List\n\n\nReturn an  element  of a list\n\n## subset by name (a vector)\nx_lst$idx  \n\n[1] 1 2 3\n\n## subset by indexing (a vector)\nx_lst[[1]]  \n\n[1] 1 2 3\n\ntypeof(x_lst$idx)\n\n[1] \"integer\"\n\n\n\n\nReturn a  sub-list  of a list\n\n## subset by name (still a list)\nx_lst[\"idx\"]  \n\n$idx\n[1] 1 2 3\n\n## subset by indexing (still a list)\nx_lst[1]  \n\n$idx\n[1] 1 2 3\n\ntypeof(x_lst[\"idx\"])\n\n[1] \"list\"\n\n\n\n\n\n\nThis is where we should pay more attention to. When we subset a list, it may return an element of the list, or it returns a sub-list of the list.\nLet’s see how it happens.\nThis is our x_lst. We can subset a list by name or by indexing.\nSuppose we want the first element of the list, we can get it by its name using x_lst$idx.\nWe can also obtain it by using indexing like x_lst[[1]] because we want the first element.\nNotice that the way we subset a list returns an integer vector, the real first element of the list, not a list.\nLet’s see another case on the right.\nWe can also subset by name using single pair of brackets, and put the name inside the brackets.\nOr we can subset by indexing, again using single pair of brackets.\nAnd you see what happened? The way we subset a list here returns a sub-list, not the element itself.\nSo please be careful when subsetting a list.\nIf you want a vector, use these ways. If you want to keep it as a list, use these ways."
  },
  {
    "objectID": "slides/06-syntax.html#section-3",
    "href": "slides/06-syntax.html#section-3",
    "title": "Basic R  and Python \n",
    "section": "",
    "text": "pepper packet pepper shaker"
  },
  {
    "objectID": "slides/06-syntax.html#section-4",
    "href": "slides/06-syntax.html#section-4",
    "title": "Basic R  and Python \n",
    "section": "",
    "text": "If list x is a train carrying objects, then x[[5]] is the object in car 5; x[4:6] is a train of cars 4-6.\n— @RLangTip, https://twitter.com/RLangTip/status/268375867468681216"
  },
  {
    "objectID": "slides/06-syntax.html#matrix-1",
    "href": "slides/06-syntax.html#matrix-1",
    "title": "Basic R  and Python \n",
    "section": "Matrix",
    "text": "Matrix\n\nA matrix is a two-dimensional analog of a vector with attribute dim.\nUse command matrix() to create a matrix.\n\n\n## Create a 3 by 2 matrix called mat\n(mat &lt;- matrix(data = 1:6, nrow = 3, ncol = 2)) \n\n     [,1] [,2]\n[1,]    1    4\n[2,]    2    5\n[3,]    3    6\n\ndim(mat); nrow(mat); ncol(mat)\n\n[1] 3 2\n\n\n[1] 3\n\n\n[1] 2\n\n\n\n\n     [,1] [,2]\n[1,]    1    2\n[2,]    3    4\n[3,]    5    6\n\n\n$dim\n[1] 3 2"
  },
  {
    "objectID": "slides/06-syntax.html#subsetting-a-matrix",
    "href": "slides/06-syntax.html#subsetting-a-matrix",
    "title": "Basic R  and Python \n",
    "section": "Subsetting a Matrix",
    "text": "Subsetting a Matrix\n\nUse the same indexing approach as vectors on rows and columns.\nUse comma , to separate row and column index.\n\nmat[2, 2] extracts the element of the second row and second column.\n\n\n\n\nmat\n\n     [,1] [,2]\n[1,]    1    4\n[2,]    2    5\n[3,]    3    6\n\n## all rows and 2nd column\n## leave row index blank\n## specify 2 in coln index\nmat[, 2]\n\n[1] 4 5 6\n\n\n\n\n## 2nd row and all columns\nmat[2, ] \n\n[1] 2 5\n\n## The 1st and 3rd rows and the 1st column\nmat[c(1, 3), 1] \n\n[1] 1 3"
  },
  {
    "objectID": "slides/06-syntax.html#binding-matrices",
    "href": "slides/06-syntax.html#binding-matrices",
    "title": "Basic R  and Python \n",
    "section": "Binding Matrices",
    "text": "Binding Matrices\n\ncbind() (binding matrices by adding columns)\nrbind() (binding matrices by adding rows)\nWhen matrices are combined by columns (rows), they should have the same number of rows (columns).\n\n\n\n\nmat\n\n     [,1] [,2]\n[1,]    1    4\n[2,]    2    5\n[3,]    3    6\n\nmat_c &lt;- matrix(data = c(7,0,0,8,2,6), \n                nrow = 3, ncol = 2)\n## should have the same number of rows\ncbind(mat, mat_c)  \n\n     [,1] [,2] [,3] [,4]\n[1,]    1    4    7    8\n[2,]    2    5    0    2\n[3,]    3    6    0    6\n\n\n\n\nmat_r &lt;- matrix(data = 1:4, \n                nrow = 2, \n                ncol = 2)\n## should have the same number of columns\nrbind(mat, mat_r)  \n\n     [,1] [,2]\n[1,]    1    4\n[2,]    2    5\n[3,]    3    6\n[4,]    1    3\n[5,]    2    4"
  },
  {
    "objectID": "slides/06-syntax.html#data-frame-the-most-common-way-of-storing-datasets",
    "href": "slides/06-syntax.html#data-frame-the-most-common-way-of-storing-datasets",
    "title": "Basic R  and Python \n",
    "section": "Data Frame: The Most Common Way of Storing Datasets",
    "text": "Data Frame: The Most Common Way of Storing Datasets\n\nA data frame is of type list of equal-length vectors, having a 2-dimensional structure.\nMore general than matrix: Different columns can have different types.\nUse data.frame() that takes named vectors as input “element”.\n\n\n\n\n## data frame w/ an dbl column named age\n## and char column named gender.\n(df &lt;- data.frame(age = c(19, 21, 40), \n                  gen = c(\"m\", \"f\", \"m\")))\n\n  age gen\n1  19   m\n2  21   f\n3  40   m\n\n## a data frame has a list structure\nstr(df)  \n\n'data.frame':   3 obs. of  2 variables:\n $ age: num  19 21 40\n $ gen: chr  \"m\" \"f\" \"m\"\n\n\n\n\n## must set column names\n## or they are ugly and non-recognizable\ndata.frame(c(19, 21, 40), c(\"m\", \"f\", \"m\")) \n\n  c.19..21..40. c..m....f....m..\n1            19                m\n2            21                f\n3            40                m"
  },
  {
    "objectID": "slides/06-syntax.html#properties-of-data-frames",
    "href": "slides/06-syntax.html#properties-of-data-frames",
    "title": "Basic R  and Python \n",
    "section": "Properties of Data Frames",
    "text": "Properties of Data Frames\nData frame has properties of matrix and list.\n\n\n\nnames(df)  ## df as a list\n\n[1] \"age\" \"gen\"\n\ncolnames(df)  ## df as a matrix\n\n[1] \"age\" \"gen\"\n\nlength(df) ## df as a list\n\n[1] 2\n\nncol(df) ## df as a matrix\n\n[1] 2\n\ndim(df) ## df as a matrix\n\n[1] 3 2\n\n\n\n\n## rbind() and cbind() can be used on df\ndf_r &lt;- data.frame(age = 10, \n                   gen = \"f\")\nrbind(df, df_r)\n\n  age gen\n1  19   m\n2  21   f\n3  40   m\n4  10   f\n\ndf_c &lt;- \n    data.frame(col = c(\"red\",\"blue\",\"gray\"))\n(df_new &lt;- cbind(df, df_c))\n\n  age gen  col\n1  19   m  red\n2  21   f blue\n3  40   m gray"
  },
  {
    "objectID": "slides/06-syntax.html#subsetting-a-data-frame",
    "href": "slides/06-syntax.html#subsetting-a-data-frame",
    "title": "Basic R  and Python \n",
    "section": "Subsetting a Data Frame",
    "text": "Subsetting a Data Frame\nCan use either list or matrix subsetting methods.\n\n\n\ndf_new\n\n  age gen  col\n1  19   m  red\n2  21   f blue\n3  40   m gray\n\n## Subset rows\ndf_new[c(1, 3), ]\n\n  age gen  col\n1  19   m  red\n3  40   m gray\n\n## select the row where age == 21\ndf_new[df_new$age == 21, ]\n\n  age gen  col\n2  21   f blue\n\n\n\n\n## Subset columns\n## like a list\ndf_new$age\n\n[1] 19 21 40\n\ndf_new[c(\"age\", \"gen\")]\n\n  age gen\n1  19   m\n2  21   f\n3  40   m\n\n## like a matrix\ndf_new[, c(\"age\", \"gen\")]\n\n  age gen\n1  19   m\n2  21   f\n3  40   m\n\n\n\n\n\n\n  age gen  col\n1  19   m  red\n3  40   m gray\n\n\n'data.frame':   3 obs. of  1 variable:\n $ age: num  19 21 40\n\n\n num [1:3] 19 21 40"
  },
  {
    "objectID": "slides/06-syntax.html#section-5",
    "href": "slides/06-syntax.html#section-5",
    "title": "Basic R  and Python \n",
    "section": "",
    "text": "05-R Data Type Summary \n\nIn lab.qmd Lab 5,\n\nCreate R objects vector v1, factor f2, list l3, matrix m4 and data frame d5.\nCheck typeof() and class() of those objects, and create a list having the output below.\n\n\n\n\n\nv1 &lt;- __________\nf2 &lt;- __________\nl3 &lt;- __________\nm4 &lt;- __________\nd5 &lt;- __________\nv &lt;- c(type = typeof(v1), class = class(v1))\nf &lt;- c(type = __________, class = _________)\nl &lt;- c(type = __________, class = _________)\nm &lt;- c(type = __________, class = _________)\nd &lt;- c(type = __________, class = _________)\n____(vec    =   v,\n     ______ = ___,\n     ______ = ___,\n     ______ = ___,\n     ______ = ___)\n\n\n\n\n$vec\n     type     class \n \"double\" \"numeric\" \n\n$fac\n     type     class \n\"integer\"  \"factor\" \n\n$lst\n  type  class \n\"list\" \"list\" \n\n$mat\n     type    class1    class2 \n\"integer\"  \"matrix\"   \"array\" \n\n$df\n        type        class \n      \"list\" \"data.frame\""
  },
  {
    "objectID": "slides/06-syntax.html#python-lists",
    "href": "slides/06-syntax.html#python-lists",
    "title": "Basic R  and Python \n",
    "section": "Python Lists",
    "text": "Python Lists\n\nPython has numbers and strings, but no built-in vector structure.\nTo create a sequence type of structure, we can use a list that can save several elements in an single object.\nTo create a list in Python, we use [].\n\n\n\n\nlst_num = [0, 2, 4] \nlst_num\n\n[0, 2, 4]\n\ntype(lst_num)\n\n&lt;class 'list'&gt;\n\nlen(lst_num)\n\n3\n\n\n\nList elements can have different types!\n\nlst = ['data', 'math', 34, True]\nlst\n\n['data', 'math', 34, True]"
  },
  {
    "objectID": "slides/06-syntax.html#subsetting-lists",
    "href": "slides/06-syntax.html#subsetting-lists",
    "title": "Basic R  and Python \n",
    "section": "Subsetting Lists",
    "text": "Subsetting Lists\n\n\n\nIndexing in Python always starts at 0!\n\n0: the 1st element\n\n\nlst\n\n['data', 'math', 34, True]\n\nlst[0]\n\n'data'\n\ntype(lst[0]) ## not a list\n\n&lt;class 'str'&gt;\n\n\n\n\n-1: the last element\n\n\nlst[-2]\n\n34\n\n\n\n\n\n[a:b]: the (a+1)-th to b-th elements\n\n\nlst[1:4]\n\n['math', 34, True]\n\ntype(lst[1:4]) ## a list\n\n&lt;class 'list'&gt;\n\n\n\n\n[a:]: elements from the (a+1)-th to the last\n\n\nlst[2:]\n\n[34, True]\n\n\n\n\n\nWhat does lst[0:1] return? Is it a list?\n\n\nWhat does lst[0:1] return? Is it a list?"
  },
  {
    "objectID": "slides/06-syntax.html#lists-are-mutable",
    "href": "slides/06-syntax.html#lists-are-mutable",
    "title": "Basic R  and Python \n",
    "section": "Lists are Mutable",
    "text": "Lists are Mutable\nLists are changed in place!\n\n\n\nlst[1]\n\n'math'\n\nlst[1] = \"stats\"\nlst\n\n['data', 'stats', 34, True]\n\n\n\n\nlst[2:] = [False, 77]\nlst\n\n['data', 'stats', False, 77]\n\n\n\n\nIf we change any element value in a list, the list itself will be changed as well."
  },
  {
    "objectID": "slides/06-syntax.html#list-operations-and-methods-list.method",
    "href": "slides/06-syntax.html#list-operations-and-methods-list.method",
    "title": "Basic R  and Python \n",
    "section": "List Operations and Methods list.method()\n",
    "text": "List Operations and Methods list.method()\n\n\n\n\n## Concatenation\nlst_num + lst\n\n[0, 2, 4, 'data', 'stats', False, 77]\n\n\n\n## Repetition\nlst_num * 3 \n\n[0, 2, 4, 0, 2, 4, 0, 2, 4]\n\n\n\n## Membership\n34 in lst\n\nFalse\n\n\n\n\n## Appends \"cat\" to lst\nlst.append(\"cat\")\nlst\n\n['data', 'stats', False, 77, 'cat']\n\n\n\n## Removes and returns last object from list\nlst.pop()\n\n'cat'\n\nlst\n\n['data', 'stats', False, 77]\n\n\n\n## Removes object from list\nlst.remove(\"stats\")\nlst\n\n['data', False, 77]\n\n\n\n## Reverses objects of list in place\nlst.reverse()\nlst\n\n[77, False, 'data']\n\n\n\n\nThis is a common syntax in Python. We start with a Pyhton object of some type, then type dot followed by any method specifically for this particular data type or structure for operations. list.pop(index)"
  },
  {
    "objectID": "slides/06-syntax.html#tuples",
    "href": "slides/06-syntax.html#tuples",
    "title": "Basic R  and Python \n",
    "section": "Tuples",
    "text": "Tuples\n\nTuples work exactly like lists except they are immutable, i.e., they can’t be changed in place.\nTo create a tuple, we use ().\n\n\n\n\ntup = ('data', 'math', 34, True)\ntup\n\n('data', 'math', 34, True)\n\ntype(tup)\n\n&lt;class 'tuple'&gt;\n\nlen(tup)\n\n4\n\n\n\n\ntup[2:]\n\n(34, True)\n\ntup[-2]\n\n34\n\n\n\ntup[1] = \"stats\"  ## does not work!\n# TypeError: 'tuple' object does not support item assignment\n\n\ntup\n\n('data', 'math', 34, True)\n\n\n\n\n‘tuple’ object does not support item assignment"
  },
  {
    "objectID": "slides/06-syntax.html#tuples-functions-and-methods",
    "href": "slides/06-syntax.html#tuples-functions-and-methods",
    "title": "Basic R  and Python \n",
    "section": "Tuples Functions and Methods",
    "text": "Tuples Functions and Methods\n\n# Converts a list into tuple\ntuple(lst_num)\n\n(0, 2, 4)\n\n\n\n# number of occurance of \"data\"\ntup.count(\"data\")\n\n1\n\n\n\n# first index of \"data\"\ntup.index(\"data\")\n\n0\n\n\n\n\n\n\n\n\nNote\n\n\n\nLists have more methods than tuples because lists are more flexible."
  },
  {
    "objectID": "slides/06-syntax.html#dictionaries",
    "href": "slides/06-syntax.html#dictionaries",
    "title": "Basic R  and Python \n",
    "section": "Dictionaries",
    "text": "Dictionaries\n\nA dictionary consists of key-value pairs.\nA dictionary is mutable, i.e., the values can be changed in place and more key-value pairs can be added.\nTo create a dictionary, we use {'key': value}.\nThe value can be accessed by the key in the dictionary.\n\n\ndic = {'Name': 'Ivy', 'Age': 7, 'Class': 'First'}\n\n\ndic['Age']\n\n7\n\n\n\ndic['age']  ## does not work\n\n\ndic['Age'] = 9\ndic['Class'] = 'Third'\ndic\n\n{'Name': 'Ivy', 'Age': 9, 'Class': 'Third'}"
  },
  {
    "objectID": "slides/06-syntax.html#properties-of-dictionaries",
    "href": "slides/06-syntax.html#properties-of-dictionaries",
    "title": "Basic R  and Python \n",
    "section": "Properties of Dictionaries",
    "text": "Properties of Dictionaries\n\nPython will use the last assignment!\n\n\ndic1 = {'Name': 'Ivy', 'Age': 7, 'Name': 'Liya'}\ndic1['Name']\n\n'Liya'\n\n\n\n\nKeys are unique and immutable.\nA key can be a tuple, but CANNOT be a list.\n\n\n## The first key is a tuple!\ndic2 = {('First', 'Last'): 'Ivy Lee', 'Age': 7}\ndic2[('First', 'Last')]\n\n'Ivy Lee'\n\n\n\n## does not work\ndic2 = {['First', 'Last']: 'Ivy Lee', 'Age': 7}\ndic2[['First', 'Last']]"
  },
  {
    "objectID": "slides/06-syntax.html#dictionary-methods",
    "href": "slides/06-syntax.html#dictionary-methods",
    "title": "Basic R  and Python \n",
    "section": "Dictionary Methods",
    "text": "Dictionary Methods\n\n\n{'Name': 'Ivy', 'Age': 9, 'Class': 'Third'}\n\n\n\ndic.keys() ## Returns list of dictionary dict's keys\n\ndict_keys(['Name', 'Age', 'Class'])\n\n\n\n\n\ndic.values() ## Returns list of dictionary dict's values\n\ndict_values(['Ivy', 9, 'Third'])\n\n\n\n\n\n\ndic.items() ## Returns a list of dict's (key, value) tuple pairs\n\ndict_items([('Name', 'Ivy'), ('Age', 9), ('Class', 'Third')])\n\n\n\n\n\n\n## Adds dictionary dic2's key-values pairs in to dic\ndic2 = {'Gender': 'female'}\ndic.update(dic2)\ndic\n\n{'Name': 'Ivy', 'Age': 9, 'Class': 'Third', 'Gender': 'female'}\n\n\n\n## Removes all elements of dictionary dict\ndic.clear()\ndic\n\n{}"
  },
  {
    "objectID": "slides/06-syntax.html#section-6",
    "href": "slides/06-syntax.html#section-6",
    "title": "Basic R  and Python \n",
    "section": "",
    "text": "06-Python Data Structure \nIn lab.qmd Lab 6,\n\nCreate a Python list and dictionary similar to the R list below.\n\n\nx_lst &lt;- list(idx = 1:3, \n              \"a\", \n              c(TRUE, FALSE))\n\nRemember to create Python code chunk\n\n```{Python}\n#| echo: true\n#| eval: false\n#| code-line-numbers: false\n\n```\n\nAny issue of this Python chunk?\nCommit and Push your work once you are done."
  },
  {
    "objectID": "slides/06-syntax.html#python-data-structures-for-data-science",
    "href": "slides/06-syntax.html#python-data-structures-for-data-science",
    "title": "Basic R  and Python \n",
    "section": "Python Data Structures for Data Science",
    "text": "Python Data Structures for Data Science\n\nPython built-in data structures are not specifically for data science.\nTo use more data science friendly functions and structures, such as array or data frame, Python relies on packages NumPy and pandas."
  },
  {
    "objectID": "slides/06-syntax.html#installing-numpy-and-pandas",
    "href": "slides/06-syntax.html#installing-numpy-and-pandas",
    "title": "Basic R  and Python \n",
    "section": "Installing NumPy and pandas*",
    "text": "Installing NumPy and pandas*\nIn your lab-yourusername project, run\n\nlibrary(reticulate)\nvirtualenv_create(\"myenv\")\n\n\nGo to Tools &gt; Global Options &gt; Python &gt; Select &gt; Virtual Environments"
  },
  {
    "objectID": "slides/06-syntax.html#installing-numpy-and-pandas-1",
    "href": "slides/06-syntax.html#installing-numpy-and-pandas-1",
    "title": "Basic R  and Python \n",
    "section": "Installing NumPy and pandas*",
    "text": "Installing NumPy and pandas*\nYou may need to restart R session. Do it, and in the new R session, run\n\nlibrary(reticulate)\npy_install(c(\"numpy\", \"pandas\", \"matplotlib\"))\n\n\nRun the following Python code, and make sure everything goes well.\n\nimport numpy as np\nimport pandas as pd\nv1 = np.array([3, 8])\nv1\n\narray([3, 8])\n\ndf = pd.DataFrame({\"col\": ['red', 'blue', 'green']})\ndf\n\n     col\n0    red\n1   blue\n2  green"
  },
  {
    "objectID": "slides/06-syntax.html#central-tendency-mean-and-median",
    "href": "slides/06-syntax.html#central-tendency-mean-and-median",
    "title": "Basic R  and Python \n",
    "section": "Central Tendency: Mean and Median",
    "text": "Central Tendency: Mean and Median\n\n\n\n\n\n\n\n\n\n\n\ndata &lt;- c(3,12,56,9,230,22)\nmean(data)\n\n[1] 55.3\n\nmedian(data)  \n\n[1] 17\n\n\n\n\n\n\n\n\n\n\n\n\n\ndata = np.array([3,12,56,9,230,22])\ntype(data)\n\n&lt;class 'numpy.ndarray'&gt;\n\nnp.mean(data)\n\n55.333333333333336\n\nnp.median(data)\n\n17.0\n\n\n\n\n\n\nThe (arithmetic) mean or average is adding up all of the values, then dividing by the total number of them.\nMean balances data Values.\nThe median is the middle value when data values are arranged from the lowest to highest.\nMean is sensitive to extreme values (outliers)."
  },
  {
    "objectID": "slides/06-syntax.html#variation",
    "href": "slides/06-syntax.html#variation",
    "title": "Basic R  and Python \n",
    "section": "Variation",
    "text": "Variation\n\n\n\n\n\n\n\n\n\n\n\nquantile(data, c(0.25, 0.5, 0.75)) \n\n  25%   50%   75% \n 9.75 17.00 47.50 \n\n\n\nvar(data)\n\n[1] 7677\n\nsd(data)\n\n[1] 87.6\n\n\n\nsummary(data)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n    3.0     9.8    17.0    55.3    47.5   230.0 \n\n\n\n\n\n\n\n\n\n\n\n\n\nnp.quantile(data,  [0.25, 0.5, 0.75])\n\narray([ 9.75, 17.  , 47.5 ])\n\n\n\nnp.var(data, ddof = 1)\n\n7676.666666666666\n\nnp.std(data, ddof = 1)\n\n87.61658899242008\n\n\n\ndf = pd.Series(data)\ndf.describe()\n\ncount      6.000000\nmean      55.333333\nstd       87.616589\nmin        3.000000\n25%        9.750000\n50%       17.000000\n75%       47.500000\nmax      230.000000\ndtype: float64\n\n\n\n\n\n\n\np-th percentile: a data value such that at most \\(p\\%\\) of the data values are below it and at most \\((1−p)\\%\\) of the values are above it.\n\nFirst Quartile (Q1): the 25-th percentile\n\nSecond Quartile (Q2): the 50-th percentile (Median)\n\nThird Quartile (Q3): the 75-th percentile\n\nInterquartile Range (IQR): Q3 - Q1\n\nIQR(data)\n\nq75, q25 = np.percentile(data, [75 ,25])\nq75 - q25\n\nDelta Degrees of Freedom."
  },
  {
    "objectID": "slides/06-syntax.html#r-plot",
    "href": "slides/06-syntax.html#r-plot",
    "title": "Basic R  and Python \n",
    "section": "R plot()\n",
    "text": "R plot()\n\n\n\n\nmtcars[1:15, 1:4]\n\n                    mpg cyl disp  hp\nMazda RX4          21.0   6  160 110\nMazda RX4 Wag      21.0   6  160 110\nDatsun 710         22.8   4  108  93\nHornet 4 Drive     21.4   6  258 110\nHornet Sportabout  18.7   8  360 175\nValiant            18.1   6  225 105\nDuster 360         14.3   8  360 245\nMerc 240D          24.4   4  147  62\nMerc 230           22.8   4  141  95\nMerc 280           19.2   6  168 123\nMerc 280C          17.8   6  168 123\nMerc 450SE         16.4   8  276 180\nMerc 450SL         17.3   8  276 180\nMerc 450SLC        15.2   8  276 180\nCadillac Fleetwood 10.4   8  472 205\n\n\n\n\nplot(x = mtcars$mpg, y = mtcars$hp, \n     xlab  = \"Miles per gallon\", \n     ylab = \"Horsepower\", \n     main = \"Scatter plot\", \n     col = \"red\", \n     pch = 5, las = 1)"
  },
  {
    "objectID": "slides/06-syntax.html#argument-pch",
    "href": "slides/06-syntax.html#argument-pch",
    "title": "Basic R  and Python \n",
    "section": "Argument pch",
    "text": "Argument pch\n\n\nThe defualt is pch = 1"
  },
  {
    "objectID": "slides/06-syntax.html#python-matplotlib.pyplot",
    "href": "slides/06-syntax.html#python-matplotlib.pyplot",
    "title": "Basic R  and Python \n",
    "section": "Python matplotlib.pyplot\n",
    "text": "Python matplotlib.pyplot\n\n\n\n\nCodemtcars = pd.read_csv('./data/mtcars.csv')\nmtcars.iloc[0:15,0:4]\n\n     mpg  cyl   disp   hp\n0   21.0    6  160.0  110\n1   21.0    6  160.0  110\n2   22.8    4  108.0   93\n3   21.4    6  258.0  110\n4   18.7    8  360.0  175\n5   18.1    6  225.0  105\n6   14.3    8  360.0  245\n7   24.4    4  146.7   62\n8   22.8    4  140.8   95\n9   19.2    6  167.6  123\n10  17.8    6  167.6  123\n11  16.4    8  275.8  180\n12  17.3    8  275.8  180\n13  15.2    8  275.8  180\n14  10.4    8  472.0  205\n\n\n\n\nimport matplotlib.pyplot as plt\nplt.scatter(x = mtcars.mpg, \n            y = mtcars.hp, \n            color = \"r\")\nplt.xlabel(\"Miles per gallon\")\nplt.ylabel(\"Horsepower\")\nplt.title(\"Scatter plot\")"
  },
  {
    "objectID": "slides/06-syntax.html#r-subplots",
    "href": "slides/06-syntax.html#r-subplots",
    "title": "Basic R  and Python \n",
    "section": "R Subplots",
    "text": "R Subplots\n\npar(mfrow = c(1, 2))\nplot(x = mtcars$mpg, y = mtcars$hp, xlab = \"mpg\")\nplot(x = mtcars$mpg, y = mtcars$wt, xlab = \"mpg\")"
  },
  {
    "objectID": "slides/06-syntax.html#python-subplots",
    "href": "slides/06-syntax.html#python-subplots",
    "title": "Basic R  and Python \n",
    "section": "Python Subplots",
    "text": "Python Subplots\n\n\n\nThe command plt.scatter() is used for creating one single plot.\nIf multiple subplots are wanted in one single call, one can use plt.subplots()\n\n\nfig, (ax1, ax2) = plt.subplots(1, 2)\nax1.scatter(x = mtcars.mpg, y = mtcars.hp)\nax2.scatter(x = mtcars.mpg, y = mtcars.wt)\nax1.set_xlabel(\"mpg\")\nax2.set_xlabel(\"mpg\")"
  },
  {
    "objectID": "slides/06-syntax.html#r-boxplot",
    "href": "slides/06-syntax.html#r-boxplot",
    "title": "Basic R  and Python \n",
    "section": "R boxplot()\n",
    "text": "R boxplot()\n\n\n\n\nboxplot(mpg ~ cyl, \n        data = mtcars, \n        col = c(\"blue\", \"green\", \"red\"), \n        las = 1, \n        horizontal = TRUE,\n        xlab = \"Miles per gallon\", \n        ylab = \"Number of cylinders\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nVisualizing relationships between numerical and categorical data, we can check side-by-side boxplots.\nFor example, if we want to check the data variation of (miles per gallon) for each number of cylinder, we can use boxplot() function.\nAnd inside the function, we use the formula mpg ~ cyl, and specify the dataset.\nThat is basically it. The rest of arguments are decorating your plot. They are optional."
  },
  {
    "objectID": "slides/06-syntax.html#python-boxplot",
    "href": "slides/06-syntax.html#python-boxplot",
    "title": "Basic R  and Python \n",
    "section": "Python boxplot()\n",
    "text": "Python boxplot()\n\n\nCodecyl_num = np.unique(mtcars.cyl)\ncyl_list = []\ncyl_list.append(mtcars[mtcars.cyl == cyl_num[0]].mpg)\ncyl_list.append(mtcars[mtcars.cyl == cyl_num[1]].mpg)\ncyl_list.append(mtcars[mtcars.cyl == cyl_num[2]].mpg)\n\n\n\nimport matplotlib.pyplot as plt\nplt.boxplot(cyl_list, vert=False, tick_labels=[4, 6, 8])\nplt.xlabel(\"Miles per gallon\")\nplt.ylabel(\"Number of cylinders\")"
  },
  {
    "objectID": "slides/06-syntax.html#r-hist",
    "href": "slides/06-syntax.html#r-hist",
    "title": "Basic R  and Python \n",
    "section": "R hist()\n",
    "text": "R hist()\n\n\n\nhist() decides the class intervals/with based on breaks. If not provided, R chooses one.\n\n\n\n\nhist(mtcars$wt, \n     breaks = 20, \n     col = \"#003366\", \n     border = \"#FFCC00\", \n     xlab = \"weights\", \n     main = \"Histogram of weights\",\n     las = 1)\n\n\n\n\n\n\n\n\n\n\n\n\n\nBesides color names, you can also use hex number to specify colors. Pretty handy."
  },
  {
    "objectID": "slides/06-syntax.html#python-hist",
    "href": "slides/06-syntax.html#python-hist",
    "title": "Basic R  and Python \n",
    "section": "Python hist()",
    "text": "Python hist()\n\n## by default bins=10\nplt.hist(mtcars.wt, \n         bins = 20, \n         color=\"#003366\",\n         edgecolor=\"#FFCC00\")\nplt.xlabel(\"weights\")\nplt.title(\"Histogram of weights\")"
  },
  {
    "objectID": "slides/06-syntax.html#r-barplot",
    "href": "slides/06-syntax.html#r-barplot",
    "title": "Basic R  and Python \n",
    "section": "R barplot()\n",
    "text": "R barplot()\n\n\n(counts &lt;- table(mtcars$gear)) \n\n\n 3  4  5 \n15 12  5 \n\n\n\nmy_bar &lt;- barplot(counts, \n                  main = \"Car Distribution\", \n                  xlab = \"Number of Gears\", \n                  las = 1)\ntext(x = my_bar, y = counts - 0.8, \n     labels = counts, \n     cex = 0.8)"
  },
  {
    "objectID": "slides/06-syntax.html#python-barplot",
    "href": "slides/06-syntax.html#python-barplot",
    "title": "Basic R  and Python \n",
    "section": "Python barplot()",
    "text": "Python barplot()\n\ncount_py = mtcars.value_counts('gear')\ncount_py\n\ngear\n3    15\n4    12\n5     5\nName: count, dtype: int64\n\n\n\nplt.bar([\"3\", \"4\", \"5\"], count_py)\nplt.xlabel(\"Number of Gears\")\nplt.title(\"Car Distribution\")"
  },
  {
    "objectID": "slides/06-syntax.html#r-pie",
    "href": "slides/06-syntax.html#r-pie",
    "title": "Basic R  and Python \n",
    "section": "R pie()\n",
    "text": "R pie()\n\n\n(percent &lt;- round(counts / sum(counts) * 100, 2))\n\n\n   3    4    5 \n46.9 37.5 15.6 \n\n(labels &lt;- paste0(3:5, \" gears: \", percent, \"%\"))\n\n[1] \"3 gears: 46.88%\" \"4 gears: 37.5%\"  \"5 gears: 15.62%\"\n\n\n\npie(x = counts, labels = labels,\n    main = \"Pie Chart\", \n    col = 2:4, \n    radius = 1)\n\n\n\nPie charts are used for categorical variables, especially when we want to know percentage of each category.\nThe first argument is the frequency table, and you can add labels to each category."
  },
  {
    "objectID": "slides/06-syntax.html#python-pie",
    "href": "slides/06-syntax.html#python-pie",
    "title": "Basic R  and Python \n",
    "section": "Python pie()\n",
    "text": "Python pie()\n\n\npercent = round(count_py / sum(count_py) * 100, 2)\ntexts = (percent.index.astype(str) + \" gears: \" + percent.astype(str) + \"%\").tolist()\n\n\nplt.pie(count_py, labels = texts, colors = ['r', 'g', 'b'])\nplt.title(\"Pie Charts\")"
  },
  {
    "objectID": "slides/06-syntax.html#r-2d-imaging-image",
    "href": "slides/06-syntax.html#r-2d-imaging-image",
    "title": "Basic R  and Python \n",
    "section": "R 2D Imaging: image()\n",
    "text": "R 2D Imaging: image()\n\n\nThe image() function displays the values in a matrix using color.\n\n\n\n\nmatrix(1:30, 6, 5)\n\n     [,1] [,2] [,3] [,4] [,5]\n[1,]    1    7   13   19   25\n[2,]    2    8   14   20   26\n[3,]    3    9   15   21   27\n[4,]    4   10   16   22   28\n[5,]    5   11   17   23   29\n[6,]    6   12   18   24   30\n\nimage(matrix(1:30, 6, 5))\n\n\n\n\n\n\n\n\n\n\n\n\nIn Python,\n\nCodematrix = np.arange(1, 31).reshape(5, 6)\nplt.imshow(matrix, cmap=\"viridis\", origin=\"lower\")\nplt.colorbar()\nplt.show()"
  },
  {
    "objectID": "slides/06-syntax.html#r-fieldsimage.plot",
    "href": "slides/06-syntax.html#r-fieldsimage.plot",
    "title": "Basic R  and Python \n",
    "section": "R fields::image.plot()\n",
    "text": "R fields::image.plot()\n\n\n\n\nlibrary(fields)\nstr(volcano)\n\n num [1:87, 1:61] 100 101 102 103 104 105 105 106 107 108 ...\n\nimage.plot(volcano)\n\n\n\n\n num [1:87, 1:61] 100 101 102 103 104 105 105 106 107 108 ..."
  },
  {
    "objectID": "slides/06-syntax.html#r-2d-imaging-example-volcano",
    "href": "slides/06-syntax.html#r-2d-imaging-example-volcano",
    "title": "Basic R  and Python \n",
    "section": "R 2D Imaging Example: Volcano",
    "text": "R 2D Imaging Example: Volcano"
  },
  {
    "objectID": "slides/06-syntax.html#r-3d-scatter-plot-scatterplot3d",
    "href": "slides/06-syntax.html#r-3d-scatter-plot-scatterplot3d",
    "title": "Basic R  and Python \n",
    "section": "R 3D scatter plot: scatterplot3d()\n",
    "text": "R 3D scatter plot: scatterplot3d()\n\n\n\n\nlibrary(scatterplot3d)\nscatterplot3d(x = mtcars$wt, \n              y = mtcars$disp, \n              z = mtcars$mpg, \n              main = \"3D Scatter Plot\", \n              xlab = \"Weights\", \n              ylab = \"Displacement\",\n              zlab = \"Miles per gallon\", \n              pch = 16, \n              color = \"steelblue\")\n\n\n\n\n\n\n\n\n\n\n\n\nIn Python,\n\nCodefig = plt.figure()\nax = fig.add_subplot(projection='3d')\nax.scatter(mtcars['wt'], mtcars['disp'], mtcars['mpg'], c='steelblue', marker='o')\nax.set_title(\"3D Scatter Plot\")\nax.set_xlabel(\"Weights\")\nax.set_ylabel(\"Displacement\")\nax.set_zlabel(\"Miles per gallon\")\nplt.show()"
  },
  {
    "objectID": "slides/06-syntax.html#r-perspective-plot-persp",
    "href": "slides/06-syntax.html#r-perspective-plot-persp",
    "title": "Basic R  and Python \n",
    "section": "R Perspective Plot: persp()\n",
    "text": "R Perspective Plot: persp()\n\n\n\n\npar(mar = c(0,0,0,0))\n# Exaggerate the relief\nz &lt;- 2 * volcano      \n# 10 meter spacing (S to N)\nx &lt;- 10 * (1:nrow(z))   \n# 10 meter spacing (E to W)\ny &lt;- 10 * (1:ncol(z))   \npar(bg = \"slategray\")\npersp(x, y, z, theta = 135, phi = 30, \n      col = \"green3\", scale = FALSE,\n      ltheta = -120, shade = 0.75, \n      border = NA, box = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\nIn Python,\n\nCodevolcano = pd.read_csv(\"./slides/data/volcano.csv\", index_col=0)\nvolcano = volcano.values\nz = 2 * volcano\nx = np.arange(1, z.shape[0] + 1) * 10\ny = np.arange(1, z.shape[1] + 1) * 10  \nX, Y = np.meshgrid(y, x)\nfig = plt.figure()\nax = fig.add_subplot(projection='3d', facecolor=\"slategray\")\nax.plot_surface(X, Y, z, cmap=\"Greens\", edgecolor=\"none\", shade=True, alpha=0.9)\nplt.show()\n\n\n\nYou can also generate a so-called perspective plot using the function persp().\nI don’t use the function often. You can try it with different argument values, and see how it changes."
  },
  {
    "objectID": "slides/06-syntax.html#section-7",
    "href": "slides/06-syntax.html#section-7",
    "title": "Basic R  and Python \n",
    "section": "",
    "text": "07-Plotting  \nIn lab.qmd ## Lab 7,\n\nFor the mtcars data, use R or Python to\n\nmake a scatter plot of miles per gallon vs. weight. Decorate your plot using arguments, col, pch, xlab, etc.\ncreate a histogram of 1/4 mile time. Make it beautiful!\n\n\nCommit and Push your work once you are done.\n\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nmtcars = pd.read_csv('./data/mtcars.csv')"
  },
  {
    "objectID": "slides/06-syntax.html#resources",
    "href": "slides/06-syntax.html#resources",
    "title": "Basic R  and Python \n",
    "section": "Resources",
    "text": "Resources\n\nThe R Graph Gallery\nmatplotlib\n\nWe will talk about data visualization in detail soon!\nhttps://stackoverflow.com/questions/43482191/matplotlib-axes-plot-vs-pyplot-plot\n\n\n\n\nmath3570-s25.github.io/website"
  },
  {
    "objectID": "exercise/lab11-ggplot2.html",
    "href": "exercise/lab11-ggplot2.html",
    "title": "Lab 11: ggplot2",
    "section": "",
    "text": "Note\n\n\n\n\n\n\nIn lab.qmd ## Lab 11 section,\n\nUse readr::read_csv() to import the data penguins.csv into your R workspace.\nGenerate the following ggplot:\n\n\n\n\n\n\n\n\n\n\n\npenguins &lt;- read_csv(_________________)\n________ |&gt; \n  ggplot(mapping = ____(x = ______________,\n                        y = ______________,\n                        colour = ________)) +\n  geom______() +\n  ____(title = ____________________,\n       _________ = \"Dimensions for Adelie, Chinstrap, and Gentoo Penguins\",\n       x = _____________, y = _______________,\n       _______ = \"Species\",\n       _______ = \"Source: Palmer Station LTER / palmerpenguins package\")"
  },
  {
    "objectID": "exercise/lab18-prob.html",
    "href": "exercise/lab18-prob.html",
    "title": "Lab 18: Probability",
    "section": "",
    "text": "Note\n\n\n\n\n\n\nIn lab.qmd ## Lab 18 section,\n\nPlot the probability function \\(P(X = x)\\) of \\(X \\sim \\text{binomial}(n = 5, \\pi = 0.3)\\).\n\nTo use ggplot,\n\nCreate a data frame saving all possible values of \\(x\\) and their corresponding probability using dbinom(x, size = ___, prob = ___).\n\n\n\n# A tibble: 6 × 2\n      x       y\n  &lt;int&gt;   &lt;dbl&gt;\n1     0 0.168  \n2     1 0.360  \n3     2 0.309  \n4     3 0.132  \n5     4 0.0284 \n6     5 0.00243\n\n\n\nAdd geom_col()\n\n\n\n\n\n\n\n\n\n\n:::"
  },
  {
    "objectID": "exercise/lab05-rtype.html",
    "href": "exercise/lab05-rtype.html",
    "title": "Lab 05: R Data Type Summary",
    "section": "",
    "text": "Note\n\n\n\n\n\n\nIn lab.qmd Lab 5,\n\nCreate R objects vector v1, factor f2, list l3, matrix m4 and data frame d5.\nCheck typeof() and class() of those objects, and create a list having the output below.\n\n\nv1 &lt;- c(__________)\nf2 &lt;- f_____(__________)\nl3 &lt;- l_____(__________)\nm4 &lt;- m_____(__________)\nd5 &lt;- d_____.f_____(__________)\nv &lt;- c(type = typeof(v1), class = class(v1))\nf &lt;- c(type = __________, class = _________)\nl &lt;- c(type = __________, class = _________)\nm &lt;- c(type = __________, class = _________)\nd &lt;- c(type = __________, class = _________)\n____(vec    =   v,\n     ______ = ___,\n     ______ = ___,\n     ______ = ___,\n     ______ = ___)\n\n\n\n$vec\n     type     class \n \"double\" \"numeric\" \n\n$fac\n     type     class \n\"integer\"  \"factor\" \n\n$lst\n  type  class \n\"list\" \"list\" \n\n$mat\n     type    class1    class2 \n\"integer\"  \"matrix\"   \"array\" \n\n$df\n        type        class \n      \"list\" \"data.frame\""
  },
  {
    "objectID": "exercise/lab22-knn.html",
    "href": "exercise/lab22-knn.html",
    "title": "Lab 22: K Nearest Neighbors",
    "section": "",
    "text": "Note\n\n\n\n\n\n\nIn lab.qmd ## Lab 22 section,\n\n\nuse HEIGHT and WAIST to predict GENDER using KNN with \\(K = 3\\).\nGenerate the (test) confusion matrix.\nCalculate (test) accuracy rate.\nDoes using more predictors predict better?\n\n\nR Code\n\nlibrary(tidymodels)\n\n## load data\nbodydata &lt;- read_csv(\"./data/body.csv\")\nbody &lt;- bodydata |&gt; \n    select(GENDER, HEIGHT, WAIST, BMI) |&gt; \n    mutate(GENDER = as.factor(GENDER))\n\n## training and test data\nset.seed(2024)\ndf_split &lt;- initial_split(data = body, prop = 0.8)\ndf_trn &lt;- training(df_split)\ndf_tst &lt;- testing(df_split)\n\n## KNN training\nknn_recipe &lt;- recipe(GENDER ~ HEIGHT + WAIST, data = df_trn) |&gt; \n    step_normalize(all_predictors())\nknn_mdl &lt;- nearest_neighbor(neighbors = 3, mode = \"classification\")\nknn_out &lt;- workflow() |&gt; \n    add_recipe(knn_recipe) |&gt; \n    add_model(knn_mdl) |&gt; \n    fit(data = df_trn)\n\n## KNN prediction\nknn_pred &lt;- pull(predict(knn_out, df_tst))\ntable(knn_pred, df_tst$GENDER)\nmean(knn_pred == df_tst$GENDER)\n\n\n\nPython Code\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\n\n## load data\nbody = pd.read_csv('./data/body.csv')\nX = body[['HEIGHT', 'WAIST']]\ny = body['GENDER']\n\n## training and test data\nX_trn, X_tst, y_trn, y_tst = train_test_split(X, y, test_size=0.2, random_state=2024)\n\n## KNN training\nknn = KNeighborsClassifier(n_neighbors = 3)\nX_trn = np.array(X_trn)\nX_tst = np.array(X_tst)\nknn.fit(X_trn, y_trn)\n\n## KNN prediction\ny_pred = knn.predict(X_tst)\nfrom sklearn.metrics import confusion_matrix\nconfusion_matrix(y_tst, y_pred)\nnp.mean(y_tst == y_pred)"
  },
  {
    "objectID": "exercise/lab24-kmeans.html",
    "href": "exercise/lab24-kmeans.html",
    "title": "Lab 24: K-Means Clustering",
    "section": "",
    "text": "Note\n\n\n\n\n\n\nIn lab.qmd ## Lab 24 section,\n\nInstall R package palmerpenguins at https://allisonhorst.github.io/palmerpenguins/\nPerform K-Means to with \\(K = 3\\) to cluster penguins based on bill_length_mm and flipper_length_mm of data peng.\n\n\nlibrary(palmerpenguins)\npeng &lt;- penguins[complete.cases(penguins), ] |&gt; \n    select(flipper_length_mm, bill_length_mm)\n\n\n\n\n\n\n\n\n\n\n\n\nWarning: Removed 2 rows containing missing values (`geom_point()`)."
  },
  {
    "objectID": "exercise/lab16-join.html",
    "href": "exercise/lab16-join.html",
    "title": "Lab 16: Joining tables",
    "section": "",
    "text": "Note\n\n\n\n\n\n\nIn lab.qmd ## Lab 16 section\n\nImport the data at https://www.jaredlander.com/data/DiamondColors.csv. Call it diamond_color.\n\n\ndiamond_color &lt;- readr::read_csv(\"the url\")\n\n\nUse left_join() to combine the data set diamonds in ggplot2 and diamond_color by the key variable color.\n\n\n\nSelect the variables carat, color, Description, Details.\n\n\n## Variable \"color\" in diamonds but \"Color\" in diamond_color\n\njoined_df &lt;- diamonds |&gt;  \n    _______(_______, by = c('color' = 'Color')) |&gt;  ## join\n    _______(_________________________________________)  ## select\n\n\nCreate a bar chart of the variable color.\n\n\n\n# A tibble: 53,940 × 4\n   carat color Description    Details                    \n   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;          &lt;chr&gt;                      \n 1  0.23 E     Colorless      Minute traces of color     \n 2  0.21 E     Colorless      Minute traces of color     \n 3  0.23 E     Colorless      Minute traces of color     \n 4  0.29 I     Near Colorless Slightly detectable color  \n 5  0.31 J     Near Colorless Slightly detectable color  \n 6  0.24 J     Near Colorless Slightly detectable color  \n 7  0.24 I     Near Colorless Slightly detectable color  \n 8  0.26 H     Near Colorless Color is dificult to detect\n 9  0.22 E     Colorless      Minute traces of color     \n10  0.23 H     Near Colorless Color is dificult to detect\n# ℹ 53,930 more rows"
  },
  {
    "objectID": "exercise/lab20-slr.html",
    "href": "exercise/lab20-slr.html",
    "title": "Lab 20: Simple Linear Regression",
    "section": "",
    "text": "Note\n\n\n\n\n\n\nIn lab.qmd ## Lab 20 section,\n\nUse the mpg data to fit a simple linear regression where \\(y\\) is hwy and \\(x\\) is cty.\nProduce the plot below. (add the layer geom_smooth(method = \"lm\", se = FALSE))"
  },
  {
    "objectID": "exercise/lab21-logistic.html",
    "href": "exercise/lab21-logistic.html",
    "title": "Lab 21: Logistic Regression",
    "section": "",
    "text": "Note\n\n\n\n\n\n\nIn lab.qmd ## Lab 21 section,\n\nUse our fitted logistic regression model to predict whether you are male or female! Change 175 to your height (cm).\nUse the converter to get your height in cm!\n\n\n# Fit the logistic regression\n\npredict(logis_out$fit, newdata = data.frame(HEIGHT = 175), \n        type = \"response\")"
  },
  {
    "objectID": "exercise/lab23-pca.html",
    "href": "exercise/lab23-pca.html",
    "title": "Lab 23: Principal Component Analysis",
    "section": "",
    "text": "Note\n\n\n\n\n\n\nIn lab.qmd ## Lab 23 section,\n\nUse slice() to print the first six rows of iris data.\nPerform PCA on Sepal.Length, Sepal.Width, Petal.Length, and Petal.Width.\nGenerate biplot, and explain it.\n\n\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa"
  },
  {
    "objectID": "exercise/lab04-chunk.html",
    "href": "exercise/lab04-chunk.html",
    "title": "Lab 04: Code Chunk",
    "section": "",
    "text": "Note\n\n\n\n\n\n\n\nIn lab.qmd ## Lab 4: Code Chunk, use code chunks to\n\ninclude an image with knitr::include_graphics(\"URL or file path\") https://raw.githubusercontent.com/rstudio/hex-stickers/master/PNG/ggplot2.png\ninclude a plot plot(mtcars$disp, mtcars$mpg)\nShow dataset mtcars as a table using knitr::kable()\n\nDo some inline code calculation like `r ncol(mtcars)`, `r log(100, base = 10) + sqrt(4)`.\nAdd option fig-height: 4, fig-width: 6 and fig-align: right to the chunk for your plot. What are the changes?\nHow do we set global chunk options to not show the code in every chunk in the document?\nOnce done, commit with message “04-codechunk” and push your work to GitHub."
  },
  {
    "objectID": "exercise/lab17-tidyr.html",
    "href": "exercise/lab17-tidyr.html",
    "title": "Lab 17: tidyr",
    "section": "",
    "text": "Note\n\n\n\n\n\n\nIn lab.qmd ## Lab 17 section,\n\n\nImport trump.csv. Call it trump_data as below on the left.\nUse pivot_longer() to transform trump_data into the data set trump_longer on the right.\n\n\ntrump_data\n\n# A tibble: 2,702 × 4\n   subgroup date       approval disapproval\n   &lt;chr&gt;    &lt;date&gt;        &lt;dbl&gt;       &lt;dbl&gt;\n 1 Voters   2020-10-04     44.7        52.2\n 2 Adults   2020-10-04     43.2        52.6\n 3 Adults   2020-10-03     43.2        52.6\n 4 Voters   2020-10-03     45.0        51.7\n 5 Adults   2020-10-02     43.3        52.4\n 6 Voters   2020-10-02     44.5        52.1\n 7 Voters   2020-10-01     44.1        52.8\n 8 Adults   2020-10-01     42.7        53.3\n 9 Adults   2020-09-30     42.2        53.7\n10 Voters   2020-09-30     44.2        52.7\n# ℹ 2,692 more rows\n\n\n\ntrump_longer &lt;- ______________\n    pivot_longer(\n        cols = ____________,\n        names_to = _______________,\n        values_to = _______________\n    ) \n\n\n\n# A tibble: 5,404 × 4\n   subgroup date       rating_type rating_value\n   &lt;chr&gt;    &lt;date&gt;     &lt;chr&gt;              &lt;dbl&gt;\n 1 Voters   2020-10-04 approval            44.7\n 2 Voters   2020-10-04 disapproval         52.2\n 3 Adults   2020-10-04 approval            43.2\n 4 Adults   2020-10-04 disapproval         52.6\n 5 Adults   2020-10-03 approval            43.2\n 6 Adults   2020-10-03 disapproval         52.6\n 7 Voters   2020-10-03 approval            45.0\n 8 Voters   2020-10-03 disapproval         51.7\n 9 Adults   2020-10-02 approval            43.3\n10 Adults   2020-10-02 disapproval         52.4\n# ℹ 5,394 more rows\n\n\nBONUS 💷: Use trump_longer to generate a plot like the one below."
  },
  {
    "objectID": "exercise/lab10-import.html",
    "href": "exercise/lab10-import.html",
    "title": "Lab 10: Import Data",
    "section": "",
    "text": "Note\n\n\n\n\n\n\n\nIf you haven’t, install and load the tidyverse package.\n\nIn lab.qmd ## Lab 10 section,        \n\nImport ssa_male_prob.csv and ssa_female_prob.Rds in the data folder using read_csv() and call them ssa_male and ssa_female, respectively.\n\n\nssa_male &lt;- readr::read____(____________)\nssa_female &lt;- readr::read____(____________)\n\n\nPlot Age (x-axis) vs. LifeExp (y-axis) for Female. The type should be “line”, and the line color is red. Add x-label, y-label and title to your plot.\n\n\nplot(x = _____, y = _____, type = ______, col = ______,\n     xlab = ______, ylab = _______, main = ____________)\n\n\nUse lines() to add a line of Age (x-axis) vs. LifeExp (y-axis) for Male to the plot. The color is blue.\n\n\nlines(x = _____, y = _____, col = ______)"
  },
  {
    "objectID": "exercise/lab00-posit.html",
    "href": "exercise/lab00-posit.html",
    "title": "Lab Exercise: Posit Cloud",
    "section": "",
    "text": "Note"
  },
  {
    "objectID": "exercise/lab00-posit.html#install-posit-cloud",
    "href": "exercise/lab00-posit.html#install-posit-cloud",
    "title": "Lab Exercise: Posit Cloud",
    "section": "Install Posit Cloud",
    "text": "Install Posit Cloud\n\nStep 1: In the Posit website https://posit.co/, choose Products &gt; Posit Cloud as shown below.\n\n\n\n\n\n\n\n\n\n\n\nStep 2: Click GET STARTED.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStep 3: Cloud Student &gt; Sign Up using your Marquette email address.\n\n\n\n\n\n\n\n\n\n\nThe student plan has more computing power and resources that help you do homework and data science project more efficiently!\n\nNew project"
  },
  {
    "objectID": "exercise/lab00-posit.html#welcome-to-3570-data-science",
    "href": "exercise/lab00-posit.html#welcome-to-3570-data-science",
    "title": "Lab Exercise: Posit Cloud",
    "section": "Welcome to 3570 Data Science!",
    "text": "Welcome to 3570 Data Science!\n\nI’m sending you a link via email for joining the course workspace 2025-spring-math-3570. Please join.\n\n\n\n\n\n\n\n\n\n\n\nIn the bar, click workspace 2025-spring-math-3570.\nClick New Project &gt; New RStudio Project to get into the IDE.\nIn Untitled Project, name your project as 3570-project.\nIn the Console pane, write R code: a string \"Hello WoRld!\" or math 2 + 4.\nTools &gt; Global Options &gt; Appearance to select your favorite editor theme."
  },
  {
    "objectID": "exercise/lab07-plot.html",
    "href": "exercise/lab07-plot.html",
    "title": "Lab 07: Plotting",
    "section": "",
    "text": "Note\n\n\n\n\n\n\n\n\nIn lab.qmd ## Lab 7,\n\nFor the mtcars data, use R or Python to\n\nmake a scatter plot of miles per gallon vs. weight. Decorate your plot using arguments, col, pch, xlab, etc.\ncreate a histogram of 1/4 mile time. Make it beautiful!\n\nCommit and Push your work once you are done."
  }
]